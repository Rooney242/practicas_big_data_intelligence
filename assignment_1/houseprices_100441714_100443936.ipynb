{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices Kaggle Competition\n",
    "\n",
    "\n",
    "## Authors \n",
    "David Moreno Maldonado 100441714    \n",
    "Inés Fernández Campos 100443936    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the completion of this exercise we start by importing all the libraries we are going to need as well as defining all parameters for the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import statistics as st\n",
    "from sklearn import preprocessing, model_selection, tree, neighbors, metrics\n",
    "from scipy.stats import uniform, randint as sp_randint\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN PARAMETERS FOR THE ASSIGNMENT\n",
    "budget = 100\n",
    "random_state = 0\n",
    "verbose = 0\n",
    "\n",
    "#PARAMETERS FOR THE HYPER-PARAMETER TUNNING\n",
    "min_max_depth = 2\n",
    "max_max_depth = 20#16\n",
    "min_n_neigbors = 1\n",
    "max_n_neigbors = 16#16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create a dataframe that will contain all information regarding the studied models for each different configuration applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframes with all the information of each model\n",
    "summary = {\n",
    "    'tree': pd.DataFrame(columns=['Time (sec)', 'Score (RMSE)', 'Min. samples split', 'Criterion', 'Max. depth']),\n",
    "    'knn': pd.DataFrame(columns=['Time (sec)', 'Score (RMSE)', 'N. neighbors', 'Weights', 'P'])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "\n",
    "In the next cells we load the data, split it in four matrices, two used for training and two used for the competition, we standardize the input attributes and split our training matrices into train test splits, as well as define the cross validation grid used for 2-fold cross validation throughout the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "data = pd.read_csv(\"kaggleCompetition.csv\")\n",
    "data = data.values\n",
    "\n",
    "#Splitting data in the one used for training and the one used for the competition\n",
    "x = data[0:1460, :-1]\n",
    "y = data[0:1460, -1] \n",
    "x_comp = data[1460:,:-1] \n",
    "y_comp = data[1460:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize input attributes.\n",
    "scaler = preprocessing.StandardScaler().fit(x) \n",
    "x = scaler.transform(x)\n",
    "x_comp = scaler.transform(x_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split in train/test sets using holdout 3/4 for training, 1/4 for testing\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, train_size=0.75, random_state=0)\n",
    "\n",
    "#Hyperparams evaluated by 2-fold CV (inner evaluation)\n",
    "cv_grid = model_selection.KFold(n_splits=2, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models using **default parameters**\n",
    "\n",
    "In this section we evaluate the performance of the regression using decission trees and KNN when using default parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by training the decision tree with all its default parameters: min_samples_split = 2, max_depth = None and criterion='mse'.    \n",
    "Once trained, we perform its inner evaluation applying 2-fold CV on the train splitted data and save the acquired data to our summary dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1.1 Decision Tree\n",
    "np.random.seed(random_state)\n",
    "tree_default = tree.DecisionTreeRegressor(random_state=random_state)\n",
    "scores = -model_selection.cross_val_score(tree_default, x_train, y_train, scoring='neg_root_mean_squared_error', cv=cv_grid)\n",
    "\n",
    "summary['tree'] = summary['tree'].append(pd.Series({\n",
    "    'Time (sec)': 0, \n",
    "    'Score (RMSE)': scores.mean(),\n",
    "    'Min. samples split': 2, \n",
    "    'Criterion': 'mse', \n",
    "    'Max. depth': 'None'\n",
    "    },\n",
    "    name='default'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also implement regression through KNN with all its default parameters: n_neighbors=5, weights='uniform', p=2, metric='minkowski'.   \n",
    "As we did with the decision tree, once trained, we perform its inner evaluation applying 2-fold CV on the train splitted data and save the acquired data to our summary dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1.2 K Nearest neighbours\n",
    "np.random.seed(random_state)\n",
    "knn_default = neighbors.KNeighborsRegressor()\n",
    "scores = -model_selection.cross_val_score(knn_default, x_train, y_train, scoring='neg_root_mean_squared_error', cv=cv_grid) \n",
    "\n",
    "summary['knn'] = summary['knn'].append(pd.Series({\n",
    "    'Time (sec)': 0, \n",
    "    'Score (RMSE)': scores.mean(), \n",
    "    'N. neighbors': 5, \n",
    "    'Weights': 'uniform', \n",
    "    'P': 2\n",
    "    }, \n",
    "    name='default'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models using **Random Search** tuning\n",
    "\n",
    "In this section we evaluate the performance of the regression using decission trees and KNN when using random search to tune the hyper-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since now we are using random search to tune our hyper-parameters, we must first define our hyper-parameter search space, in this case, *param_grid*.   \n",
    "For decision trees this greed hold three hyper-parameters to tune: the min_samples_split, a set of real numbers within 0.0 and 1.0, the criterion, either mse of friedman_mse, and finally the max_depth wich will be an integer between 2 and 20.   \n",
    "\n",
    "Once the search space defined, we define the two step method to be applied on the decision tree and evaluated using 2-fold CV over *budget* (20) iterations.   \n",
    "Then, the two step method is trained and timed and the best values for the hyper-parameters along with the time are saved in the correspondant summary dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "###3.2 Random search for Decission Tree hyper-parameter tunning\n",
    "np.random.seed(random_state)\n",
    "param_grid = {\n",
    "    'min_samples_split': uniform(0, 1),\n",
    "    'criterion': ['mse','friedman_mse'], \n",
    "    'max_depth': sp_randint(min_max_depth, max_max_depth)\n",
    "}\n",
    "tree_random_search = model_selection.RandomizedSearchCV(\n",
    "    tree.DecisionTreeRegressor(random_state=random_state), \n",
    "    param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=cv_grid, \n",
    "    verbose=verbose,\n",
    "    n_iter=budget\n",
    "    )\n",
    "start_time = time.time()\n",
    "tree_random_search.fit(X=x_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['tree'] = summary['tree'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': -tree_random_search.best_score_,\n",
    "    'Min. samples split': tree_random_search.best_params_['min_samples_split'], \n",
    "    'Criterion': tree_random_search.best_params_['criterion'], \n",
    "    'Max. depth': tree_random_search.best_params_['max_depth']\n",
    "    },\n",
    "    name='random_search'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For KNN, the procedure is the same, the only thing that changes is the hyper-parameters to tune. In this case, these are: the number of neighbors, a random integer between 1 and 16, the weights, the type of distance, and p, the exponent of the distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###3.3 Random search for K Nearest Neighbours hyper-parameter tunning\n",
    "np.random.seed(random_state)\n",
    "param_grid = {\n",
    "    'n_neighbors': sp_randint(min_n_neigbors, max_n_neigbors),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "knn_random_search = model_selection.RandomizedSearchCV(\n",
    "    neighbors.KNeighborsRegressor(), \n",
    "    param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=cv_grid, \n",
    "    verbose=verbose,\n",
    "    n_iter=budget\n",
    "    )\n",
    "start_time = time.time()\n",
    "knn_random_search.fit(X=x_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['knn'] = summary['knn'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': -knn_random_search.best_score_, \n",
    "    'N. neighbors': knn_random_search.best_params_['n_neighbors'], \n",
    "    'Weights': knn_random_search.best_params_['weights'], \n",
    "    'P': knn_random_search.best_params_['p']\n",
    "    }, \n",
    "    name='random_search'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models using **SKOPT - Bayesian Optimization** Hyper-Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3.4.1 Decission trees\n",
    "np.random.seed(random_state)\n",
    "param_grid = {\n",
    "    'min_samples_split': Real(0+sys.float_info.min, 1),\n",
    "    'criterion': Categorical(['mse','friedman_mse']), \n",
    "    'max_depth': Integer(min_max_depth, max_max_depth)\n",
    "}\n",
    "tree_skopt = BayesSearchCV(tree.DecisionTreeRegressor(random_state=random_state), \n",
    "    param_grid,\n",
    "    cv=cv_grid,    \n",
    "    verbose=verbose,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_iter=budget\n",
    "    )\n",
    "start_time = time.time()\n",
    "tree_skopt.fit(X=x_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['tree'] = summary['tree'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': -tree_skopt.best_score_,\n",
    "    'Min. samples split': tree_skopt.best_params_['min_samples_split'], \n",
    "    'Criterion': tree_skopt.best_params_['criterion'], \n",
    "    'Max. depth': tree_skopt.best_params_['max_depth']\n",
    "    },\n",
    "    name='skopt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3.4.1 K Nearest neighbours\n",
    "np.random.seed(random_state)\n",
    "param_grid = {\n",
    "    'n_neighbors': Integer(min_n_neigbors, max_n_neigbors),\n",
    "    'weights': Categorical(['uniform', 'distance']),\n",
    "    'p': Categorical([1, 2])\n",
    "}\n",
    "knn_skopt = BayesSearchCV(neighbors.KNeighborsRegressor(), \n",
    "    param_grid,\n",
    "    cv=cv_grid,    \n",
    "    verbose=verbose,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_iter=budget\n",
    "    )\n",
    "start_time = time.time()\n",
    "knn_skopt.fit(X=x_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['knn'] = summary['knn'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': -knn_skopt.best_score_, \n",
    "    'N. neighbors': knn_skopt.best_params_['n_neighbors'], \n",
    "    'Weights': knn_skopt.best_params_['weights'], \n",
    "    'P': knn_skopt.best_params_['p']\n",
    "    }, \n",
    "    name='skopt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna - Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainings OPTUNA models\n"
     ]
    }
   ],
   "source": [
    "###3.5 Optuna (bayesian) hyper-parameter tunning\n",
    "print('Trainings OPTUNA models')\n",
    "optuna.logging.set_verbosity(verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.5.1 Decission trees\n",
    "np.random.seed(random_state)\n",
    "def tree_objective(trial):\n",
    "    min_samples_split = trial.suggest_uniform('min_samples_split', 0+sys.float_info.min, 1)\n",
    "    criterion = trial.suggest_categorical('criterion', ['mse','friedman_mse'])\n",
    "    max_depth = trial.suggest_int('max_depth', min_max_depth, max_max_depth)\n",
    "\n",
    "    clf = tree.DecisionTreeRegressor(\n",
    "        random_state=random_state,\n",
    "        min_samples_split=min_samples_split,\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth)\n",
    "\n",
    "    scores = -model_selection.cross_val_score(clf, x_train, y_train,\n",
    "        cv=cv_grid,\n",
    "        verbose=verbose,\n",
    "        scoring='neg_root_mean_squared_error')\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "tree_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "tree_optuna.optimize(tree_objective, n_trials=budget)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['tree'] = summary['tree'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': tree_optuna.best_value,\n",
    "    'Min. samples split': tree_optuna.best_params['min_samples_split'], \n",
    "    'Criterion': tree_optuna.best_params['criterion'], \n",
    "    'Max. depth': tree_optuna.best_params['max_depth']\n",
    "    },\n",
    "    name='optuna'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.5.2 K Nearest Neighbours\n",
    "np.random.seed(random_state)\n",
    "def knn_objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', min_n_neigbors, max_n_neigbors)\n",
    "    weights = trial.suggest_categorical('weights', ['uniform','distance'])\n",
    "    p = trial.suggest_categorical('p', [1, 2])\n",
    "\n",
    "    clf = neighbors.KNeighborsRegressor(\n",
    "        n_neighbors=n_neighbors,\n",
    "        weights=weights,\n",
    "        p=p)\n",
    "\n",
    "    scores = -model_selection.cross_val_score(clf, x_train, y_train,\n",
    "        cv=cv_grid,\n",
    "        verbose=verbose,\n",
    "        scoring='neg_root_mean_squared_error')\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "knn_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "knn_optuna.optimize(knn_objective, n_trials=budget)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['knn'] = summary['knn'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': knn_optuna.best_value, \n",
    "    'N. neighbors': knn_optuna.best_params['n_neighbors'], \n",
    "    'Weights': knn_optuna.best_params['weights'], \n",
    "    'P': knn_optuna.best_params['p']\n",
    "    }, \n",
    "    name='optuna'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUMMARY FOR DECISSION TREE MODELS\n",
      "              Time (sec)  Score (RMSE) Min. samples split     Criterion  \\\n",
      "default                0      0.236676                  2           mse   \n",
      "default                0      0.236676                  2           mse   \n",
      "random_search     0.9377      0.215140          0.0580292  friedman_mse   \n",
      "skopt           332.1260      0.211516          0.0529852           mse   \n",
      "optuna            2.3214      0.211674          0.0514588           mse   \n",
      "\n",
      "              Max. depth  \n",
      "default             None  \n",
      "default             None  \n",
      "random_search          9  \n",
      "skopt                 19  \n",
      "optuna                13  \n",
      "\n",
      "SUMMARY FOR K NEAREST NEIGHBORS MODELS\n",
      "              Time (sec)  Score (RMSE) N. neighbors   Weights  P\n",
      "default                0      0.191550            5   uniform  2\n",
      "random_search    13.0968      0.177165            6  distance  1\n",
      "skopt           401.8476      0.177087            7  distance  1\n",
      "optuna           13.1554      0.177086            7  distance  1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSUMMARY FOR DECISSION TREE MODELS\")\n",
    "print(summary['tree'])\n",
    "print(\"\\nSUMMARY FOR K NEAREST NEIGHBORS MODELS\")\n",
    "print(summary['knn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The best model is K Nearest Neighbors Regressor with optuna\n"
     ]
    }
   ],
   "source": [
    "###3.6 Determine the best model from its inner evaluation\n",
    "best_tree_model = summary['tree']['Score (RMSE)'].idxmin()\n",
    "best_knn_model = summary['knn']['Score (RMSE)'].idxmin()\n",
    "\n",
    "if summary['tree'].loc[best_tree_model]['Score (RMSE)'] < summary['knn'].loc[best_knn_model]['Score (RMSE)']:\n",
    "    print('\\n--> The best model is Decision Tree Regressor with {}'.format(best_tree_model))\n",
    "    best_model = tree.DecisionTreeRegressor(\n",
    "        random_state=random_state,\n",
    "        min_samples_split=summary['tree'].loc[best_tree_model]['Min. samples split'] ,\n",
    "        criterion=summary['tree'].loc[best_tree_model]['Criterion'],\n",
    "        max_depth=summary['tree'].loc[best_tree_model]['Max. depth'])\n",
    "else:\n",
    "    print('\\nThe best model is K Nearest Neighbors Regressor with {}'.format(best_knn_model))\n",
    "    best_model = neighbors.KNeighborsRegressor(\n",
    "        n_neighbors=summary['knn'].loc[best_knn_model]['N. neighbors'] ,\n",
    "        weights=summary['knn'].loc[best_knn_model]['Weights'],\n",
    "        p=summary['knn'].loc[best_knn_model]['P'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model performance at competition:\n",
      "RMSE: 0.1620 (should be lower than the trivial predictor using the mean MSE: 0.3856)\n",
      "R square: 0.8234 (should be higher than the trivial predictor using the mean: R square 0.0000)\n"
     ]
    }
   ],
   "source": [
    "###3.7 Performance estimation\n",
    "best_model.fit(x_train, y_train)\n",
    "best_model_predict = best_model.predict(x_test)\n",
    "print('\\nBest Model performance at competition:')\n",
    "print('RMSE: {:.4f} (should be lower than the trivial predictor using the mean MSE: {:.4f})'.format(\n",
    "    math.sqrt(metrics.mean_squared_error(y_test, best_model_predict)),\n",
    "    math.sqrt(metrics.mean_squared_error(y_test, [y_test.mean() for i in range(len(y_test))]))))\n",
    "print('R square: {:.4f} (should be higher than the trivial predictor using the mean: R square {:.4f})'.format(\n",
    "    metrics.r2_score(y_test, best_model_predict),\n",
    "    metrics.r2_score(y_test, [y_test.mean() for i in range(len(y_test))])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.8 Final model train\n",
    "best_model.fit(x, y)\n",
    "y_comp = [math.exp(i) for i in best_model.predict(x_comp)]\n",
    "\n",
    "submission = pd.DataFrame(columns=['Id', 'SalePrice'])\n",
    "submission['Id'] = pd.Series(range(1461, 2920))\n",
    "submission['SalePrice'] = pd.Series(y_comp)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
