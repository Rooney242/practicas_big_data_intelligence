{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Prices Kaggle Competition\n",
    "\n",
    "\n",
    "## Authors \n",
    "David Moreno Maldonado 100441714    \n",
    "Inés Fernández Campos 100443936    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the completion of this exercise we start by importing all the libraries we are going to need as well as defining all parameters for the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import statistics as st\n",
    "from sklearn import preprocessing, model_selection, tree, neighbors, metrics\n",
    "from scipy.stats import uniform, randint as sp_randint\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real, Categorical\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN PARAMETERS FOR THE ASSIGNMENT\n",
    "budget = 100\n",
    "random_state = 0\n",
    "verbose = 0\n",
    "\n",
    "#PARAMETERS FOR THE HYPER-PARAMETER TUNNING\n",
    "min_max_depth = 2\n",
    "max_max_depth = 20#16\n",
    "min_n_neigbors = 1\n",
    "max_n_neigbors = 16#16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create a dataframe that will contain all information regarding the studied models for each different configuration applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframes with all the information of each model\n",
    "summary = {\n",
    "    'tree': pd.DataFrame(columns=['Time (sec)', 'Score (RMSE)', 'Min. samples split', 'Criterion', 'Max. depth']),\n",
    "    'knn': pd.DataFrame(columns=['Time (sec)', 'Score (RMSE)', 'N. neighbors', 'Weights', 'P'])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "\n",
    "In the next cells we load the data, split it in four matrices, two used for training and two used for the competition, we standardize the input attributes and split our training matrices into train test splits, as well as define the cross validation grid used for 2-fold cross validation throughout the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data\n",
    "data = pd.read_csv(\"kaggleCompetition.csv\")\n",
    "data = data.values\n",
    "\n",
    "#Splitting data in the one used for training and the one used for the competition\n",
    "x = data[0:1460, :-1]\n",
    "y = data[0:1460, -1] \n",
    "x_comp = data[1460:,:-1] \n",
    "y_comp = data[1460:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize input attributes.\n",
    "scaler = preprocessing.StandardScaler().fit(x) \n",
    "x = scaler.transform(x)\n",
    "x_comp = scaler.transform(x_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split in train/test sets using holdout 3/4 for training, 1/4 for testing\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, train_size=0.75, random_state=0)\n",
    "\n",
    "#Hyperparams evaluated by 2-fold CV (inner evaluation)\n",
    "cv_grid = model_selection.KFold(n_splits=2, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models using **default parameters**\n",
    "\n",
    "In this section we evaluate the performance of the regression using decission trees and KNN when using default parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by training the decision tree with all its default parameters: min_samples_split = 2, max_depth = None and criterion='mse'.    \n",
    "Once trained, we perform its inner evaluation applying 2-fold CV on the train splitted data and save the acquired data to our summary dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1.1 Decision Tree\n",
    "np.random.seed(random_state)\n",
    "tree_default = tree.DecisionTreeRegressor(random_state=random_state)\n",
    "\n",
    "scores = -model_selection.cross_val_score(tree_default, x_train, y_train, scoring='neg_root_mean_squared_error', cv=cv_grid)\n",
    "\n",
    "summary['tree'] = summary['tree'].append(pd.Series({\n",
    "    'Time (sec)': 0, \n",
    "    'Score (RMSE)': scores.mean(),\n",
    "    'Min. samples split': 2, \n",
    "    'Criterion': 'mse', \n",
    "    'Max. depth': 'None'\n",
    "    },\n",
    "    name='default'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also implement regression through KNN with all its default parameters: n_neighbors=5, weights='uniform', p=2, metric='minkowski'.   \n",
    "As we did with the decision tree, once trained, we perform its inner evaluation applying 2-fold CV on the train splitted data and save the acquired data to our summary dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.1.2 K Nearest neighbours\n",
    "np.random.seed(random_state)\n",
    "knn_default = neighbors.KNeighborsRegressor()\n",
    "scores = -model_selection.cross_val_score(knn_default, x_train, y_train, scoring='neg_root_mean_squared_error', cv=cv_grid) \n",
    "\n",
    "summary['knn'] = summary['knn'].append(pd.Series({\n",
    "    'Time (sec)': 0, \n",
    "    'Score (RMSE)': scores.mean(), \n",
    "    'N. neighbors': 5, \n",
    "    'Weights': 'uniform', \n",
    "    'P': 2\n",
    "    }, \n",
    "    name='default'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models using **Random Search** tuning\n",
    "\n",
    "In this section we evaluate the performance of the regression using decission trees and KNN when using random search to tune the hyper-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since now we are using random search to tune our hyper-parameters, we must first define our hyper-parameter search space, in this case, *param_grid*.   \n",
    "For decision trees this greed hold three hyper-parameters to tune: the min_samples_split, a set of real numbers within 0.0 and 1.0, the criterion, either mse of friedman_mse, and finally the max_depth wich will be an integer between 2 and 20.   \n",
    "\n",
    "Once the search space defined, we define the two step method to be applied on the decision tree and evaluated using 2-fold CV over *budget* (20) iterations and performance measure the negative root MSE.      \n",
    "Then, the two step method is trained and timed and the best values for the hyper-parameters along with the time are saved in the correspondant summary dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###3.2 Random search for Decission Tree hyper-parameter tunning\n",
    "np.random.seed(random_state)\n",
    "param_grid = {\n",
    "    'min_samples_split': uniform(0, 1),\n",
    "    'criterion': ['mse','friedman_mse'], \n",
    "    'max_depth': sp_randint(min_max_depth, max_max_depth)\n",
    "}\n",
    "tree_random_search = model_selection.RandomizedSearchCV(\n",
    "    tree.DecisionTreeRegressor(random_state=random_state), \n",
    "    param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=cv_grid, \n",
    "    verbose=verbose,\n",
    "    n_iter=budget\n",
    "    )\n",
    "start_time = time.time()\n",
    "tree_random_search.fit(X=x_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['tree'] = summary['tree'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': -tree_random_search.best_score_,\n",
    "    'Min. samples split': tree_random_search.best_params_['min_samples_split'], \n",
    "    'Criterion': tree_random_search.best_params_['criterion'], \n",
    "    'Max. depth': tree_random_search.best_params_['max_depth']\n",
    "    },\n",
    "    name='random_search'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For KNN, the procedure is the same, the only thing that changes is the hyper-parameters to tune. In this case, these are: the number of neighbors, a random integer between 1 and 16, the weights, the type of distance, and p, the exponent of the distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###3.3 Random search for K Nearest Neighbours hyper-parameter tunning\n",
    "np.random.seed(random_state)\n",
    "param_grid = {\n",
    "    'n_neighbors': sp_randint(min_n_neigbors, max_n_neigbors),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "knn_random_search = model_selection.RandomizedSearchCV(\n",
    "    neighbors.KNeighborsRegressor(), \n",
    "    param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=cv_grid, \n",
    "    verbose=verbose,\n",
    "    n_iter=budget\n",
    "    )\n",
    "start_time = time.time()\n",
    "knn_random_search.fit(X=x_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['knn'] = summary['knn'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': -knn_random_search.best_score_, \n",
    "    'N. neighbors': knn_random_search.best_params_['n_neighbors'], \n",
    "    'Weights': knn_random_search.best_params_['weights'], \n",
    "    'P': knn_random_search.best_params_['p']\n",
    "    }, \n",
    "    name='random_search'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models using **SKOPT - Bayesian Optimization** Hyper-Parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section goes through the implementation of hyper-parameter tuning by means of model based optimization (bayesian optimization).    \n",
    "\n",
    "In comparison with the previous search methods, the implementation of Bayesian optimization is very similar in the sense that we define a similar parameter grid with the hyper-parameters to explore, evaluate with 2-fold CV and measure performance through the negative root MSE.    \n",
    "Differences can be found however, in the way the search space of the hyper-parameters are defined, in this case using specific skopt classes that stablish the hyper-parameter's type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3.4.1 Decission trees\n",
    "np.random.seed(random_state)\n",
    "param_grid = {\n",
    "    'min_samples_split': Real(0+sys.float_info.min, 1),\n",
    "    'criterion': Categorical(['mse','friedman_mse']), \n",
    "    'max_depth': Integer(min_max_depth, max_max_depth)\n",
    "}\n",
    "tree_skopt = BayesSearchCV(tree.DecisionTreeRegressor(random_state=random_state), \n",
    "    param_grid,\n",
    "    cv=cv_grid,    \n",
    "    verbose=verbose,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_iter=budget\n",
    "    )\n",
    "start_time = time.time()\n",
    "tree_skopt.fit(X=x_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['tree'] = summary['tree'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': -tree_skopt.best_score_,\n",
    "    'Min. samples split': tree_skopt.best_params_['min_samples_split'], \n",
    "    'Criterion': tree_skopt.best_params_['criterion'], \n",
    "    'Max. depth': tree_skopt.best_params_['max_depth']\n",
    "    },\n",
    "    name='skopt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n",
      "/home/fddcampos/.local/lib/python3.8/site-packages/skopt/optimizer/optimizer.py:449: UserWarning:\n",
      "\n",
      "The objective has been evaluated at this point before.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3.4.1 K Nearest neighbours\n",
    "np.random.seed(random_state)\n",
    "param_grid = {\n",
    "    'n_neighbors': Integer(min_n_neigbors, max_n_neigbors),\n",
    "    'weights': Categorical(['uniform', 'distance']),\n",
    "    'p': Categorical([1, 2])\n",
    "}\n",
    "knn_skopt = BayesSearchCV(neighbors.KNeighborsRegressor(), \n",
    "    param_grid,\n",
    "    cv=cv_grid,    \n",
    "    verbose=verbose,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_iter=budget\n",
    "    )\n",
    "start_time = time.time()\n",
    "knn_skopt.fit(X=x_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['knn'] = summary['knn'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': -knn_skopt.best_score_, \n",
    "    'N. neighbors': knn_skopt.best_params_['n_neighbors'], \n",
    "    'Weights': knn_skopt.best_params_['weights'], \n",
    "    'P': knn_skopt.best_params_['p']\n",
    "    }, \n",
    "    name='skopt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Optuna models - Bayesian Optimization\n",
    "\n",
    "In this section, we tune our hyperparameters now using optuna to apply bayesian optimization.   \n",
    "\n",
    "In order to use optuna, we define an objective function (*tree_objective* and *knn_objective*) where we suggest values for the hyper-parameters using a trial object. The trial object sets a new point in the hyper-parameter space, a suggestion of hyper-parameters to evaluate. Then, the model is created using those hyper-parameters and through CV a score is produced.\n",
    "\n",
    "Through optuna, we create a *study*, an optimization session with a direction. In our case we seek to minimize the objective function's negative root MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-21 18:56:54,495]\u001b[0m A new study created in memory with name: no-name-9d73be2c-e63a-4ca1-a3ad-3efe05ba658f\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,505]\u001b[0m Trial 0 finished with value: 0.2984974304504965 and parameters: {'min_samples_split': 0.6861249154215259, 'criterion': 'mse', 'max_depth': 16}. Best is trial 0 with value: 0.2984974304504965.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,522]\u001b[0m Trial 1 finished with value: 0.23452873176177735 and parameters: {'min_samples_split': 0.1907816462795069, 'criterion': 'friedman_mse', 'max_depth': 7}. Best is trial 1 with value: 0.23452873176177735.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,537]\u001b[0m Trial 2 finished with value: 0.2827141767132929 and parameters: {'min_samples_split': 0.4378314630460862, 'criterion': 'friedman_mse', 'max_depth': 9}. Best is trial 1 with value: 0.23452873176177735.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,555]\u001b[0m Trial 3 finished with value: 0.22403157570587573 and parameters: {'min_samples_split': 0.11408441057280105, 'criterion': 'friedman_mse', 'max_depth': 17}. Best is trial 3 with value: 0.22403157570587573.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,566]\u001b[0m Trial 4 finished with value: 0.2984974304504965 and parameters: {'min_samples_split': 0.8878301325750569, 'criterion': 'mse', 'max_depth': 12}. Best is trial 3 with value: 0.22403157570587573.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,583]\u001b[0m Trial 5 finished with value: 0.2442142842141522 and parameters: {'min_samples_split': 0.23761897123961062, 'criterion': 'mse', 'max_depth': 12}. Best is trial 3 with value: 0.22403157570587573.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,597]\u001b[0m Trial 6 finished with value: 0.23457069336124417 and parameters: {'min_samples_split': 0.08224077737789726, 'criterion': 'friedman_mse', 'max_depth': 3}. Best is trial 3 with value: 0.22403157570587573.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,611]\u001b[0m Trial 7 finished with value: 0.2518175367743838 and parameters: {'min_samples_split': 0.32539044498839287, 'criterion': 'friedman_mse', 'max_depth': 6}. Best is trial 3 with value: 0.22403157570587573.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,626]\u001b[0m Trial 8 finished with value: 0.2776573521072824 and parameters: {'min_samples_split': 0.4294786752512496, 'criterion': 'mse', 'max_depth': 7}. Best is trial 3 with value: 0.22403157570587573.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,661]\u001b[0m Trial 9 finished with value: 0.23169068570274337 and parameters: {'min_samples_split': 0.016030350232298263, 'criterion': 'friedman_mse', 'max_depth': 12}. Best is trial 3 with value: 0.22403157570587573.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,681]\u001b[0m Trial 10 finished with value: 0.2984974304504965 and parameters: {'min_samples_split': 0.6431910369745377, 'criterion': 'friedman_mse', 'max_depth': 19}. Best is trial 3 with value: 0.22403157570587573.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,712]\u001b[0m Trial 11 finished with value: 0.23070928541369706 and parameters: {'min_samples_split': 0.017583956777331013, 'criterion': 'friedman_mse', 'max_depth': 16}. Best is trial 3 with value: 0.22403157570587573.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,741]\u001b[0m Trial 12 finished with value: 0.2241101688071822 and parameters: {'min_samples_split': 0.01911247020401219, 'criterion': 'friedman_mse', 'max_depth': 17}. Best is trial 3 with value: 0.22403157570587573.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,760]\u001b[0m Trial 13 finished with value: 0.23213429625198073 and parameters: {'min_samples_split': 0.13412050662353547, 'criterion': 'friedman_mse', 'max_depth': 20}. Best is trial 3 with value: 0.22403157570587573.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,792]\u001b[0m Trial 14 finished with value: 0.2405494222142496 and parameters: {'min_samples_split': 0.0057062126437142854, 'criterion': 'friedman_mse', 'max_depth': 16}. Best is trial 3 with value: 0.22403157570587573.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,808]\u001b[0m Trial 15 finished with value: 0.2442142842141522 and parameters: {'min_samples_split': 0.233072162208287, 'criterion': 'friedman_mse', 'max_depth': 18}. Best is trial 3 with value: 0.22403157570587573.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,823]\u001b[0m Trial 16 finished with value: 0.2827141767132929 and parameters: {'min_samples_split': 0.5900252963007938, 'criterion': 'friedman_mse', 'max_depth': 15}. Best is trial 3 with value: 0.22403157570587573.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,838]\u001b[0m Trial 17 finished with value: 0.2984974304504965 and parameters: {'min_samples_split': 0.9733747378501456, 'criterion': 'friedman_mse', 'max_depth': 14}. Best is trial 3 with value: 0.22403157570587573.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,855]\u001b[0m Trial 18 finished with value: 0.2518175367743838 and parameters: {'min_samples_split': 0.3440093168350663, 'criterion': 'friedman_mse', 'max_depth': 18}. Best is trial 3 with value: 0.22403157570587573.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,875]\u001b[0m Trial 19 finished with value: 0.22272892749177367 and parameters: {'min_samples_split': 0.0999554255245411, 'criterion': 'friedman_mse', 'max_depth': 20}. Best is trial 19 with value: 0.22272892749177367.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,896]\u001b[0m Trial 20 finished with value: 0.23213429625198073 and parameters: {'min_samples_split': 0.13640858621950125, 'criterion': 'friedman_mse', 'max_depth': 20}. Best is trial 19 with value: 0.22272892749177367.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,917]\u001b[0m Trial 21 finished with value: 0.21947201162984253 and parameters: {'min_samples_split': 0.07304353216429263, 'criterion': 'friedman_mse', 'max_depth': 18}. Best is trial 21 with value: 0.21947201162984253.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,933]\u001b[0m Trial 22 finished with value: 0.2518175367743838 and parameters: {'min_samples_split': 0.2950132478750302, 'criterion': 'friedman_mse', 'max_depth': 20}. Best is trial 21 with value: 0.21947201162984253.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,952]\u001b[0m Trial 23 finished with value: 0.22272892749177367 and parameters: {'min_samples_split': 0.09734904088409857, 'criterion': 'friedman_mse', 'max_depth': 14}. Best is trial 21 with value: 0.21947201162984253.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,972]\u001b[0m Trial 24 finished with value: 0.22164615698047463 and parameters: {'min_samples_split': 0.0820664390368425, 'criterion': 'friedman_mse', 'max_depth': 14}. Best is trial 21 with value: 0.21947201162984253.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:54,989]\u001b[0m Trial 25 finished with value: 0.23138675737803144 and parameters: {'min_samples_split': 0.18406633175248688, 'criterion': 'friedman_mse', 'max_depth': 14}. Best is trial 21 with value: 0.21947201162984253.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,017]\u001b[0m Trial 26 finished with value: 0.24053193897468256 and parameters: {'min_samples_split': 0.006796954307949951, 'criterion': 'friedman_mse', 'max_depth': 10}. Best is trial 21 with value: 0.21947201162984253.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,030]\u001b[0m Trial 27 finished with value: 0.2984974304504965 and parameters: {'min_samples_split': 0.7849548140825882, 'criterion': 'mse', 'max_depth': 13}. Best is trial 21 with value: 0.21947201162984253.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,043]\u001b[0m Trial 28 finished with value: 0.2776573521072824 and parameters: {'min_samples_split': 0.3996806770425594, 'criterion': 'friedman_mse', 'max_depth': 18}. Best is trial 21 with value: 0.21947201162984253.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,059]\u001b[0m Trial 29 finished with value: 0.2518175367743838 and parameters: {'min_samples_split': 0.26337087708751156, 'criterion': 'mse', 'max_depth': 19}. Best is trial 21 with value: 0.21947201162984253.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,075]\u001b[0m Trial 30 finished with value: 0.2827141767132929 and parameters: {'min_samples_split': 0.5464002882394413, 'criterion': 'friedman_mse', 'max_depth': 14}. Best is trial 21 with value: 0.21947201162984253.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,097]\u001b[0m Trial 31 finished with value: 0.22347945366223232 and parameters: {'min_samples_split': 0.08745597223682018, 'criterion': 'friedman_mse', 'max_depth': 15}. Best is trial 21 with value: 0.21947201162984253.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,116]\u001b[0m Trial 32 finished with value: 0.2301939639267372 and parameters: {'min_samples_split': 0.17283207625459718, 'criterion': 'friedman_mse', 'max_depth': 11}. Best is trial 21 with value: 0.21947201162984253.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,139]\u001b[0m Trial 33 finished with value: 0.217872837280309 and parameters: {'min_samples_split': 0.060589559266889685, 'criterion': 'friedman_mse', 'max_depth': 15}. Best is trial 33 with value: 0.217872837280309.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,168]\u001b[0m Trial 34 finished with value: 0.217872837280309 and parameters: {'min_samples_split': 0.06259942412511815, 'criterion': 'friedman_mse', 'max_depth': 15}. Best is trial 33 with value: 0.217872837280309.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,188]\u001b[0m Trial 35 finished with value: 0.23452873176177735 and parameters: {'min_samples_split': 0.19382093657417326, 'criterion': 'friedman_mse', 'max_depth': 16}. Best is trial 33 with value: 0.217872837280309.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,221]\u001b[0m Trial 36 finished with value: 0.21411272973681786 and parameters: {'min_samples_split': 0.055754915829485975, 'criterion': 'friedman_mse', 'max_depth': 17}. Best is trial 36 with value: 0.21411272973681786.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,251]\u001b[0m Trial 37 finished with value: 0.21589954024717523 and parameters: {'min_samples_split': 0.044861928100863216, 'criterion': 'friedman_mse', 'max_depth': 17}. Best is trial 36 with value: 0.21411272973681786.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,276]\u001b[0m Trial 38 finished with value: 0.21432756162893613 and parameters: {'min_samples_split': 0.03107002442035544, 'criterion': 'mse', 'max_depth': 17}. Best is trial 36 with value: 0.21411272973681786.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,295]\u001b[0m Trial 39 finished with value: 0.231292754021896 and parameters: {'min_samples_split': 0.144800362603337, 'criterion': 'mse', 'max_depth': 17}. Best is trial 36 with value: 0.21411272973681786.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,311]\u001b[0m Trial 40 finished with value: 0.24342450785511588 and parameters: {'min_samples_split': 0.22104653259637666, 'criterion': 'mse', 'max_depth': 17}. Best is trial 36 with value: 0.21411272973681786.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,334]\u001b[0m Trial 41 finished with value: 0.2116742018106415 and parameters: {'min_samples_split': 0.05283308451018334, 'criterion': 'mse', 'max_depth': 15}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,358]\u001b[0m Trial 42 finished with value: 0.21562695059010759 and parameters: {'min_samples_split': 0.037709698371163544, 'criterion': 'mse', 'max_depth': 19}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,380]\u001b[0m Trial 43 finished with value: 0.21562695059010759 and parameters: {'min_samples_split': 0.03809407425077073, 'criterion': 'mse', 'max_depth': 19}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,414]\u001b[0m Trial 44 finished with value: 0.2366758471374292 and parameters: {'min_samples_split': 0.0014375663034386504, 'criterion': 'mse', 'max_depth': 19}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,432]\u001b[0m Trial 45 finished with value: 0.2302207543656615 and parameters: {'min_samples_split': 0.1667525066550869, 'criterion': 'mse', 'max_depth': 19}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,455]\u001b[0m Trial 46 finished with value: 0.23457069336124417 and parameters: {'min_samples_split': 0.037291215122061, 'criterion': 'mse', 'max_depth': 3}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,474]\u001b[0m Trial 47 finished with value: 0.23213429625198073 and parameters: {'min_samples_split': 0.1365361106572514, 'criterion': 'mse', 'max_depth': 16}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,505]\u001b[0m Trial 48 finished with value: 0.23269211423496464 and parameters: {'min_samples_split': 0.008517712157693862, 'criterion': 'mse', 'max_depth': 18}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,539]\u001b[0m Trial 49 finished with value: 0.2366758471374292 and parameters: {'min_samples_split': 0.000921366718429753, 'criterion': 'mse', 'max_depth': 19}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,552]\u001b[0m Trial 50 finished with value: 0.2984974304504965 and parameters: {'min_samples_split': 0.7354473145673538, 'criterion': 'mse', 'max_depth': 8}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,575]\u001b[0m Trial 51 finished with value: 0.2116742018106415 and parameters: {'min_samples_split': 0.05218288151364216, 'criterion': 'mse', 'max_depth': 16}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,597]\u001b[0m Trial 52 finished with value: 0.22876582462101352 and parameters: {'min_samples_split': 0.12468440811371503, 'criterion': 'mse', 'max_depth': 16}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,623]\u001b[0m Trial 53 finished with value: 0.21351947910711394 and parameters: {'min_samples_split': 0.042348882614435736, 'criterion': 'mse', 'max_depth': 17}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,643]\u001b[0m Trial 54 finished with value: 0.22403157570587573 and parameters: {'min_samples_split': 0.10894731362607528, 'criterion': 'mse', 'max_depth': 17}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,661]\u001b[0m Trial 55 finished with value: 0.2384312107651132 and parameters: {'min_samples_split': 0.20685796159164513, 'criterion': 'mse', 'max_depth': 5}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,684]\u001b[0m Trial 56 finished with value: 0.21387144345782225 and parameters: {'min_samples_split': 0.047504803432713294, 'criterion': 'mse', 'max_depth': 13}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,702]\u001b[0m Trial 57 finished with value: 0.24852527946429437 and parameters: {'min_samples_split': 0.24423532673781523, 'criterion': 'mse', 'max_depth': 13}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,721]\u001b[0m Trial 58 finished with value: 0.2354502147354278 and parameters: {'min_samples_split': 0.15718173229785595, 'criterion': 'mse', 'max_depth': 13}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,743]\u001b[0m Trial 59 finished with value: 0.22272892749177367 and parameters: {'min_samples_split': 0.09638197910384155, 'criterion': 'mse', 'max_depth': 12}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,760]\u001b[0m Trial 60 finished with value: 0.2518175367743838 and parameters: {'min_samples_split': 0.28147829474725405, 'criterion': 'mse', 'max_depth': 15}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,784]\u001b[0m Trial 61 finished with value: 0.21444984445495718 and parameters: {'min_samples_split': 0.04059772471157025, 'criterion': 'mse', 'max_depth': 16}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,827]\u001b[0m Trial 62 finished with value: 0.2327825924800351 and parameters: {'min_samples_split': 0.0013776610027368547, 'criterion': 'mse', 'max_depth': 16}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,849]\u001b[0m Trial 63 finished with value: 0.2164467631278305 and parameters: {'min_samples_split': 0.06224096928509055, 'criterion': 'mse', 'max_depth': 16}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,874]\u001b[0m Trial 64 finished with value: 0.22774498264072157 and parameters: {'min_samples_split': 0.11562959281290179, 'criterion': 'mse', 'max_depth': 15}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,899]\u001b[0m Trial 65 finished with value: 0.21874395273419267 and parameters: {'min_samples_split': 0.03954922316911814, 'criterion': 'mse', 'max_depth': 18}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,923]\u001b[0m Trial 66 finished with value: 0.2197136508326502 and parameters: {'min_samples_split': 0.07485650982875847, 'criterion': 'mse', 'max_depth': 17}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,954]\u001b[0m Trial 67 finished with value: 0.23779722446960977 and parameters: {'min_samples_split': 0.00027173040384541325, 'criterion': 'mse', 'max_depth': 13}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,976]\u001b[0m Trial 68 finished with value: 0.22403157570587573 and parameters: {'min_samples_split': 0.11134317545077634, 'criterion': 'mse', 'max_depth': 15}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:55,993]\u001b[0m Trial 69 finished with value: 0.2518175367743838 and parameters: {'min_samples_split': 0.3303075234491421, 'criterion': 'mse', 'max_depth': 14}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,007]\u001b[0m Trial 70 finished with value: 0.2827141767132929 and parameters: {'min_samples_split': 0.46624116571985497, 'criterion': 'mse', 'max_depth': 12}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,032]\u001b[0m Trial 71 finished with value: 0.21916064598316248 and parameters: {'min_samples_split': 0.028822087349576715, 'criterion': 'mse', 'max_depth': 17}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,054]\u001b[0m Trial 72 finished with value: 0.2169073011552353 and parameters: {'min_samples_split': 0.06469434501525514, 'criterion': 'mse', 'max_depth': 18}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,079]\u001b[0m Trial 73 finished with value: 0.21562695059010759 and parameters: {'min_samples_split': 0.0373939144097348, 'criterion': 'mse', 'max_depth': 11}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,101]\u001b[0m Trial 74 finished with value: 0.2221183156652018 and parameters: {'min_samples_split': 0.08458823128672996, 'criterion': 'mse', 'max_depth': 20}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,119]\u001b[0m Trial 75 finished with value: 0.23412739315880424 and parameters: {'min_samples_split': 0.14808131073578196, 'criterion': 'mse', 'max_depth': 11}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,133]\u001b[0m Trial 76 finished with value: 0.2984974304504965 and parameters: {'min_samples_split': 0.9835560931443234, 'criterion': 'mse', 'max_depth': 10}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,160]\u001b[0m Trial 77 finished with value: 0.22065869205868377 and parameters: {'min_samples_split': 0.022636725397242992, 'criterion': 'mse', 'max_depth': 17}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,184]\u001b[0m Trial 78 finished with value: 0.21175992841269375 and parameters: {'min_samples_split': 0.04954945662245126, 'criterion': 'mse', 'max_depth': 16}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,203]\u001b[0m Trial 79 finished with value: 0.23138675737803144 and parameters: {'min_samples_split': 0.18392065010354147, 'criterion': 'mse', 'max_depth': 16}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,226]\u001b[0m Trial 80 finished with value: 0.2164467631278305 and parameters: {'min_samples_split': 0.060551213824574755, 'criterion': 'mse', 'max_depth': 14}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,248]\u001b[0m Trial 81 finished with value: 0.22272892749177367 and parameters: {'min_samples_split': 0.09587177574603466, 'criterion': 'mse', 'max_depth': 18}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,269]\u001b[0m Trial 82 finished with value: 0.21346528431867678 and parameters: {'min_samples_split': 0.04648426107812173, 'criterion': 'mse', 'max_depth': 16}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,301]\u001b[0m Trial 83 finished with value: 0.2327825924800351 and parameters: {'min_samples_split': 0.001259790964514132, 'criterion': 'mse', 'max_depth': 16}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,320]\u001b[0m Trial 84 finished with value: 0.22911962838636127 and parameters: {'min_samples_split': 0.1238330452041379, 'criterion': 'mse', 'max_depth': 15}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,333]\u001b[0m Trial 85 finished with value: 0.2984974304504965 and parameters: {'min_samples_split': 0.8810471724421394, 'criterion': 'mse', 'max_depth': 17}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,355]\u001b[0m Trial 86 finished with value: 0.215140439875334 and parameters: {'min_samples_split': 0.05791224503720803, 'criterion': 'mse', 'max_depth': 15}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,381]\u001b[0m Trial 87 finished with value: 0.21949836407203688 and parameters: {'min_samples_split': 0.019081002476417863, 'criterion': 'mse', 'max_depth': 16}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,402]\u001b[0m Trial 88 finished with value: 0.22272892749177367 and parameters: {'min_samples_split': 0.09470002226584054, 'criterion': 'mse', 'max_depth': 17}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,425]\u001b[0m Trial 89 finished with value: 0.21928823539404552 and parameters: {'min_samples_split': 0.07752128874498818, 'criterion': 'mse', 'max_depth': 15}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,444]\u001b[0m Trial 90 finished with value: 0.23176969747891368 and parameters: {'min_samples_split': 0.14633308397614092, 'criterion': 'mse', 'max_depth': 16}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,468]\u001b[0m Trial 91 finished with value: 0.2116742018106415 and parameters: {'min_samples_split': 0.05145396871254857, 'criterion': 'mse', 'max_depth': 14}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,492]\u001b[0m Trial 92 finished with value: 0.21175992841269375 and parameters: {'min_samples_split': 0.04996268767364102, 'criterion': 'mse', 'max_depth': 14}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,518]\u001b[0m Trial 93 finished with value: 0.22349850154252152 and parameters: {'min_samples_split': 0.02017434790480329, 'criterion': 'mse', 'max_depth': 14}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,540]\u001b[0m Trial 94 finished with value: 0.2164467631278305 and parameters: {'min_samples_split': 0.05913649603771145, 'criterion': 'mse', 'max_depth': 13}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,559]\u001b[0m Trial 95 finished with value: 0.22774498264072157 and parameters: {'min_samples_split': 0.11567579500419098, 'criterion': 'mse', 'max_depth': 14}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,581]\u001b[0m Trial 96 finished with value: 0.22164615698047463 and parameters: {'min_samples_split': 0.0810973417198392, 'criterion': 'mse', 'max_depth': 14}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,605]\u001b[0m Trial 97 finished with value: 0.21394610735542252 and parameters: {'min_samples_split': 0.0482738062112811, 'criterion': 'mse', 'max_depth': 15}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,625]\u001b[0m Trial 98 finished with value: 0.2302207543656615 and parameters: {'min_samples_split': 0.16537058046756206, 'criterion': 'mse', 'max_depth': 15}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 18:56:56,646]\u001b[0m Trial 99 finished with value: 0.22952427772156203 and parameters: {'min_samples_split': 0.13009072263086532, 'criterion': 'mse', 'max_depth': 13}. Best is trial 41 with value: 0.2116742018106415.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#3.5.1 Decission trees\n",
    "np.random.seed(random_state)\n",
    "def tree_objective(trial):\n",
    "    min_samples_split = trial.suggest_uniform('min_samples_split', 0+sys.float_info.min, 1)\n",
    "    criterion = trial.suggest_categorical('criterion', ['mse','friedman_mse'])\n",
    "    max_depth = trial.suggest_int('max_depth', min_max_depth, max_max_depth)\n",
    "\n",
    "    clf = tree.DecisionTreeRegressor(\n",
    "        random_state=random_state,\n",
    "        min_samples_split=min_samples_split,\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth)\n",
    "\n",
    "    scores = -model_selection.cross_val_score(clf, x_train, y_train,\n",
    "        cv=cv_grid,\n",
    "        verbose=verbose,\n",
    "        scoring='neg_root_mean_squared_error')\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "tree_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "tree_optuna.optimize(tree_objective, n_trials=budget)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['tree'] = summary['tree'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': tree_optuna.best_value,\n",
    "    'Min. samples split': tree_optuna.best_params['min_samples_split'], \n",
    "    'Criterion': tree_optuna.best_params['criterion'], \n",
    "    'Max. depth': tree_optuna.best_params['max_depth']\n",
    "    },\n",
    "    name='optuna'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-12-21 19:09:53,606]\u001b[0m A new study created in memory with name: no-name-884d50f3-199d-4e22-b220-c22de1e9a4b7\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:53,718]\u001b[0m Trial 0 finished with value: 0.18251608100710465 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'p': 1}. Best is trial 0 with value: 0.18251608100710465.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:53,815]\u001b[0m Trial 1 finished with value: 0.19095741162861635 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'p': 2}. Best is trial 0 with value: 0.18251608100710465.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:53,898]\u001b[0m Trial 2 finished with value: 0.1794445718169178 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'p': 1}. Best is trial 2 with value: 0.1794445718169178.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:53,982]\u001b[0m Trial 3 finished with value: 0.17823769926145944 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'p': 1}. Best is trial 3 with value: 0.17823769926145944.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:54,065]\u001b[0m Trial 4 finished with value: 0.19246038581091535 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'p': 2}. Best is trial 3 with value: 0.17823769926145944.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:54,144]\u001b[0m Trial 5 finished with value: 0.21270088687648767 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'p': 2}. Best is trial 3 with value: 0.17823769926145944.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:54,228]\u001b[0m Trial 6 finished with value: 0.18325398831829404 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'p': 1}. Best is trial 3 with value: 0.17823769926145944.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:54,311]\u001b[0m Trial 7 finished with value: 0.19299005332382413 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'p': 2}. Best is trial 3 with value: 0.17823769926145944.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:54,392]\u001b[0m Trial 8 finished with value: 0.19001786963376283 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'p': 2}. Best is trial 3 with value: 0.17823769926145944.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:54,469]\u001b[0m Trial 9 finished with value: 0.24086693186472402 and parameters: {'n_neighbors': 1, 'weights': 'uniform', 'p': 2}. Best is trial 3 with value: 0.17823769926145944.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:54,556]\u001b[0m Trial 10 finished with value: 0.18357592746399404 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'p': 1}. Best is trial 3 with value: 0.17823769926145944.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:54,643]\u001b[0m Trial 11 finished with value: 0.17716491260735712 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'p': 1}. Best is trial 11 with value: 0.17716491260735712.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:54,730]\u001b[0m Trial 12 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:54,816]\u001b[0m Trial 13 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:54,900]\u001b[0m Trial 14 finished with value: 0.17802457109008007 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:54,986]\u001b[0m Trial 15 finished with value: 0.17802457109008007 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:55,073]\u001b[0m Trial 16 finished with value: 0.18146539030727066 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:55,162]\u001b[0m Trial 17 finished with value: 0.17805683830594643 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:55,246]\u001b[0m Trial 18 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:55,330]\u001b[0m Trial 19 finished with value: 0.17750283764844682 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:55,417]\u001b[0m Trial 20 finished with value: 0.17805683830594643 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:55,503]\u001b[0m Trial 21 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:55,588]\u001b[0m Trial 22 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:55,672]\u001b[0m Trial 23 finished with value: 0.17716491260735712 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:55,756]\u001b[0m Trial 24 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:55,858]\u001b[0m Trial 25 finished with value: 0.17932124355660986 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:56,006]\u001b[0m Trial 26 finished with value: 0.17823769926145944 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:56,121]\u001b[0m Trial 27 finished with value: 0.17802457109008007 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:56,218]\u001b[0m Trial 28 finished with value: 0.17823769926145944 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:56,314]\u001b[0m Trial 29 finished with value: 0.17932124355660986 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:56,411]\u001b[0m Trial 30 finished with value: 0.17835671142266468 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:56,536]\u001b[0m Trial 31 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:56,661]\u001b[0m Trial 32 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:56,761]\u001b[0m Trial 33 finished with value: 0.17805683830594643 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:56,882]\u001b[0m Trial 34 finished with value: 0.17716491260735712 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:56,993]\u001b[0m Trial 35 finished with value: 0.17750283764844682 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:57,095]\u001b[0m Trial 36 finished with value: 0.17932124355660986 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:57,186]\u001b[0m Trial 37 finished with value: 0.18026857327711138 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:57,276]\u001b[0m Trial 38 finished with value: 0.1903485792800921 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'p': 2}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:57,372]\u001b[0m Trial 39 finished with value: 0.18084242424675906 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:57,462]\u001b[0m Trial 40 finished with value: 0.17835671142266468 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:57,554]\u001b[0m Trial 41 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:57,646]\u001b[0m Trial 42 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:57,742]\u001b[0m Trial 43 finished with value: 0.17716491260735712 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:57,835]\u001b[0m Trial 44 finished with value: 0.1887479278641862 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 2}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:57,924]\u001b[0m Trial 45 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:58,019]\u001b[0m Trial 46 finished with value: 0.17716491260735712 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:58,107]\u001b[0m Trial 47 finished with value: 0.18026857327711138 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:58,196]\u001b[0m Trial 48 finished with value: 0.1881902936338325 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'p': 2}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:58,287]\u001b[0m Trial 49 finished with value: 0.17716491260735712 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:58,376]\u001b[0m Trial 50 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:58,469]\u001b[0m Trial 51 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:58,560]\u001b[0m Trial 52 finished with value: 0.17802457109008007 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:58,654]\u001b[0m Trial 53 finished with value: 0.17805683830594643 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:58,745]\u001b[0m Trial 54 finished with value: 0.17802457109008007 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:58,838]\u001b[0m Trial 55 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:58,926]\u001b[0m Trial 56 finished with value: 0.17716491260735712 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:59,022]\u001b[0m Trial 57 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:59,116]\u001b[0m Trial 58 finished with value: 0.17750283764844682 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:59,207]\u001b[0m Trial 59 finished with value: 0.17802457109008007 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:59,301]\u001b[0m Trial 60 finished with value: 0.18026857327711138 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:59,388]\u001b[0m Trial 61 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:59,480]\u001b[0m Trial 62 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:59,569]\u001b[0m Trial 63 finished with value: 0.17716491260735712 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:59,657]\u001b[0m Trial 64 finished with value: 0.17805683830594643 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:59,755]\u001b[0m Trial 65 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:59,852]\u001b[0m Trial 66 finished with value: 0.17802457109008007 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:09:59,941]\u001b[0m Trial 67 finished with value: 0.17823769926145944 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:00,035]\u001b[0m Trial 68 finished with value: 0.17716491260735712 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:00,122]\u001b[0m Trial 69 finished with value: 0.1903485792800921 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'p': 2}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:00,211]\u001b[0m Trial 70 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:00,301]\u001b[0m Trial 71 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:00,396]\u001b[0m Trial 72 finished with value: 0.17802457109008007 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:00,492]\u001b[0m Trial 73 finished with value: 0.17805683830594643 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:00,586]\u001b[0m Trial 74 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:00,677]\u001b[0m Trial 75 finished with value: 0.17716491260735712 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:00,769]\u001b[0m Trial 76 finished with value: 0.17802457109008007 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:00,860]\u001b[0m Trial 77 finished with value: 0.17716491260735712 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:00,955]\u001b[0m Trial 78 finished with value: 0.17750283764844682 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:01,048]\u001b[0m Trial 79 finished with value: 0.17823769926145944 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:01,136]\u001b[0m Trial 80 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:01,226]\u001b[0m Trial 81 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:01,318]\u001b[0m Trial 82 finished with value: 0.17802457109008007 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:01,405]\u001b[0m Trial 83 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:01,494]\u001b[0m Trial 84 finished with value: 0.17716491260735712 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:01,585]\u001b[0m Trial 85 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:01,673]\u001b[0m Trial 86 finished with value: 0.1794105730305509 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:01,764]\u001b[0m Trial 87 finished with value: 0.18357592746399404 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:01,854]\u001b[0m Trial 88 finished with value: 0.17802457109008007 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:01,938]\u001b[0m Trial 89 finished with value: 0.1881902936338325 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'p': 2}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:02,026]\u001b[0m Trial 90 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:02,118]\u001b[0m Trial 91 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:02,205]\u001b[0m Trial 92 finished with value: 0.17802457109008007 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:02,295]\u001b[0m Trial 93 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:02,386]\u001b[0m Trial 94 finished with value: 0.17716491260735712 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:02,473]\u001b[0m Trial 95 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:02,561]\u001b[0m Trial 96 finished with value: 0.17823769926145944 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:02,651]\u001b[0m Trial 97 finished with value: 0.17716491260735712 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:02,739]\u001b[0m Trial 98 finished with value: 0.17802457109008007 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n",
      "\u001b[32m[I 2020-12-21 19:10:02,829]\u001b[0m Trial 99 finished with value: 0.17708635867485897 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 12 with value: 0.17708635867485897.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#3.5.2 K Nearest Neighbours\n",
    "np.random.seed(random_state)\n",
    "def knn_objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', min_n_neigbors, max_n_neigbors)\n",
    "    weights = trial.suggest_categorical('weights', ['uniform','distance'])\n",
    "    p = trial.suggest_categorical('p', [1, 2])\n",
    "\n",
    "    clf = neighbors.KNeighborsRegressor(\n",
    "        n_neighbors=n_neighbors,\n",
    "        weights=weights,\n",
    "        p=p)\n",
    "\n",
    "    scores = -model_selection.cross_val_score(clf, x_train, y_train,\n",
    "        cv=cv_grid,\n",
    "        verbose=verbose,\n",
    "        scoring='neg_root_mean_squared_error')\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "knn_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "knn_optuna.optimize(knn_objective, n_trials=budget)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['knn'] = summary['knn'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': knn_optuna.best_value, \n",
    "    'N. neighbors': knn_optuna.best_params['n_neighbors'], \n",
    "    'Weights': knn_optuna.best_params['weights'], \n",
    "    'P': knn_optuna.best_params['p']\n",
    "    }, \n",
    "    name='optuna'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will try to sum up our results. \n",
    "\n",
    "The next cell outputs all the information given to us by the models, the best values for each hyper-parameter, time needed to train the model, and RMSE score for each hyper-parameter method used.\n",
    "\n",
    "From this dataframe we can draw some interesting conclusions. Clearly, hyper-parameter tuning improves the models performance for both KNN and decision trees by at least 0.014385 and 0.025002 for each model respectively.    \n",
    "The best hyper-parameter method judging by the given scores is the one given by skopt for decision trees and the one given by optuna for KNearestNeighbors respectively.   \n",
    "However, the fastest hyper-parameter tuning method (excluding setting hyper-parameters by default which isn't really tuning) is random search for decision trees and optuna for KNN. So for KNN optuna yields the best score in the least time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUMMARY FOR DECISSION TREE MODELS\n",
      "              Time (sec)  Score (RMSE) Min. samples split     Criterion  \\\n",
      "default                0      0.236676                  2           mse   \n",
      "random_search     1.1164      0.215140          0.0580292  friedman_mse   \n",
      "skopt           399.1219      0.211516          0.0529852           mse   \n",
      "optuna            2.1498      0.211674          0.0528331           mse   \n",
      "\n",
      "              Max. depth  \n",
      "default             None  \n",
      "random_search          9  \n",
      "skopt                 19  \n",
      "optuna                15  \n",
      "\n",
      "SUMMARY FOR K NEAREST NEIGHBORS MODELS\n",
      "              Time (sec)  Score (RMSE) N. neighbors   Weights  P\n",
      "default                0      0.191550            5   uniform  2\n",
      "random_search    13.7176      0.177165            6  distance  1\n",
      "skopt           425.5685      0.177087            7  distance  1\n",
      "optuna            9.2219      0.177086            7  distance  1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSUMMARY FOR DECISSION TREE MODELS\")\n",
    "print(summary['tree'])\n",
    "print(\"\\nSUMMARY FOR K NEAREST NEIGHBORS MODELS\")\n",
    "print(summary['knn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The following cell locates from within our summary dataframe the model that has obtained the best RMSE score for both decision tree models and KNN models.   \n",
    "\n",
    "The output tells us that **the best model according to the inner evaluation is the one given by KNN tuned by means of optuna**. If we contrast this information with the previous' cell output we can verify that this model has a score of 0.177086 which is a big improvement compared to the decision tree model tuned by optuna that receives a score of 0.211674."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The best model is K Nearest Neighbors Regressor with optuna\n"
     ]
    }
   ],
   "source": [
    "###3.6 Determine the best model from its inner evaluation\n",
    "best_tree_model = summary['tree']['Score (RMSE)'].idxmin()\n",
    "best_knn_model = summary['knn']['Score (RMSE)'].idxmin()\n",
    "\n",
    "if summary['tree'].loc[best_tree_model]['Score (RMSE)'] < summary['knn'].loc[best_knn_model]['Score (RMSE)']:\n",
    "    print('\\n--> The best model is Decision Tree Regressor with {}'.format(best_tree_model))\n",
    "    best_model = tree.DecisionTreeRegressor(\n",
    "        random_state=random_state,\n",
    "        min_samples_split=summary['tree'].loc[best_tree_model]['Min. samples split'] ,\n",
    "        criterion=summary['tree'].loc[best_tree_model]['Criterion'],\n",
    "        max_depth=summary['tree'].loc[best_tree_model]['Max. depth'])\n",
    "else:\n",
    "    print('\\nThe best model is K Nearest Neighbors Regressor with {}'.format(best_knn_model))\n",
    "    best_model = neighbors.KNeighborsRegressor(\n",
    "        n_neighbors=summary['knn'].loc[best_knn_model]['N. neighbors'] ,\n",
    "        weights=summary['knn'].loc[best_knn_model]['Weights'],\n",
    "        p=summary['knn'].loc[best_knn_model]['P'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, taking this best model **we make an estimation of the performance we would get at the competition**. To do this, we evaluate the KNN optuna model on the test matrices, *X_test* and *y_test*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model performance at competition:\n",
      "RMSE: 0.1620 (should be lower than the trivial predictor using the mean MSE: 0.3856)\n",
      "R square: 0.8234 (should be higher than the trivial predictor using the mean: R square 0.0000)\n"
     ]
    }
   ],
   "source": [
    "###3.7 Performance estimation\n",
    "best_model.fit(x_train, y_train)\n",
    "best_model_predict = best_model.predict(x_test)\n",
    "print('\\nBest Model performance at competition:')\n",
    "print('RMSE: {:.4f} (should be lower than the trivial predictor using the mean MSE: {:.4f})'.format(\n",
    "    math.sqrt(metrics.mean_squared_error(y_test, best_model_predict)),\n",
    "    math.sqrt(metrics.mean_squared_error(y_test, [y_test.mean() for i in range(len(y_test))]))))\n",
    "print('R square: {:.4f} (should be higher than the trivial predictor using the mean: R square {:.4f})'.format(\n",
    "    metrics.r2_score(y_test, best_model_predict),\n",
    "    metrics.r2_score(y_test, [y_test.mean() for i in range(len(y_test))])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we train the best model (KNN with optuna) on the whole available dataset (x, y) and make predictions on the competition matrix *x_comp*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.8 Final model train\n",
    "best_model.fit(x, y)\n",
    "y_comp = [math.exp(i) for i in best_model.predict(x_comp)]\n",
    "\n",
    "submission = pd.DataFrame(columns=['Id', 'SalePrice'])\n",
    "submission['Id'] = pd.Series(range(1461, 2920))\n",
    "submission['SalePrice'] = pd.Series(y_comp)\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
