{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wind prediction - Second assignment\n",
    "\n",
    "## Authors\n",
    "\n",
    "David Moreno Maldonado 100441714     \n",
    "Inés Fernández Campos 100443936"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/roni/Desktop/master/2nd quarter/big data intelligence/assignments/assignment_2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import some libraries\n",
    "import os\n",
    "import numpy as np              \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn import preprocessing, impute, model_selection, metrics, neighbors, ensemble, feature_selection\n",
    "from sklearn.pipeline import Pipeline\n",
    "import optuna\n",
    "import optuna.visualization as ov\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN PARAMETERS FOR THE ASSIGNMENT\n",
    "budget = 20\n",
    "random_state = 3\n",
    "verbose = 0\n",
    "n_jobs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"wind_pickle\" file contains data in a binary format called \"Pickle\". Pickle data loads faster than text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle('wind_pickle.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the attributes in the dataset. Very important, the output attribute (i.e. the value to be predicted, **energy**, is the first attribute). **Steps** represents the hours in advance of the forecast. We will not use this variable here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5937, 556)\n"
     ]
    }
   ],
   "source": [
    "# The dataset contains 5937 instances and 556 attributes (including the outcome to be predicted)\n",
    "print(data.shape)\n",
    "#data.columns.values.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-1 for training, 0 for validation, 1 for testing\n",
    "year_to_part = {\n",
    "    2005: -1,\n",
    "    2006: -1,\n",
    "    2007: 0,\n",
    "    2008: 0, \n",
    "    2009: 1,\n",
    "    2010: 1\n",
    "}\n",
    "data['partition'] = data['year'].apply(lambda x: year_to_part[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now remove the columns that cannot be used for training the models from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps, month, day, hour, year should be removed, they cannot be used for training the models\n",
    "to_remove = ['steps', 'month', 'year', 'day', 'hour']\n",
    "for m in to_remove: data = data.drop(m, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets put 163861 missing values \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import randint\n",
    "\n",
    "# we add na values at random\n",
    "my_NIA = 100443936 + 100441714\n",
    "np.random.seed(my_NIA)\n",
    "\n",
    "how_many_nas = round(data.shape[0]*data.shape[1]*0.05)\n",
    "print('Lets put '+str(how_many_nas)+' missing values \\n')\n",
    "x_locations = randint(0, data.shape[0], size=how_many_nas)\n",
    "y_locations = randint(1, data.shape[1]-2, size=how_many_nas)\n",
    "\n",
    "for i in range(len(x_locations)):\n",
    "    data.iat[x_locations[i], y_locations[i]] = np.nan\n",
    "    \n",
    "data.to_pickle('wind_pickle_with_nan.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point on, the file wind_pickle_with_nan should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5937, 552)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('wind_pickle_with_nan.pickle')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().values.any())\n",
    "input_cols = data.columns.difference(['energy', 'partition'])\n",
    "x = data[input_cols]\n",
    "#Iterative imputer (takes too long)\n",
    "'''iter_imp = impute.IterativeImputer(random_state=random_state, \n",
    "                                   initial_strategy='median', \n",
    "                                   max_iter=3,\n",
    "                                   verbose=verbose)\n",
    "no_nan = iter_imp.fit_transform(x)'''\n",
    "\n",
    "#KNN imputer(takes too long)\n",
    "'''knn_imp = impute.KNNImputer(weights='distance')\n",
    "no_nan = knn_imp.fit_transform(x)'''\n",
    "\n",
    "#Simple imputer\n",
    "simp_imp = impute.SimpleImputer(strategy='median',\n",
    "                               verbose=2)\n",
    "no_nan = simp_imp.fit_transform(x)\n",
    "\n",
    "data[input_cols] = pd.DataFrame(data=no_nan)\n",
    "print(data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(data[input_cols]) \n",
    "data[input_cols] = scaler.transform(data[input_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split\n",
    "We are going to use train/test for model evaluation (outer) and train/validation for hyperparameter tuning (inner), as follows:     \n",
    "1. Train partition: the first two years of data. Given that there are 6 years worth of data, we will use the first 2/6 of the instances for training.     \n",
    "2. Validation partition: the second two years of data. \n",
    "3. Test partition: the remaining data    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-1 for training, 0 for validation, 1 for testing\n",
    "test = data[data['partition'] == 1]\n",
    "train = data[data['partition'] == -1]\n",
    "val = data[data['partition'] == 0]\n",
    "\n",
    "del test['partition']\n",
    "del train['partition']\n",
    "\n",
    "y_test = test['energy']\n",
    "x_test = test[test.columns.difference(['energy'])]\n",
    "\n",
    "y_train = train['energy']\n",
    "x_train = train[train.columns.difference(['energy'])]\n",
    "\n",
    "\n",
    "y_val = val['energy']\n",
    "x_val = val[train.columns.difference(['energy'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MODEL SELECTION AND HYPER-PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframes with all the information of each model\n",
    "summary = {\n",
    "    'knn': pd.DataFrame(columns=['Time (sec)', 'Score (RMSE)', 'N. neighbors', 'Weights', 'P']),\n",
    "    'random_forest': pd.DataFrame(columns=['Time (sec)', 'Score (RMSE)', 'Min. samples split', 'Criterion', 'Max. depth', 'N. estimators','Max. features']),\n",
    "    'gradient_boosting': pd.DataFrame(columns=['Time (sec)', 'Score (RMSE)'])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Default hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_state)\n",
    "knn_default = neighbors.KNeighborsRegressor()\n",
    "\n",
    "start_time = time.time()\n",
    "scores = -model_selection.cross_val_score(knn_default, x_train, y_train,\n",
    "                                          scoring='neg_root_mean_squared_error',\n",
    "                                          cv=tr_val_partition,\n",
    "                                          verbose=verbose) \n",
    "start_time = time.time()\n",
    "knn_default = knn_default.fit(x_train, y_train)\n",
    "y_val_pred = knn_default.predict(x_val)\n",
    "score = math.sqrt(metrics.mean_squared_error(y_val, y_val_pred))\n",
    "end_time = time.time()\n",
    "\n",
    "summary['knn'] = summary['knn'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': score, \n",
    "    'N. neighbors': 5, \n",
    "    'Weights': 'uniform', \n",
    "    'P': 2\n",
    "    }, \n",
    "    name='default'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Hyper-parameter tunning (OPTUNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_n_neigbors = 1\n",
    "max_n_neigbors = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-13 09:42:49,538]\u001b[0m A new study created in memory with name: no-name-a8bca65c-cfc6-4259-bafe-8f395c6645e4\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:42:49,635]\u001b[0m Trial 0 finished with value: 435.96737369410965 and parameters: {'n_neighbors': 16, 'weights': 'uniform', 'p': 2}. Best is trial 0 with value: 435.96737369410965.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:42:51,987]\u001b[0m Trial 1 finished with value: 437.64527002872245 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'p': 1}. Best is trial 0 with value: 435.96737369410965.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:42:52,075]\u001b[0m Trial 2 finished with value: 438.83757546832885 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'p': 2}. Best is trial 0 with value: 435.96737369410965.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:42:54,402]\u001b[0m Trial 3 finished with value: 426.6970286295103 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'p': 1}. Best is trial 3 with value: 426.6970286295103.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:42:54,479]\u001b[0m Trial 4 finished with value: 512.2161694249993 and parameters: {'n_neighbors': 2, 'weights': 'uniform', 'p': 2}. Best is trial 3 with value: 426.6970286295103.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:42:54,566]\u001b[0m Trial 5 finished with value: 474.4113498134497 and parameters: {'n_neighbors': 3, 'weights': 'uniform', 'p': 2}. Best is trial 3 with value: 426.6970286295103.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:42:56,903]\u001b[0m Trial 6 finished with value: 437.64527002872245 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'p': 1}. Best is trial 3 with value: 426.6970286295103.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:42:59,345]\u001b[0m Trial 7 finished with value: 429.3973607287476 and parameters: {'n_neighbors': 14, 'weights': 'uniform', 'p': 1}. Best is trial 3 with value: 426.6970286295103.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:42:59,429]\u001b[0m Trial 8 finished with value: 435.01184629064824 and parameters: {'n_neighbors': 14, 'weights': 'uniform', 'p': 2}. Best is trial 3 with value: 426.6970286295103.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:42:59,517]\u001b[0m Trial 9 finished with value: 436.66754039946005 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'p': 2}. Best is trial 3 with value: 426.6970286295103.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:43:01,964]\u001b[0m Trial 10 finished with value: 424.95488026361073 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'p': 1}. Best is trial 10 with value: 424.95488026361073.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:43:04,348]\u001b[0m Trial 11 finished with value: 424.97500012000376 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'p': 1}. Best is trial 10 with value: 424.95488026361073.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:43:06,778]\u001b[0m Trial 12 finished with value: 424.95488026361073 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'p': 1}. Best is trial 10 with value: 424.95488026361073.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:43:09,204]\u001b[0m Trial 13 finished with value: 424.95488026361073 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'p': 1}. Best is trial 10 with value: 424.95488026361073.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:43:11,553]\u001b[0m Trial 14 finished with value: 425.19635407015437 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'p': 1}. Best is trial 10 with value: 424.95488026361073.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:43:13,897]\u001b[0m Trial 15 finished with value: 427.6511157945625 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'p': 1}. Best is trial 10 with value: 424.95488026361073.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:43:16,246]\u001b[0m Trial 16 finished with value: 432.080866275361 and parameters: {'n_neighbors': 7, 'weights': 'distance', 'p': 1}. Best is trial 10 with value: 424.95488026361073.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:43:18,588]\u001b[0m Trial 17 finished with value: 424.95488026361073 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'p': 1}. Best is trial 10 with value: 424.95488026361073.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:43:20,927]\u001b[0m Trial 18 finished with value: 425.19635407015437 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'p': 1}. Best is trial 10 with value: 424.95488026361073.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:43:23,267]\u001b[0m Trial 19 finished with value: 451.6020085952498 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'p': 1}. Best is trial 10 with value: 424.95488026361073.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(random_state)\n",
    "def knn_objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', min_n_neigbors, max_n_neigbors)\n",
    "    weights = trial.suggest_categorical('weights', ['uniform','distance'])\n",
    "    p = trial.suggest_categorical('p', [1, 2])\n",
    "\n",
    "    clf = neighbors.KNeighborsRegressor(\n",
    "        n_neighbors=n_neighbors,\n",
    "        weights=weights,\n",
    "        p=p)\n",
    "    \n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    y_val_pred = clf.predict(x_val)\n",
    "    return math.sqrt(metrics.mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "knn_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "knn_optuna.optimize(knn_objective, n_trials=budget)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['knn'] = summary['knn'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': knn_optuna.best_value, \n",
    "    'N. neighbors': knn_optuna.best_params['n_neighbors'], \n",
    "    'Weights': knn_optuna.best_params['weights'], \n",
    "    'P': knn_optuna.best_params['p']\n",
    "    }, \n",
    "    name='optuna'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Default hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_state)\n",
    "rf_default = ensemble.RandomForestRegressor(random_state=random_state, verbose=verbose, n_jobs=n_jobs)\n",
    "\n",
    "start_time = time.time()\n",
    "rf_default = rf_default.fit(x_train, y_train)\n",
    "y_val_pred = rf_default.predict(x_val)\n",
    "score =  math.sqrt(metrics.mean_squared_error(y_val, y_val_pred))\n",
    "end_time = time.time()\n",
    "\n",
    "summary['random_forest'] = summary['random_forest'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': scores.mean(),\n",
    "    'Min. samples split': 2, \n",
    "    'Criterion': 'mse', \n",
    "    'Max. depth': 'None',\n",
    "    'N. estimators': 100,\n",
    "    'Max. features': 1\n",
    "    },\n",
    "    name='default'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Hyper-parameter tunning (OPTUNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_depth = 2\n",
    "max_max_depth = 50\n",
    "min_n_estimators = 50\n",
    "max_n_estimators = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-13 11:39:52,943]\u001b[0m A new study created in memory with name: no-name-76fa9773-98e2-419b-b3e9-014342aa65b8\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:39:54,026]\u001b[0m Trial 0 finished with value: 417.3797320560538 and parameters: {'min_samples_split': 0.25350059739092334, 'criterion': 'mse', 'n_estimators': 157, 'max_features': 'log2'}. Best is trial 0 with value: 417.3797320560538.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:40:36,417]\u001b[0m Trial 1 finished with value: 698.9371249690789 and parameters: {'min_samples_split': 0.6408643943729035, 'criterion': 'mae', 'n_estimators': 193, 'max_features': 'auto'}. Best is trial 0 with value: 417.3797320560538.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:40:41,102]\u001b[0m Trial 2 finished with value: 531.076475910281 and parameters: {'min_samples_split': 0.6105777961377941, 'criterion': 'mse', 'n_estimators': 72, 'max_features': 'auto'}. Best is trial 0 with value: 417.3797320560538.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:40:42,455]\u001b[0m Trial 3 finished with value: 400.7199654855606 and parameters: {'min_samples_split': 0.22022245260875262, 'criterion': 'mse', 'n_estimators': 85, 'max_features': 'sqrt'}. Best is trial 3 with value: 400.7199654855606.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:41:12,444]\u001b[0m Trial 4 finished with value: 423.55708342870315 and parameters: {'min_samples_split': 0.25255861877068764, 'criterion': 'mae', 'n_estimators': 182, 'max_features': 'log2'}. Best is trial 3 with value: 400.7199654855606.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:41:12,612]\u001b[0m Trial 5 finished with value: 668.3460135053414 and parameters: {'min_samples_split': 0.9984816415133091, 'criterion': 'mse', 'n_estimators': 132, 'max_features': 'sqrt'}. Best is trial 3 with value: 400.7199654855606.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:41:12,819]\u001b[0m Trial 6 finished with value: 506.5877640968004 and parameters: {'min_samples_split': 0.5615620243120499, 'criterion': 'mse', 'n_estimators': 64, 'max_features': 'log2'}. Best is trial 3 with value: 400.7199654855606.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:41:12,918]\u001b[0m Trial 7 finished with value: 668.2624350357512 and parameters: {'min_samples_split': 0.7837327131274209, 'criterion': 'mse', 'n_estimators': 66, 'max_features': 'log2'}. Best is trial 3 with value: 400.7199654855606.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:41:14,045]\u001b[0m Trial 8 finished with value: 411.61277056639557 and parameters: {'min_samples_split': 0.14257239059086746, 'criterion': 'mse', 'n_estimators': 133, 'max_features': 'log2'}. Best is trial 3 with value: 400.7199654855606.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:41:14,230]\u001b[0m Trial 9 finished with value: 668.3493549783518 and parameters: {'min_samples_split': 0.7127372857957316, 'criterion': 'mse', 'n_estimators': 149, 'max_features': 'sqrt'}. Best is trial 3 with value: 400.7199654855606.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:42:11,055]\u001b[0m Trial 10 finished with value: 380.13690376405395 and parameters: {'min_samples_split': 0.025289321282742694, 'criterion': 'mae', 'n_estimators': 98, 'max_features': 'sqrt'}. Best is trial 10 with value: 380.13690376405395.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:43:10,693]\u001b[0m Trial 11 finished with value: 374.51337086490906 and parameters: {'min_samples_split': 0.002083901633246156, 'criterion': 'mae', 'n_estimators': 97, 'max_features': 'sqrt'}. Best is trial 11 with value: 374.51337086490906.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:44:10,157]\u001b[0m Trial 12 finished with value: 373.97700814917715 and parameters: {'min_samples_split': 0.007419815620190872, 'criterion': 'mae', 'n_estimators': 101, 'max_features': 'sqrt'}. Best is trial 12 with value: 373.97700814917715.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:45:09,904]\u001b[0m Trial 13 finished with value: 378.28039871974784 and parameters: {'min_samples_split': 0.017048532156431706, 'criterion': 'mae', 'n_estimators': 105, 'max_features': 'sqrt'}. Best is trial 12 with value: 373.97700814917715.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:45:42,140]\u001b[0m Trial 14 finished with value: 429.0483201288025 and parameters: {'min_samples_split': 0.41372170188422414, 'criterion': 'mae', 'n_estimators': 111, 'max_features': 'sqrt'}. Best is trial 12 with value: 373.97700814917715.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:46:33,044]\u001b[0m Trial 15 finished with value: 382.8949660476959 and parameters: {'min_samples_split': 0.037317747407758534, 'criterion': 'mae', 'n_estimators': 94, 'max_features': 'sqrt'}. Best is trial 12 with value: 373.97700814917715.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:47:07,542]\u001b[0m Trial 16 finished with value: 428.40101526002707 and parameters: {'min_samples_split': 0.4131875474701712, 'criterion': 'mae', 'n_estimators': 118, 'max_features': 'sqrt'}. Best is trial 12 with value: 373.97700814917715.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:56:35,955]\u001b[0m Trial 17 finished with value: 405.8668907599886 and parameters: {'min_samples_split': 0.11068795208257604, 'criterion': 'mae', 'n_estimators': 52, 'max_features': 'auto'}. Best is trial 12 with value: 373.97700814917715.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:57:04,630]\u001b[0m Trial 18 finished with value: 419.96220235666414 and parameters: {'min_samples_split': 0.3495601516878149, 'criterion': 'mae', 'n_estimators': 82, 'max_features': 'sqrt'}. Best is trial 12 with value: 373.97700814917715.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:57:04,770]\u001b[0m Trial 19 finished with value: 719.2893211778534 and parameters: {'min_samples_split': 0.9760763411739918, 'criterion': 'mae', 'n_estimators': 51, 'max_features': 'sqrt'}. Best is trial 12 with value: 373.97700814917715.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(random_state)\n",
    "def random_forest_objective(trial):\n",
    "    min_samples_split = trial.suggest_uniform('min_samples_split', 0+sys.float_info.min, 1)\n",
    "    criterion = trial.suggest_categorical('criterion', ['mse','mae'])\n",
    "    max_depth = trial.suggest_int('max_depth', min_max_depth, max_max_depth)\n",
    "    n_estimators = trial.suggest_int('n_estimators', min_n_estimators, max_n_estimators)\n",
    "    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2'])\n",
    "\n",
    "    clf = ensemble.RandomForestRegressor(\n",
    "        random_state=random_state,\n",
    "        min_samples_split=min_samples_split,\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        n_estimators=n_estimators,\n",
    "        max_features=max_features\n",
    "        )\n",
    "\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    y_val_pred = clf.predict(x_val)\n",
    "    return math.sqrt(metrics.mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "rf_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "rf_optuna.optimize(random_forest_objective, n_trials=budget, n_jobs=n_jobs)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['random_forest'] = summary['random_forest'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': rf_optuna.best_value,\n",
    "    'Min. samples split': rf_optuna.best_params['min_samples_split'], \n",
    "    'Criterion': rf_optuna.best_params['criterion'], \n",
    "    'Max. depth': rf_optuna.best_params['max_depth'],\n",
    "    'N. estimators': rf_optuna.best_params['n_estimators'],\n",
    "    'Max. features': rf_optuna.best_params['max_features']\n",
    "    },\n",
    "    name='optuna'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Default hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation using sklearn\n",
    "np.random.seed(random_state)\n",
    "gb_sk_def = ensemble.GradientBoostingRegressor(random_state=random_state, verbose=verbose)\n",
    "\n",
    "start_time = time.time()\n",
    "gb_sk_def = gb_sk_def.fit(x_train, y_train)\n",
    "y_val_pred = gb_sk_def.predict(x_val)\n",
    "score =  math.sqrt(metrics.mean_squared_error(y_val, y_val_pred))\n",
    "end_time = time.time()\n",
    "\n",
    "summary['gradient_boosting'] = summary['gradient_boosting'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': score,\n",
    "    'Learning rate': 0.1,\n",
    "    'N. estimators': 100,\n",
    "    'Criterion': 'friedman_mse', \n",
    "    'Min. samples split': 2, \n",
    "    'Min. samples leaf': 1,\n",
    "    'Max. depth': 3,\n",
    "    'Max. leaf nodes': 'None'\n",
    "    },\n",
    "    name='default'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation using xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(mat_x_train, label=mat_y_train)\n",
    "dtest = xgb.DMatrix(mat_x_test, label=mat_y_test)\n",
    "\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "start_time = time.time()\n",
    "model = model.fit(x_train, y_train)\n",
    "y_val_pred = model.predict(x_val)\n",
    "score = math.sqrt(metrics.mean_squared_error(y_val, y_val_pred))\n",
    "end_time = time.time()\n",
    "\n",
    "summary['gradient_boosting'] = summary['gradient_boosting'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': score,\n",
    "    'N. estimators': model.get_params()['n_estimators']\n",
    "    },\n",
    "    name='default'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Hyper-parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dir(dtrain))\n",
    "#print('\\n', dir(model))\n",
    "min_max_leaf_nodes = 2\n",
    "max_max_leaf_nodes = 20\n",
    "min_min_samples_leaf = 1\n",
    "max_min_samples_leaf = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-13 09:50:34,141]\u001b[0m A new study created in memory with name: no-name-b1d1519a-4e2a-4230-a1a2-75d2f55f5597\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:51:23,541]\u001b[0m Trial 0 finished with value: 516.1392210643189 and parameters: {'learning_rate': 0.924201322701786, 'n_estimators': 127, 'min_samples_split': 0.14264499434583455, 'max_depth': 4}. Best is trial 0 with value: 516.1392210643189.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:51:34,293]\u001b[0m Trial 1 finished with value: 397.64320467369106 and parameters: {'learning_rate': 0.24880511526807125, 'n_estimators': 90, 'min_samples_split': 0.992062606787323, 'max_depth': 19}. Best is trial 1 with value: 397.64320467369106.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:52:00,096]\u001b[0m Trial 2 finished with value: 380.711099231849 and parameters: {'learning_rate': 0.11769016943457755, 'n_estimators': 67, 'min_samples_split': 0.6939913120059997, 'max_depth': 12}. Best is trial 2 with value: 380.711099231849.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:52:19,810]\u001b[0m Trial 3 finished with value: 551.851565515354 and parameters: {'learning_rate': 0.005552163580898495, 'n_estimators': 183, 'min_samples_split': 0.9787214495925919, 'max_depth': 11}. Best is trial 2 with value: 380.711099231849.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:52:35,445]\u001b[0m Trial 4 finished with value: 468.22984899395163 and parameters: {'learning_rate': 0.772971817353759, 'n_estimators': 50, 'min_samples_split': 0.005409116125902336, 'max_depth': 3}. Best is trial 2 with value: 380.711099231849.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:54:35,613]\u001b[0m Trial 5 finished with value: 430.23119626144603 and parameters: {'learning_rate': 0.5209549619479861, 'n_estimators': 170, 'min_samples_split': 0.39702928351095723, 'max_depth': 9}. Best is trial 2 with value: 380.711099231849.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:54:59,386]\u001b[0m Trial 6 finished with value: 430.8503020853347 and parameters: {'learning_rate': 0.6532587638843672, 'n_estimators': 56, 'min_samples_split': 0.7358689381776073, 'max_depth': 8}. Best is trial 2 with value: 380.711099231849.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:56:11,413]\u001b[0m Trial 7 finished with value: 404.9912041441754 and parameters: {'learning_rate': 0.31899620915461735, 'n_estimators': 105, 'min_samples_split': 0.5601462351951706, 'max_depth': 11}. Best is trial 2 with value: 380.711099231849.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:56:26,779]\u001b[0m Trial 8 finished with value: 414.76348038490414 and parameters: {'learning_rate': 0.606239487860107, 'n_estimators': 85, 'min_samples_split': 0.929138108667801, 'max_depth': 8}. Best is trial 2 with value: 380.711099231849.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:57:05,572]\u001b[0m Trial 9 finished with value: 386.6876182981709 and parameters: {'learning_rate': 0.14529574955653302, 'n_estimators': 115, 'min_samples_split': 0.7545109333952302, 'max_depth': 9}. Best is trial 2 with value: 380.711099231849.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 09:58:56,168]\u001b[0m Trial 10 finished with value: 374.6853371613855 and parameters: {'learning_rate': 0.031102481071261276, 'n_estimators': 143, 'min_samples_split': 0.3169660991254603, 'max_depth': 17}. Best is trial 10 with value: 374.6853371613855.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:00:47,718]\u001b[0m Trial 11 finished with value: 375.74104506468905 and parameters: {'learning_rate': 0.03650737900519146, 'n_estimators': 147, 'min_samples_split': 0.352600936519213, 'max_depth': 17}. Best is trial 10 with value: 374.6853371613855.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:02:31,279]\u001b[0m Trial 12 finished with value: 380.45083178881515 and parameters: {'learning_rate': 0.016470000484291984, 'n_estimators': 150, 'min_samples_split': 0.2973881462054172, 'max_depth': 19}. Best is trial 10 with value: 374.6853371613855.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:05:21,269]\u001b[0m Trial 13 finished with value: 422.518800857665 and parameters: {'learning_rate': 0.35748093508655965, 'n_estimators': 146, 'min_samples_split': 0.24841847054659924, 'max_depth': 16}. Best is trial 10 with value: 374.6853371613855.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:06:31,130]\u001b[0m Trial 14 finished with value: 396.8098639267611 and parameters: {'learning_rate': 0.013384354768384787, 'n_estimators': 150, 'min_samples_split': 0.4964277458632898, 'max_depth': 16}. Best is trial 10 with value: 374.6853371613855.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:10:36,666]\u001b[0m Trial 15 finished with value: 395.1930339537452 and parameters: {'learning_rate': 0.16987660113939473, 'n_estimators': 199, 'min_samples_split': 0.08796552405363434, 'max_depth': 15}. Best is trial 10 with value: 374.6853371613855.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:14:08,273]\u001b[0m Trial 16 finished with value: 429.4480655296386 and parameters: {'learning_rate': 0.4356641616320551, 'n_estimators': 173, 'min_samples_split': 0.32013802573938394, 'max_depth': 20}. Best is trial 10 with value: 374.6853371613855.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:15:59,429]\u001b[0m Trial 17 finished with value: 379.15546101173913 and parameters: {'learning_rate': 0.0943108192759426, 'n_estimators': 132, 'min_samples_split': 0.4437493968600466, 'max_depth': 14}. Best is trial 10 with value: 374.6853371613855.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:19:37,749]\u001b[0m Trial 18 finished with value: 401.0761505307956 and parameters: {'learning_rate': 0.27630082001195716, 'n_estimators': 166, 'min_samples_split': 0.17752428948448126, 'max_depth': 18}. Best is trial 10 with value: 374.6853371613855.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:22:10,870]\u001b[0m Trial 19 finished with value: 391.8263390040928 and parameters: {'learning_rate': 0.2057962905803532, 'n_estimators': 198, 'min_samples_split': 0.5678503232270693, 'max_depth': 17}. Best is trial 10 with value: 374.6853371613855.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# hyperparam tuning for sklearn ensemble.GradientBoostingRegressor\n",
    "np.random.seed(random_state)\n",
    "\n",
    "def gradboosting_objective(trial):  \n",
    "    gb_sk_opt = None\n",
    "    some = 0\n",
    "    \n",
    "    if some == 1:\n",
    "        learning_rate = trial.suggest_uniform('learning_rate', 0+sys.float_info.min, 1)\n",
    "        n_estimators = trial.suggest_int('n_estimators', min_n_estimators, max_n_estimators)\n",
    "        criterion = trial.suggest_categorical('criterion', ['mse','friedman_mse', 'mae'])\n",
    "        min_samples_split = trial.suggest_uniform('min_samples_split', 0+sys.float_info.min, 1)\n",
    "        min_samples_leaf = trial.suggest_int('min_samples_split',min_min_samples_leaf, max_min_samples_leaf)\n",
    "        max_depth = trial.suggest_int('max_depth', min_max_depth, max_max_depth)\n",
    "        max_leaf_nodes = trial.suggest_int('max_depth', min_max_leaf_nodes, max_max_leaf_nodes)\n",
    "        \n",
    "        \n",
    "        clf = ensemble.GradientBoostingRegressor(learning_rate=learning_rate, \n",
    "                                                   n_estimators=n_estimators,\n",
    "                                                   criterion=criterion,\n",
    "                                                   min_samples_split=min_samples_split,\n",
    "                                                   min_samples_leaf=min_samples_leaf,\n",
    "                                                   max_depth=max_depth,\n",
    "                                                   max_leaf_nodes=max_leaf_nodes,\n",
    "                                                   random_state=random_state,\n",
    "                                                   verbose=verbose)\n",
    "    \n",
    "    else:\n",
    "        learning_rate = trial.suggest_uniform('learning_rate', 0+sys.float_info.min, 1)\n",
    "        n_estimators = trial.suggest_int('n_estimators', min_n_estimators, max_n_estimators)\n",
    "        #criterion = trial.suggest_categorical('criterion', ['mse','friedman_mse', 'mae'])\n",
    "        min_samples_split = trial.suggest_uniform('min_samples_split', 0+sys.float_info.min, 1)\n",
    "        #min_samples_leaf = trial.suggest_int('min_samples_split',min_min_samples_leaf, max_min_samples_leaf)\n",
    "        max_depth = trial.suggest_int('max_depth', min_max_depth, max_max_depth)\n",
    "        #max_leaf_nodes = trial.suggest_int('max_depth', min_max_leaf_nodes, max_max_leaf_nodes)\n",
    "        \n",
    "        \n",
    "        clf = ensemble.GradientBoostingRegressor(learning_rate=learning_rate, \n",
    "                                                   n_estimators=n_estimators,\n",
    "                                                   #criterion=criterion,\n",
    "                                                   min_samples_split=min_samples_split,\n",
    "                                                  # min_samples_leaf=min_samples_leaf,\n",
    "                                                   max_depth=max_depth,\n",
    "                                                  # max_leaf_nodes=max_leaf_nodes,\n",
    "                                                   random_state=random_state,\n",
    "                                                   verbose=verbose)\n",
    "    \n",
    "        \n",
    "    \n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    y_val_pred = clf.predict(x_val)\n",
    "    return math.sqrt(metrics.mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "gb_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "gb_optuna.optimize(gradboosting_objective, n_trials=budget)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['gradient_boosting'] = summary['gradient_boosting'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': gb_optuna.best_value,\n",
    "    'Learning rate': gb_optuna.best_params['learning_rate'],\n",
    "    'N. estimators': gb_optuna.best_params['n_estimators'],\n",
    "    'Criterion': 'friedman_mse', \n",
    "    'Min. samples split': gb_optuna.best_params['min_samples_split'], \n",
    "    #'Min. samples leaf': gb_optuna.best_params['min_samples_leaf'],\n",
    "    'Min. samples leaf': 1,\n",
    "    'Max. depth': gb_optuna.best_params['max_depth'],\n",
    "    'Max. leaf nodes': 'None'\n",
    "    #'Max. leaf nodes': gb_optuna.best_params['max_leaf_nodes']\n",
    "    },\n",
    "    name='optuna'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time (sec)</th>\n",
       "      <th>Score (RMSE)</th>\n",
       "      <th>N. neighbors</th>\n",
       "      <th>Weights</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>0.1176</td>\n",
       "      <td>455.123868</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optuna</th>\n",
       "      <td>33.7278</td>\n",
       "      <td>424.954880</td>\n",
       "      <td>11</td>\n",
       "      <td>distance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time (sec)  Score (RMSE) N. neighbors   Weights  P\n",
       "default     0.1176    455.123868            5   uniform  2\n",
       "optuna     33.7278    424.954880           11  distance  1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary['knn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time (sec)</th>\n",
       "      <th>Score (RMSE)</th>\n",
       "      <th>Min. samples split</th>\n",
       "      <th>Criterion</th>\n",
       "      <th>Max. depth</th>\n",
       "      <th>N. estimators</th>\n",
       "      <th>Max. features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>82.5335</td>\n",
       "      <td>375.560721</td>\n",
       "      <td>2</td>\n",
       "      <td>mse</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optuna</th>\n",
       "      <td>233.6654</td>\n",
       "      <td>374.129312</td>\n",
       "      <td>0.00872</td>\n",
       "      <td>mse</td>\n",
       "      <td>None</td>\n",
       "      <td>171</td>\n",
       "      <td>0.667976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optuna</th>\n",
       "      <td>1031.8257</td>\n",
       "      <td>373.977008</td>\n",
       "      <td>0.00742</td>\n",
       "      <td>mae</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time (sec)  Score (RMSE) Min. samples split Criterion Max. depth  \\\n",
       "default    82.5335    375.560721                  2       mse       None   \n",
       "optuna    233.6654    374.129312            0.00872       mse       None   \n",
       "optuna   1031.8257    373.977008            0.00742       mae        NaN   \n",
       "\n",
       "        N. estimators Max. features  \n",
       "default           100             1  \n",
       "optuna            171      0.667976  \n",
       "optuna            101          sqrt  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary['random_forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time (sec)</th>\n",
       "      <th>Score (RMSE)</th>\n",
       "      <th>Criterion</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Max. depth</th>\n",
       "      <th>Max. leaf nodes</th>\n",
       "      <th>Min. samples leaf</th>\n",
       "      <th>Min. samples split</th>\n",
       "      <th>N. estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>30.6806</td>\n",
       "      <td>389.357849</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optuna</th>\n",
       "      <td>1896.7269</td>\n",
       "      <td>374.685337</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>0.031102</td>\n",
       "      <td>17.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316966</td>\n",
       "      <td>143.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time (sec)  Score (RMSE)     Criterion  Learning rate  Max. depth  \\\n",
       "default    30.6806    389.357849  friedman_mse       0.100000         3.0   \n",
       "optuna   1896.7269    374.685337  friedman_mse       0.031102        17.0   \n",
       "\n",
       "        Max. leaf nodes  Min. samples leaf  Min. samples split  N. estimators  \n",
       "default            None                1.0            2.000000          100.0  \n",
       "optuna             None                1.0            0.316966          143.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary['gradient_boosting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666.6691142412726"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-13 13:26:39,766]\u001b[0m Trial 1 finished with value: 423.6779507465516 and parameters: {'k': 347, 'min_samples_split': 0.37053292247586933, 'criterion': 'mae', 'max_depth': 12, 'n_estimators': 465, 'max_features': 0.5351454204911513}. Best is trial 5 with value: 394.7416180729391.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Dummy regressor(mean)\n",
    "math.sqrt(metrics.mean_squared_error(y_val, [y_val.mean() for i in range(len(y_val))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ATTRIBUTE SELECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Select from all attributes\n",
    "\n",
    "**Are all 550 input attributes actually necessary in order to get a good model? Is it possible to have an accurate model that uses fewer than 550 variables? How many?**\n",
    "\n",
    "For this question we will be using the best model we had in previous section and now include the parameter for select only certain attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_depth = 2\n",
    "max_max_depth = 32\n",
    "min_n_estimators = 50\n",
    "max_n_estimators = 200\n",
    "min_n_k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-13 13:53:57,632]\u001b[0m A new study created in memory with name: no-name-17af4ec0-df08-4dd8-b45e-e16164dfde4b\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:53:57,769]\u001b[0m Trial 0 finished with value: 668.4779174312936 and parameters: {'k': 192, 'min_samples_split': 0.7390228289606785, 'criterion': 'mse', 'max_depth': 7, 'n_estimators': 86, 'max_features': 'sqrt'}. Best is trial 0 with value: 668.4779174312936.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:53:58,136]\u001b[0m Trial 1 finished with value: 719.4778527314924 and parameters: {'k': 65, 'min_samples_split': 0.6694258631419047, 'criterion': 'mae', 'max_depth': 27, 'n_estimators': 150, 'max_features': 'log2'}. Best is trial 0 with value: 668.4779174312936.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:53:58,540]\u001b[0m Trial 2 finished with value: 719.5022353639617 and parameters: {'k': 42, 'min_samples_split': 0.9501910351635974, 'criterion': 'mae', 'max_depth': 13, 'n_estimators': 176, 'max_features': 'log2'}. Best is trial 0 with value: 668.4779174312936.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:53:58,768]\u001b[0m Trial 3 finished with value: 668.369884397063 and parameters: {'k': 379, 'min_samples_split': 0.7578749833184354, 'criterion': 'mse', 'max_depth': 6, 'n_estimators': 165, 'max_features': 'auto'}. Best is trial 3 with value: 668.369884397063.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:53:58,922]\u001b[0m Trial 4 finished with value: 655.2257078086928 and parameters: {'k': 108, 'min_samples_split': 0.6409828039648665, 'criterion': 'mse', 'max_depth': 2, 'n_estimators': 98, 'max_features': 'log2'}. Best is trial 4 with value: 655.2257078086928.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:53:59,729]\u001b[0m Trial 5 finished with value: 376.9291848671518 and parameters: {'k': 498, 'min_samples_split': 0.022326150979685044, 'criterion': 'mse', 'max_depth': 30, 'n_estimators': 78, 'max_features': 'log2'}. Best is trial 5 with value: 376.9291848671518.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(random_state)\n",
    "def random_forest_objective_attr(trial):\n",
    "    k = trial.suggest_int('k', min_n_k, x.shape[1])\n",
    "    min_samples_split = trial.suggest_uniform('min_samples_split', 0+sys.float_info.min, 1)\n",
    "    criterion = trial.suggest_categorical('criterion', ['mse','mae'])\n",
    "    max_depth = trial.suggest_int('max_depth', min_max_depth, max_max_depth, log=True)\n",
    "    n_estimators = trial.suggest_int('n_estimators', min_n_estimators, max_n_estimators)\n",
    "    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2'])\n",
    "\n",
    "    clf = Pipeline([\n",
    "      ('feature_selection', feature_selection.SelectKBest(feature_selection.f_regression, k=k)),\n",
    "      ('regression', ensemble.RandomForestRegressor(\n",
    "          random_state=random_state,\n",
    "          min_samples_split=min_samples_split,\n",
    "          criterion=criterion,\n",
    "          max_depth=max_depth,\n",
    "          n_estimators=n_estimators,\n",
    "          max_features=max_features\n",
    "      ))\n",
    "    ])\n",
    "\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    y_val_pred = clf.predict(x_val)\n",
    "    return math.sqrt(metrics.mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "rf_attr_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "rf_attr_optuna.optimize(random_forest_objective_attr, n_trials=budget, n_jobs=n_jobs)\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Conclusions\n",
    "print(rf_attr_optuna.best_params, rf_attr_optuna.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Use only Sotavento attributes\n",
    "**Is it enough to use only the attributes for the actual Sotavento location? (13th location in the grid)**\n",
    "\n",
    "We will select only Sotavento attributes and use the best model in previous section to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2528, 22) (1299, 22) (2110, 22)\n"
     ]
    }
   ],
   "source": [
    "sot_attr = []\n",
    "for attr in x_train.columns:\n",
    "    if int(attr.split('.')[-1]) == 13:\n",
    "        sot_attr.append(attr)\n",
    "\n",
    "x_train_sot = x_train[sot_attr]\n",
    "x_val_sot = x_val[sot_attr]\n",
    "x_test_sot = x_test[sot_attr]\n",
    "print(x_train_sot.shape,x_val_sot.shape,x_test_sot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-13 13:41:40,158]\u001b[0m A new study created in memory with name: no-name-47d55393-09de-4246-a862-7ba94ba8ee42\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:41:40,344]\u001b[0m Trial 1 finished with value: 668.3057723890951 and parameters: {'min_samples_split': 0.7773231353617598, 'criterion': 'mse', 'max_depth': 16, 'n_estimators': 81, 'max_features': 'sqrt'}. Best is trial 1 with value: 668.3057723890951.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:41:41,298]\u001b[0m Trial 0 finished with value: 415.3216110107275 and parameters: {'min_samples_split': 0.20071034246198016, 'criterion': 'mse', 'max_depth': 22, 'n_estimators': 157, 'max_features': 'log2'}. Best is trial 0 with value: 415.3216110107275.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:41:41,419]\u001b[0m Trial 4 finished with value: 668.3204020271736 and parameters: {'min_samples_split': 0.7537659986365126, 'criterion': 'mse', 'max_depth': 8, 'n_estimators': 108, 'max_features': 'log2'}. Best is trial 0 with value: 415.3216110107275.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:41:42,324]\u001b[0m Trial 2 finished with value: 394.79061560842706 and parameters: {'min_samples_split': 0.07550899200651673, 'criterion': 'mse', 'max_depth': 6, 'n_estimators': 160, 'max_features': 'sqrt'}. Best is trial 2 with value: 394.79061560842706.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:41:42,688]\u001b[0m Trial 6 finished with value: 719.6143228219122 and parameters: {'min_samples_split': 0.8748725131779432, 'criterion': 'mae', 'max_depth': 20, 'n_estimators': 200, 'max_features': 'auto'}. Best is trial 2 with value: 394.79061560842706.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:41:42,968]\u001b[0m Trial 7 finished with value: 719.5657934081689 and parameters: {'min_samples_split': 0.7052197310861902, 'criterion': 'mae', 'max_depth': 11, 'n_estimators': 153, 'max_features': 'log2'}. Best is trial 2 with value: 394.79061560842706.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:41:52,025]\u001b[0m Trial 3 finished with value: 408.672424980506 and parameters: {'min_samples_split': 0.10459873351832183, 'criterion': 'mae', 'max_depth': 13, 'n_estimators': 67, 'max_features': 'log2'}. Best is trial 2 with value: 394.79061560842706.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:42:22,665]\u001b[0m Trial 8 finished with value: 429.9188440139922 and parameters: {'min_samples_split': 0.42071239509660363, 'criterion': 'mae', 'max_depth': 18, 'n_estimators': 144, 'max_features': 'sqrt'}. Best is trial 2 with value: 394.79061560842706.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:42:23,053]\u001b[0m Trial 10 finished with value: 719.5728818408751 and parameters: {'min_samples_split': 0.7922938216337005, 'criterion': 'mae', 'max_depth': 19, 'n_estimators': 187, 'max_features': 'auto'}. Best is trial 2 with value: 394.79061560842706.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:44:12,432]\u001b[0m Trial 2 finished with value: 471.86774178869734 and parameters: {'k': 463, 'min_samples_split': 0.28808574635660855, 'criterion': 'mae', 'max_depth': 2, 'n_estimators': 163, 'max_features': 'auto'}. Best is trial 14 with value: 387.8360345956135.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:44:38,812]\u001b[0m Trial 5 finished with value: 549.1689062362884 and parameters: {'min_samples_split': 0.597145468482234, 'criterion': 'mae', 'max_depth': 30, 'n_estimators': 64, 'max_features': 'auto'}. Best is trial 2 with value: 394.79061560842706.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:44:40,212]\u001b[0m Trial 12 finished with value: 427.2909278542309 and parameters: {'min_samples_split': 0.34515918828961334, 'criterion': 'mse', 'max_depth': 3, 'n_estimators': 174, 'max_features': 'sqrt'}. Best is trial 2 with value: 394.79061560842706.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:44:41,220]\u001b[0m Trial 13 finished with value: 416.7231323652545 and parameters: {'min_samples_split': 0.0002644734403789428, 'criterion': 'mse', 'max_depth': 3, 'n_estimators': 113, 'max_features': 'sqrt'}. Best is trial 2 with value: 394.79061560842706.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:44:41,709]\u001b[0m Trial 14 finished with value: 380.2166389890554 and parameters: {'min_samples_split': 0.013772746737621452, 'criterion': 'mse', 'max_depth': 9, 'n_estimators': 56, 'max_features': 'log2'}. Best is trial 14 with value: 380.2166389890554.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:44:42,798]\u001b[0m Trial 15 finished with value: 382.96254398522245 and parameters: {'min_samples_split': 0.00036702223768077073, 'criterion': 'mse', 'max_depth': 7, 'n_estimators': 134, 'max_features': 'log2'}. Best is trial 14 with value: 380.2166389890554.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:44:43,360]\u001b[0m Trial 16 finished with value: 416.02746151986463 and parameters: {'min_samples_split': 0.23357245073079713, 'criterion': 'mse', 'max_depth': 8, 'n_estimators': 94, 'max_features': 'log2'}. Best is trial 14 with value: 380.2166389890554.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:44:43,804]\u001b[0m Trial 17 finished with value: 474.20249283712155 and parameters: {'min_samples_split': 0.0074988688757371275, 'criterion': 'mse', 'max_depth': 2, 'n_estimators': 131, 'max_features': 'log2'}. Best is trial 14 with value: 380.2166389890554.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:44:44,673]\u001b[0m Trial 18 finished with value: 415.7015712621882 and parameters: {'min_samples_split': 0.22222564717233523, 'criterion': 'mse', 'max_depth': 12, 'n_estimators': 132, 'max_features': 'log2'}. Best is trial 14 with value: 380.2166389890554.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 13:44:44,798]\u001b[0m Trial 19 finished with value: 668.3047905622632 and parameters: {'min_samples_split': 0.9968437987860929, 'criterion': 'mse', 'max_depth': 26, 'n_estimators': 112, 'max_features': 'log2'}. Best is trial 14 with value: 380.2166389890554.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-87ad098e697c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mrf_sot_optuna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minimize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mrf_sot_optuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_forest_sot_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbudget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/master/lib/python3.8/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \"\"\"\n\u001b[0;32m--> 306\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/master/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     )\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 parallel(\n\u001b[0m\u001b[1;32m    102\u001b[0m                     delayed(_optimize_sequential)(\n\u001b[1;32m    103\u001b[0m                         \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/master/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/master/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/master/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/master/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/master/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/master/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(random_state)\n",
    "def random_forest_sot_objective(trial):\n",
    "    min_samples_split = trial.suggest_uniform('min_samples_split', 0+sys.float_info.min, 1)\n",
    "    criterion = trial.suggest_categorical('criterion', ['mse','mae'])\n",
    "    max_depth = trial.suggest_int('max_depth', min_max_depth, max_max_depth)\n",
    "    n_estimators = trial.suggest_int('n_estimators', min_n_estimators, max_n_estimators)\n",
    "    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2'])\n",
    "\n",
    "    clf = ensemble.RandomForestRegressor(\n",
    "        random_state=random_state,\n",
    "        min_samples_split=min_samples_split,\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        n_estimators=n_estimators,\n",
    "        max_features=max_features\n",
    "        )\n",
    "\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    y_val_pred = clf.predict(x_val)\n",
    "    return math.sqrt(metrics.mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "rf_sot_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "rf_sot_optuna.optimize(random_forest_sot_objective, n_trials=budget, n_jobs=n_jobs)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Conclusions\n",
    "print(rf_sot_optuna.best_params, rf_sot_optuna.best_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
