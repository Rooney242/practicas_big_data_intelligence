{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wind prediction - Second assignment\n",
    "\n",
    "## Authors\n",
    "\n",
    "David Moreno Maldonado 100441714     \n",
    "Inés Fernández Campos 100443936"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/fddcampos/Documents/uc3m/2_term/BDINTELLIGENCE/practicas_big_data_intelligence/assignment_2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import some libraries\n",
    "import os\n",
    "import numpy as np              \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn import preprocessing, impute, model_selection, metrics, neighbors, ensemble, feature_selection\n",
    "from sklearn.pipeline import Pipeline\n",
    "import optuna\n",
    "import optuna.visualization as ov\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN PARAMETERS FOR THE ASSIGNMENT\n",
    "budget = 20\n",
    "random_state = 3\n",
    "verbose = 0\n",
    "n_jobs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"wind_pickle\" file contains data in a binary format called \"Pickle\". Pickle data loads faster than text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle('wind_pickle.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the attributes in the dataset. Very important, the output attribute (i.e. the value to be predicted, **energy**, is the first attribute). **Steps** represents the hours in advance of the forecast. We will not use this variable here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5937, 556)\n"
     ]
    }
   ],
   "source": [
    "# The dataset contains 5937 instances and 556 attributes (including the outcome to be predicted)\n",
    "print(data.shape)\n",
    "#data.columns.values.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-1 for training, 0 for validation, 1 for testing\n",
    "year_to_part = {\n",
    "    2005: -1,\n",
    "    2006: -1,\n",
    "    2007: 0,\n",
    "    2008: 0, \n",
    "    2009: 1,\n",
    "    2010: 1\n",
    "}\n",
    "data['partition'] = data['year'].apply(lambda x: year_to_part[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now remove the columns that cannot be used for training the models from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps, month, day, hour, year should be removed, they cannot be used for training the models\n",
    "to_remove = ['steps', 'month', 'year', 'day', 'hour']\n",
    "for m in to_remove: data = data.drop(m, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets put 163861 missing values \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import randint\n",
    "\n",
    "# we add na values at random\n",
    "my_NIA = 100443936 + 100441714\n",
    "np.random.seed(my_NIA)\n",
    "\n",
    "how_many_nas = round(data.shape[0]*data.shape[1]*0.05)\n",
    "print('Lets put '+str(how_many_nas)+' missing values \\n')\n",
    "x_locations = randint(0, data.shape[0], size=how_many_nas)\n",
    "y_locations = randint(1, data.shape[1]-2, size=how_many_nas)\n",
    "\n",
    "for i in range(len(x_locations)):\n",
    "    data.iat[x_locations[i], y_locations[i]] = np.nan\n",
    "    \n",
    "data.to_pickle('wind_pickle_with_nan.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point on, the file wind_pickle_with_nan should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5937, 552)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('wind_pickle_with_nan.pickle')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().values.any())\n",
    "input_cols = data.columns.difference(['energy', 'partition'])\n",
    "x = data[input_cols]\n",
    "#Iterative imputer (takes too long)\n",
    "'''iter_imp = impute.IterativeImputer(random_state=random_state, \n",
    "                                   initial_strategy='median', \n",
    "                                   max_iter=3,\n",
    "                                   verbose=verbose)\n",
    "no_nan = iter_imp.fit_transform(x)'''\n",
    "\n",
    "#KNN imputer(takes too long)\n",
    "'''knn_imp = impute.KNNImputer(weights='distance')\n",
    "no_nan = knn_imp.fit_transform(x)'''\n",
    "\n",
    "#Simple imputer\n",
    "simp_imp = impute.SimpleImputer(strategy='median',\n",
    "                               verbose=2)\n",
    "no_nan = simp_imp.fit_transform(x)\n",
    "\n",
    "data[input_cols] = pd.DataFrame(data=no_nan)\n",
    "print(data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(data[input_cols]) \n",
    "data[input_cols] = scaler.transform(data[input_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split\n",
    "We are going to use train/test for model evaluation (outer) and train/validation for hyperparameter tuning (inner), as follows:     \n",
    "1. Train partition: the first two years of data. Given that there are 6 years worth of data, we will use the first 2/6 of the instances for training.     \n",
    "2. Validation partition: the second two years of data. \n",
    "3. Test partition: the remaining data    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-1 for training, 0 for validation, 1 for testing\n",
    "test = data[data['partition'] == 1]\n",
    "train = data[data['partition'] == -1]\n",
    "val = data[data['partition'] == 0]\n",
    "\n",
    "del test['partition']\n",
    "del train['partition']\n",
    "\n",
    "y_test = test['energy']\n",
    "x_test = test[test.columns.difference(['energy'])]\n",
    "\n",
    "y_train = train['energy']\n",
    "x_train = train[train.columns.difference(['energy'])]\n",
    "\n",
    "\n",
    "y_val = val['energy']\n",
    "x_val = val[train.columns.difference(['energy'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MODEL SELECTION AND HYPER-PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframes with all the information of each model\n",
    "summary = {\n",
    "    'knn': pd.DataFrame(columns=['Time (sec)', 'Score (RMSE)', 'N. neighbors', 'Weights', 'P']),\n",
    "    'random_forest': pd.DataFrame(columns=['Time (sec)', 'Score (RMSE)', 'Min. samples split', 'Criterion', 'Max. depth', 'N. estimators','Max. features']),\n",
    "    'gradient_boosting': pd.DataFrame(columns=['Time (sec)', 'Score (RMSE)'])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Default hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_state)\n",
    "knn_default = neighbors.KNeighborsRegressor()\n",
    "\n",
    "start_time = time.time()\n",
    "knn_default = knn_default.fit(x_train, y_train)\n",
    "y_val_pred = knn_default.predict(x_val)\n",
    "score = math.sqrt(metrics.mean_squared_error(y_val, y_val_pred))\n",
    "end_time = time.time()\n",
    "\n",
    "summary['knn'] = summary['knn'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': score, \n",
    "    'N. neighbors': 5, \n",
    "    'Weights': 'uniform', \n",
    "    'P': 2\n",
    "    }, \n",
    "    name='default'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Hyper-parameter tunning (OPTUNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_n_neigbors = 1\n",
    "max_n_neigbors = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-13 14:30:52,839]\u001b[0m A new study created in memory with name: no-name-5643f019-8098-4f6e-a30e-e1b102ce75a1\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:30:55,885]\u001b[0m Trial 0 finished with value: 461.50247231150104 and parameters: {'n_neighbors': 4, 'weights': 'distance', 'p': 2}. Best is trial 0 with value: 461.50247231150104.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:30:59,358]\u001b[0m Trial 1 finished with value: 425.8532193925109 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'p': 1}. Best is trial 1 with value: 425.8532193925109.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:31:02,432]\u001b[0m Trial 2 finished with value: 446.53181088677667 and parameters: {'n_neighbors': 6, 'weights': 'distance', 'p': 2}. Best is trial 1 with value: 425.8532193925109.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:31:05,247]\u001b[0m Trial 3 finished with value: 438.66704912167074 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 2}. Best is trial 1 with value: 425.8532193925109.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:31:08,229]\u001b[0m Trial 4 finished with value: 435.96737369410965 and parameters: {'n_neighbors': 16, 'weights': 'uniform', 'p': 2}. Best is trial 1 with value: 425.8532193925109.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:31:11,524]\u001b[0m Trial 5 finished with value: 425.19635407015437 and parameters: {'n_neighbors': 9, 'weights': 'distance', 'p': 1}. Best is trial 5 with value: 425.19635407015437.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:31:14,839]\u001b[0m Trial 6 finished with value: 434.295501863787 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'p': 2}. Best is trial 5 with value: 425.19635407015437.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:31:18,041]\u001b[0m Trial 7 finished with value: 461.102922608866 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'p': 1}. Best is trial 5 with value: 425.19635407015437.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:31:21,536]\u001b[0m Trial 8 finished with value: 432.0797327508031 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'p': 1}. Best is trial 5 with value: 425.19635407015437.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:31:24,996]\u001b[0m Trial 9 finished with value: 455.12386790067876 and parameters: {'n_neighbors': 5, 'weights': 'uniform', 'p': 2}. Best is trial 5 with value: 425.19635407015437.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:31:28,848]\u001b[0m Trial 10 finished with value: 424.95488026361073 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'p': 1}. Best is trial 10 with value: 424.95488026361073.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:31:32,720]\u001b[0m Trial 11 finished with value: 424.95488026361073 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'p': 1}. Best is trial 10 with value: 424.95488026361073.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:31:37,344]\u001b[0m Trial 12 finished with value: 424.95488026361073 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'p': 1}. Best is trial 10 with value: 424.95488026361073.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:31:41,148]\u001b[0m Trial 13 finished with value: 424.95488026361073 and parameters: {'n_neighbors': 11, 'weights': 'distance', 'p': 1}. Best is trial 10 with value: 424.95488026361073.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:31:45,116]\u001b[0m Trial 14 finished with value: 427.9653491023484 and parameters: {'n_neighbors': 14, 'weights': 'distance', 'p': 1}. Best is trial 10 with value: 424.95488026361073.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:31:48,313]\u001b[0m Trial 15 finished with value: 571.1694071873051 and parameters: {'n_neighbors': 1, 'weights': 'distance', 'p': 1}. Best is trial 10 with value: 424.95488026361073.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:31:51,797]\u001b[0m Trial 16 finished with value: 424.97500012000376 and parameters: {'n_neighbors': 10, 'weights': 'distance', 'p': 1}. Best is trial 10 with value: 424.95488026361073.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:31:55,226]\u001b[0m Trial 17 finished with value: 426.6970286295103 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'p': 1}. Best is trial 10 with value: 424.95488026361073.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:31:58,668]\u001b[0m Trial 18 finished with value: 427.6511157945625 and parameters: {'n_neighbors': 16, 'weights': 'distance', 'p': 1}. Best is trial 10 with value: 424.95488026361073.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:32:01,862]\u001b[0m Trial 19 finished with value: 427.333974534529 and parameters: {'n_neighbors': 8, 'weights': 'distance', 'p': 1}. Best is trial 10 with value: 424.95488026361073.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(random_state)\n",
    "def knn_objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', min_n_neigbors, max_n_neigbors)\n",
    "    weights = trial.suggest_categorical('weights', ['uniform','distance'])\n",
    "    p = trial.suggest_categorical('p', [1, 2])\n",
    "\n",
    "    clf = neighbors.KNeighborsRegressor(\n",
    "        n_neighbors=n_neighbors,\n",
    "        weights=weights,\n",
    "        p=p)\n",
    "    \n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    y_val_pred = clf.predict(x_val)\n",
    "    return math.sqrt(metrics.mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "knn_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "knn_optuna.optimize(knn_objective, n_trials=budget)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['knn'] = summary['knn'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': knn_optuna.best_value, \n",
    "    'N. neighbors': knn_optuna.best_params['n_neighbors'], \n",
    "    'Weights': knn_optuna.best_params['weights'], \n",
    "    'P': knn_optuna.best_params['p']\n",
    "    }, \n",
    "    name='optuna'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Default hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_state)\n",
    "rf_default = ensemble.RandomForestRegressor(random_state=random_state, verbose=verbose, n_jobs=n_jobs)\n",
    "\n",
    "start_time = time.time()\n",
    "rf_default = rf_default.fit(x_train, y_train)\n",
    "y_val_pred = rf_default.predict(x_val)\n",
    "score =  math.sqrt(metrics.mean_squared_error(y_val, y_val_pred))\n",
    "end_time = time.time()\n",
    "\n",
    "summary['random_forest'] = summary['random_forest'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': score,\n",
    "    'Min. samples split': 2, \n",
    "    'Criterion': 'mse', \n",
    "    'Max. depth': 'None',\n",
    "    'N. estimators': 100,\n",
    "    'Max. features': 1\n",
    "    },\n",
    "    name='default'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Hyper-parameter tunning (OPTUNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_depth = 2\n",
    "max_max_depth = 50\n",
    "min_n_estimators = 50\n",
    "max_n_estimators = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-13 14:40:46,203]\u001b[0m A new study created in memory with name: no-name-2663b009-5998-4065-8d0e-10ee2f47a415\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:40:48,116]\u001b[0m Trial 0 finished with value: 400.9598210339549 and parameters: {'min_samples_split': 0.2585716150647326, 'criterion': 'mse', 'max_depth': 21, 'n_estimators': 119, 'max_features': 'sqrt'}. Best is trial 0 with value: 400.9598210339549.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:40:48,275]\u001b[0m Trial 1 finished with value: 668.3836578998909 and parameters: {'min_samples_split': 0.7275958768930648, 'criterion': 'mse', 'max_depth': 19, 'n_estimators': 125, 'max_features': 'sqrt'}. Best is trial 0 with value: 400.9598210339549.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:40:48,379]\u001b[0m Trial 2 finished with value: 668.4502497483671 and parameters: {'min_samples_split': 0.9734866223139015, 'criterion': 'mse', 'max_depth': 19, 'n_estimators': 83, 'max_features': 'sqrt'}. Best is trial 0 with value: 400.9598210339549.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:40:48,521]\u001b[0m Trial 3 finished with value: 668.3890217234632 and parameters: {'min_samples_split': 0.9904091845943086, 'criterion': 'mse', 'max_depth': 12, 'n_estimators': 122, 'max_features': 'log2'}. Best is trial 0 with value: 400.9598210339549.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:41:19,220]\u001b[0m Trial 4 finished with value: 424.4919801908068 and parameters: {'min_samples_split': 0.2608742841494963, 'criterion': 'mae', 'max_depth': 44, 'n_estimators': 198, 'max_features': 'log2'}. Best is trial 0 with value: 400.9598210339549.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:41:21,039]\u001b[0m Trial 5 finished with value: 401.3502545053183 and parameters: {'min_samples_split': 0.2735220385298276, 'criterion': 'mse', 'max_depth': 25, 'n_estimators': 125, 'max_features': 'sqrt'}. Best is trial 0 with value: 400.9598210339549.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:42:30,503]\u001b[0m Trial 6 finished with value: 412.5364997638835 and parameters: {'min_samples_split': 0.2726886151779092, 'criterion': 'mae', 'max_depth': 19, 'n_estimators': 168, 'max_features': 'sqrt'}. Best is trial 0 with value: 400.9598210339549.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:43:17,957]\u001b[0m Trial 7 finished with value: 394.1882243101476 and parameters: {'min_samples_split': 0.19324574838516728, 'criterion': 'mse', 'max_depth': 25, 'n_estimators': 124, 'max_features': 'auto'}. Best is trial 7 with value: 394.1882243101476.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:43:18,264]\u001b[0m Trial 8 finished with value: 618.354981330637 and parameters: {'min_samples_split': 0.6373094267217242, 'criterion': 'mse', 'max_depth': 7, 'n_estimators': 150, 'max_features': 'sqrt'}. Best is trial 7 with value: 394.1882243101476.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:43:18,582]\u001b[0m Trial 9 finished with value: 719.4164964060726 and parameters: {'min_samples_split': 0.7003662398026363, 'criterion': 'mae', 'max_depth': 49, 'n_estimators': 138, 'max_features': 'auto'}. Best is trial 7 with value: 394.1882243101476.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:43:57,283]\u001b[0m Trial 10 finished with value: 380.3488406352341 and parameters: {'min_samples_split': 0.02490355296388508, 'criterion': 'mse', 'max_depth': 37, 'n_estimators': 63, 'max_features': 'auto'}. Best is trial 10 with value: 380.3488406352341.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:44:43,805]\u001b[0m Trial 11 finished with value: 377.26906792381976 and parameters: {'min_samples_split': 0.00363889789936404, 'criterion': 'mse', 'max_depth': 37, 'n_estimators': 59, 'max_features': 'auto'}. Best is trial 11 with value: 377.26906792381976.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:45:19,882]\u001b[0m Trial 12 finished with value: 377.5159617676009 and parameters: {'min_samples_split': 0.01066118844432426, 'criterion': 'mse', 'max_depth': 37, 'n_estimators': 53, 'max_features': 'auto'}. Best is trial 11 with value: 377.26906792381976.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:45:55,865]\u001b[0m Trial 13 finished with value: 376.9700103522176 and parameters: {'min_samples_split': 0.005353556937554937, 'criterion': 'mse', 'max_depth': 36, 'n_estimators': 50, 'max_features': 'auto'}. Best is trial 13 with value: 376.9700103522176.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:46:33,163]\u001b[0m Trial 14 finished with value: 394.20574848927464 and parameters: {'min_samples_split': 0.1110851413902727, 'criterion': 'mse', 'max_depth': 34, 'n_estimators': 86, 'max_features': 'auto'}. Best is trial 13 with value: 376.9700103522176.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:46:47,008]\u001b[0m Trial 15 finished with value: 420.15132134218635 and parameters: {'min_samples_split': 0.456175516377316, 'criterion': 'mse', 'max_depth': 32, 'n_estimators': 76, 'max_features': 'auto'}. Best is trial 13 with value: 376.9700103522176.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:53:11,102]\u001b[0m Trial 16 finished with value: 431.99886387099576 and parameters: {'min_samples_split': 0.41452703634839544, 'criterion': 'mae', 'max_depth': 43, 'n_estimators': 53, 'max_features': 'auto'}. Best is trial 13 with value: 376.9700103522176.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:54:12,879]\u001b[0m Trial 17 finished with value: 392.59803315665596 and parameters: {'min_samples_split': 0.09157790021954865, 'criterion': 'mse', 'max_depth': 49, 'n_estimators': 100, 'max_features': 'auto'}. Best is trial 13 with value: 376.9700103522176.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:54:14,452]\u001b[0m Trial 18 finished with value: 375.827967578847 and parameters: {'min_samples_split': 0.005758582581728201, 'criterion': 'mse', 'max_depth': 31, 'n_estimators': 65, 'max_features': 'log2'}. Best is trial 18 with value: 375.827967578847.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:54:15,769]\u001b[0m Trial 19 finished with value: 410.8563146030943 and parameters: {'min_samples_split': 0.13721976657959345, 'criterion': 'mse', 'max_depth': 30, 'n_estimators': 102, 'max_features': 'log2'}. Best is trial 18 with value: 375.827967578847.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(random_state)\n",
    "def random_forest_objective(trial):\n",
    "    min_samples_split = trial.suggest_uniform('min_samples_split', 0+sys.float_info.min, 1)\n",
    "    criterion = trial.suggest_categorical('criterion', ['mse','mae'])\n",
    "    max_depth = trial.suggest_int('max_depth', min_max_depth, max_max_depth)\n",
    "    n_estimators = trial.suggest_int('n_estimators', min_n_estimators, max_n_estimators)\n",
    "    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2'])\n",
    "\n",
    "    clf = ensemble.RandomForestRegressor(\n",
    "        random_state=random_state,\n",
    "        min_samples_split=min_samples_split,\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        n_estimators=n_estimators,\n",
    "        max_features=max_features\n",
    "        )\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    y_val_pred = clf.predict(x_val)\n",
    "    return math.sqrt(metrics.mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "rf_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "rf_optuna.optimize(random_forest_objective, n_trials=budget, n_jobs=n_jobs)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['random_forest'] = summary['random_forest'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': rf_optuna.best_value,\n",
    "    'Min. samples split': rf_optuna.best_params['min_samples_split'], \n",
    "    'Criterion': rf_optuna.best_params['criterion'], \n",
    "    'Max. depth': rf_optuna.best_params['max_depth'],\n",
    "    'N. estimators': rf_optuna.best_params['n_estimators'],\n",
    "    'Max. features': rf_optuna.best_params['max_features']\n",
    "    },\n",
    "    name='optuna'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Default hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation using sklearn\n",
    "np.random.seed(random_state)\n",
    "gb_sk_def = ensemble.GradientBoostingRegressor(random_state=random_state, verbose=verbose)\n",
    "\n",
    "start_time = time.time()\n",
    "gb_sk_def = gb_sk_def.fit(x_train, y_train)\n",
    "y_val_pred = gb_sk_def.predict(x_val)\n",
    "score =  math.sqrt(metrics.mean_squared_error(y_val, y_val_pred))\n",
    "end_time = time.time()\n",
    "\n",
    "summary['gradient_boosting'] = summary['gradient_boosting'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': score,\n",
    "    'Learning rate': 0.1,\n",
    "    'N. estimators': 100,\n",
    "    'Criterion': 'friedman_mse', \n",
    "    'Min. samples split': 2, \n",
    "    'Min. samples leaf': 1,\n",
    "    'Max. depth': 3,\n",
    "    'Max. leaf nodes': 'None'\n",
    "    },\n",
    "    name='default'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation using xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dtest = xgb.DMatrix(x_test, label=y_test)\n",
    "\n",
    "gb_xgb_def = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "start_time = time.time()\n",
    "gb_xgb_def = gb_xgb_def.fit(x_train, y_train)\n",
    "y_val_pred = gb_xgb_def.predict(x_val)\n",
    "score = math.sqrt(metrics.mean_squared_error(y_val, y_val_pred))\n",
    "end_time = time.time()\n",
    "\n",
    "summary['gradient_boosting'] = summary['gradient_boosting'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': score,\n",
    "    'Learning rate': 0.3,\n",
    "    'Max. depth': 6,\n",
    "    'Max. leaf nodes': 0,\n",
    "    'Gamma (min_split_loss)': 0,\n",
    "    'Lambda': 1,\n",
    "    'Alpha': 0,\n",
    "    'N. estimators': gb_xgb_def.get_params()['n_estimators']\n",
    "    },\n",
    "    name='default_xgboost'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Hyper-parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dir(dtrain))\n",
    "#print('\\n', dir(model))\n",
    "min_max_leaf_nodes = 2\n",
    "max_max_leaf_nodes = 20\n",
    "min_min_samples_leaf = 1\n",
    "max_min_samples_leaf = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-13 17:33:44,119]\u001b[0m A new study created in memory with name: no-name-85840a61-4374-4c5d-87c8-f6402e3d33fa\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 17:34:20,446]\u001b[0m Trial 0 finished with value: 426.3910818511826 and parameters: {'learning_rate': 0.9437204360706714, 'n_estimators': 179, 'min_samples_split': 0.9904165055278342, 'max_depth': 4, 'criterion': 'friedman_mse', 'min_samples_leaf': 5, 'max_leaf_nodes': 5}. Best is trial 0 with value: 426.3910818511826.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 17:36:14,804]\u001b[0m Trial 1 finished with value: 451.73522494764103 and parameters: {'learning_rate': 0.8426704875565854, 'n_estimators': 174, 'min_samples_split': 0.6297387035925248, 'max_depth': 6, 'criterion': 'friedman_mse', 'min_samples_leaf': 10, 'max_leaf_nodes': 15}. Best is trial 0 with value: 426.3910818511826.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 17:36:52,655]\u001b[0m Trial 2 finished with value: 471.6245212069269 and parameters: {'learning_rate': 0.9957578627484363, 'n_estimators': 96, 'min_samples_split': 0.8946037659207297, 'max_depth': 9, 'criterion': 'friedman_mse', 'min_samples_leaf': 4, 'max_leaf_nodes': 11}. Best is trial 0 with value: 426.3910818511826.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 17:37:09,263]\u001b[0m Trial 3 finished with value: 406.67011756131495 and parameters: {'learning_rate': 0.8371150444242546, 'n_estimators': 52, 'min_samples_split': 0.49078633378092584, 'max_depth': 7, 'criterion': 'mse', 'min_samples_leaf': 9, 'max_leaf_nodes': 2}. Best is trial 3 with value: 406.67011756131495.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 17:38:23,186]\u001b[0m Trial 4 finished with value: 378.534765140851 and parameters: {'learning_rate': 0.12904545476672757, 'n_estimators': 115, 'min_samples_split': 0.5949070997701705, 'max_depth': 5, 'criterion': 'friedman_mse', 'min_samples_leaf': 7, 'max_leaf_nodes': 5}. Best is trial 4 with value: 378.534765140851.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 17:40:03,616]\u001b[0m Trial 5 finished with value: 384.3678785967688 and parameters: {'learning_rate': 0.15727218364405904, 'n_estimators': 84, 'min_samples_split': 0.31692872611290845, 'max_depth': 9, 'criterion': 'friedman_mse', 'min_samples_leaf': 6, 'max_leaf_nodes': 12}. Best is trial 4 with value: 378.534765140851.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 17:41:47,454]\u001b[0m Trial 6 finished with value: 443.96440563773274 and parameters: {'learning_rate': 0.7161201918079666, 'n_estimators': 199, 'min_samples_split': 0.7911401667685287, 'max_depth': 8, 'criterion': 'mse', 'min_samples_leaf': 8, 'max_leaf_nodes': 17}. Best is trial 4 with value: 378.534765140851.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 17:43:36,205]\u001b[0m Trial 7 finished with value: 388.54385777534395 and parameters: {'learning_rate': 0.26800234196295825, 'n_estimators': 175, 'min_samples_split': 0.5995905355607194, 'max_depth': 5, 'criterion': 'friedman_mse', 'min_samples_leaf': 9, 'max_leaf_nodes': 17}. Best is trial 4 with value: 378.534765140851.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 17:44:25,465]\u001b[0m Trial 8 finished with value: 434.0440837996413 and parameters: {'learning_rate': 0.6607043829976477, 'n_estimators': 105, 'min_samples_split': 0.3682658581586651, 'max_depth': 3, 'criterion': 'mse', 'min_samples_leaf': 3, 'max_leaf_nodes': 5}. Best is trial 4 with value: 378.534765140851.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 17:46:20,729]\u001b[0m Trial 9 finished with value: 448.4228731582385 and parameters: {'learning_rate': 0.6605989830661771, 'n_estimators': 184, 'min_samples_split': 0.7831395508322547, 'max_depth': 15, 'criterion': 'friedman_mse', 'min_samples_leaf': 5, 'max_leaf_nodes': 17}. Best is trial 4 with value: 378.534765140851.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 17:48:14,210]\u001b[0m Trial 10 finished with value: 416.03446387762983 and parameters: {'learning_rate': 0.009670080431897835, 'n_estimators': 146, 'min_samples_split': 0.08662349610426745, 'max_depth': 13, 'criterion': 'friedman_mse', 'min_samples_leaf': 1, 'max_leaf_nodes': 7}. Best is trial 4 with value: 378.534765140851.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 17:49:19,749]\u001b[0m Trial 11 finished with value: 373.5031534726167 and parameters: {'learning_rate': 0.13012147162039495, 'n_estimators': 60, 'min_samples_split': 0.20892275826444368, 'max_depth': 10, 'criterion': 'friedman_mse', 'min_samples_leaf': 7, 'max_leaf_nodes': 9}. Best is trial 11 with value: 373.5031534726167.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 17:49:53,641]\u001b[0m Trial 12 finished with value: 399.8686837073088 and parameters: {'learning_rate': 0.3966774989624777, 'n_estimators': 50, 'min_samples_split': 0.0018539423143096312, 'max_depth': 11, 'criterion': 'friedman_mse', 'min_samples_leaf': 7, 'max_leaf_nodes': 8}. Best is trial 11 with value: 373.5031534726167.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 17:50:37,099]\u001b[0m Trial 13 finished with value: 562.4780275233212 and parameters: {'learning_rate': 0.006461915651622754, 'n_estimators': 134, 'min_samples_split': 0.20423428218614853, 'max_depth': 2, 'criterion': 'friedman_mse', 'min_samples_leaf': 7, 'max_leaf_nodes': 2}. Best is trial 11 with value: 373.5031534726167.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 17:51:43,972]\u001b[0m Trial 14 finished with value: 385.43405456841555 and parameters: {'learning_rate': 0.2181808124497991, 'n_estimators': 69, 'min_samples_split': 0.44730177719027986, 'max_depth': 11, 'criterion': 'friedman_mse', 'min_samples_leaf': 7, 'max_leaf_nodes': 8}. Best is trial 11 with value: 373.5031534726167.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 17:54:50,359]\u001b[0m Trial 15 finished with value: 414.53970397004514 and parameters: {'learning_rate': 0.4289674628773087, 'n_estimators': 120, 'min_samples_split': 0.19256391043083487, 'max_depth': 12, 'criterion': 'friedman_mse', 'min_samples_leaf': 10, 'max_leaf_nodes': 13}. Best is trial 11 with value: 373.5031534726167.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 17:55:29,838]\u001b[0m Trial 16 finished with value: 380.55105478026474 and parameters: {'learning_rate': 0.1014538797315698, 'n_estimators': 67, 'min_samples_split': 0.6379738821787163, 'max_depth': 6, 'criterion': 'mse', 'min_samples_leaf': 8, 'max_leaf_nodes': 5}. Best is trial 11 with value: 373.5031534726167.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 17:58:44,953]\u001b[0m Trial 17 finished with value: 397.7850845967097 and parameters: {'learning_rate': 0.3158396517373767, 'n_estimators': 147, 'min_samples_split': 0.28173827210244645, 'max_depth': 10, 'criterion': 'friedman_mse', 'min_samples_leaf': 3, 'max_leaf_nodes': 9}. Best is trial 11 with value: 373.5031534726167.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 17:59:52,058]\u001b[0m Trial 18 finished with value: 387.82029485211586 and parameters: {'learning_rate': 0.06764203312622216, 'n_estimators': 107, 'min_samples_split': 0.030591261739652875, 'max_depth': 14, 'criterion': 'friedman_mse', 'min_samples_leaf': 6, 'max_leaf_nodes': 3}. Best is trial 11 with value: 373.5031534726167.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:00:24,140]\u001b[0m Trial 19 finished with value: 413.53145388683106 and parameters: {'learning_rate': 0.5275054264891156, 'n_estimators': 73, 'min_samples_split': 0.54910640137881, 'max_depth': 2, 'criterion': 'friedman_mse', 'min_samples_leaf': 8, 'max_leaf_nodes': 20}. Best is trial 11 with value: 373.5031534726167.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# hyperparam tuning for sklearn ensemble.GradientBoostingRegressor\n",
    "np.random.seed(random_state)\n",
    "\n",
    "def gradboosting_objective(trial):  \n",
    "    gb_sk_opt = None\n",
    "    short = False\n",
    "    \n",
    "    learning_rate = trial.suggest_uniform('learning_rate', 0+sys.float_info.min, 1)\n",
    "    n_estimators = trial.suggest_int('n_estimators', min_n_estimators, max_n_estimators)\n",
    "    min_samples_split = trial.suggest_uniform('min_samples_split', 0+sys.float_info.min, 1)\n",
    "    max_depth = trial.suggest_int('max_depth', min_max_depth, max_max_depth)\n",
    "        \n",
    "    if short == False: # it will take a long time to run \n",
    "        criterion = trial.suggest_categorical('criterion', ['mse','friedman_mse'])\n",
    "        min_samples_leaf = trial.suggest_int('min_samples_leaf',min_min_samples_leaf, max_min_samples_leaf)\n",
    "        max_leaf_nodes = trial.suggest_int('max_leaf_nodes', min_max_leaf_nodes, max_max_leaf_nodes)\n",
    "        \n",
    "        gb_sk_opt = ensemble.GradientBoostingRegressor(learning_rate=learning_rate, \n",
    "                                                   n_estimators=n_estimators,\n",
    "                                                   criterion=criterion,\n",
    "                                                   min_samples_split=min_samples_split,\n",
    "                                                   min_samples_leaf=min_samples_leaf,\n",
    "                                                   max_depth=max_depth,\n",
    "                                                   max_leaf_nodes=max_leaf_nodes,\n",
    "                                                   random_state=random_state,\n",
    "                                                   verbose=verbose)\n",
    "    else:  # will take less time        \n",
    "        gb_sk_opt = ensemble.GradientBoostingRegressor(learning_rate=learning_rate, \n",
    "                                                   n_estimators=n_estimators,\n",
    "                                                   min_samples_split=min_samples_split,\n",
    "                                                   max_depth=max_depth,\n",
    "                                                   random_state=random_state,\n",
    "                                                   verbose=verbose)\n",
    "        \n",
    "    gb_sk_opt = gb_sk_opt.fit(x_train, y_train)\n",
    "    y_val_pred = gb_sk_opt.predict(x_val)\n",
    "    \n",
    "    return math.sqrt(metrics.mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "gb_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "gb_optuna.optimize(gradboosting_objective, n_trials=budget)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['gradient_boosting'] = summary['gradient_boosting'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': gb_optuna.best_value,\n",
    "    'Learning rate': gb_optuna.best_params['learning_rate'],\n",
    "    'N. estimators': gb_optuna.best_params['n_estimators'],\n",
    "    'Criterion': 'friedman_mse', \n",
    "    #Min. samples split': gb_optuna.best_params['min_samples_split'], \n",
    "    'Min. samples leaf': gb_optuna.best_params['min_samples_leaf'],\n",
    "    'Min. samples leaf': 1,\n",
    "    'Max. depth': gb_optuna.best_params['max_depth'],\n",
    "    #Max. leaf nodes': 'None'\n",
    "    'Max. leaf nodes': gb_optuna.best_params['max_leaf_nodes']\n",
    "    },\n",
    "    name='optuna_sklearn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-13 18:00:31,508]\u001b[0m A new study created in memory with name: no-name-665d982e-98ea-4bc4-b946-dd024ab898e8\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:00:43,128]\u001b[0m Trial 0 finished with value: 407.8463263806792 and parameters: {'eta': 0.01578049329785458, 'max_depth': 3, 'n_estimators': 138, 'gamma': 0.6971905601309071, 'lambda': 0.3811080738096944, 'alpha': 0.20120626381188714}. Best is trial 0 with value: 407.8463263806792.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:00:52,135]\u001b[0m Trial 1 finished with value: 385.58132285995805 and parameters: {'eta': 0.11756590681846768, 'max_depth': 2, 'n_estimators': 161, 'gamma': 0.1854233470219595, 'lambda': 0.06834635874698405, 'alpha': 0.4742807662973112}. Best is trial 1 with value: 385.58132285995805.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:01:04,613]\u001b[0m Trial 2 finished with value: 421.71825083991206 and parameters: {'eta': 0.4634993828570153, 'max_depth': 4, 'n_estimators': 92, 'gamma': 0.5211171901404208, 'lambda': 0.25973284204659014, 'alpha': 0.06487483813687336}. Best is trial 1 with value: 385.58132285995805.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:01:16,513]\u001b[0m Trial 3 finished with value: 469.8715245355276 and parameters: {'eta': 0.6200609963857777, 'max_depth': 5, 'n_estimators': 89, 'gamma': 0.47096592273509075, 'lambda': 0.4069968808696434, 'alpha': 0.308949313057165}. Best is trial 1 with value: 385.58132285995805.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:01:48,380]\u001b[0m Trial 4 finished with value: 463.75017718031086 and parameters: {'eta': 0.6468771965519099, 'max_depth': 11, 'n_estimators': 89, 'gamma': 0.28672368191584724, 'lambda': 0.22766603591835724, 'alpha': 0.4739153564084242}. Best is trial 1 with value: 385.58132285995805.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:02:29,846]\u001b[0m Trial 5 finished with value: 502.5541114722541 and parameters: {'eta': 0.8419333976743137, 'max_depth': 11, 'n_estimators': 115, 'gamma': 0.98758894173913, 'lambda': 0.40986109442266816, 'alpha': 0.18329844438947973}. Best is trial 1 with value: 385.58132285995805.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:03:11,571]\u001b[0m Trial 6 finished with value: 407.6658642913706 and parameters: {'eta': 0.27836684898872377, 'max_depth': 9, 'n_estimators': 157, 'gamma': 0.8207513429699044, 'lambda': 0.13886642710810426, 'alpha': 0.2633413578162749}. Best is trial 1 with value: 385.58132285995805.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:04:05,712]\u001b[0m Trial 7 finished with value: 410.7581579383196 and parameters: {'eta': 0.19567479315954117, 'max_depth': 11, 'n_estimators': 165, 'gamma': 0.8958439330480388, 'lambda': 0.058865921313795186, 'alpha': 0.395831171368637}. Best is trial 1 with value: 385.58132285995805.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:04:42,717]\u001b[0m Trial 8 finished with value: 490.8807933978972 and parameters: {'eta': 0.790520944651379, 'max_depth': 15, 'n_estimators': 139, 'gamma': 0.9536846441190027, 'lambda': 0.2989929958967444, 'alpha': 0.34772984324113393}. Best is trial 1 with value: 385.58132285995805.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:05:14,107]\u001b[0m Trial 9 finished with value: 466.3973410062788 and parameters: {'eta': 0.517466473015899, 'max_depth': 11, 'n_estimators': 163, 'gamma': 0.5654539130761359, 'lambda': 0.38598569764469914, 'alpha': 0.06790054998940168}. Best is trial 1 with value: 385.58132285995805.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:05:32,141]\u001b[0m Trial 10 finished with value: 384.9483192892662 and parameters: {'eta': 0.040580521732963504, 'max_depth': 6, 'n_estimators': 199, 'gamma': 0.048594749757944866, 'lambda': 0.04312136375875453, 'alpha': 0.4922811422458214}. Best is trial 10 with value: 384.9483192892662.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:05:54,834]\u001b[0m Trial 11 finished with value: 385.0582051987584 and parameters: {'eta': 0.017493962241014533, 'max_depth': 6, 'n_estimators': 198, 'gamma': 0.07478599121005548, 'lambda': 0.014836021657790098, 'alpha': 0.4886339581561613}. Best is trial 10 with value: 384.9483192892662.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:06:26,030]\u001b[0m Trial 12 finished with value: 636.7312395524712 and parameters: {'eta': 0.0028960459451350187, 'max_depth': 6, 'n_estimators': 199, 'gamma': 0.018149360536698328, 'lambda': 0.015459712941053609, 'alpha': 0.4201617451440953}. Best is trial 10 with value: 384.9483192892662.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:07:10,105]\u001b[0m Trial 13 finished with value: 414.9299519152858 and parameters: {'eta': 0.35673372650535845, 'max_depth': 7, 'n_estimators': 199, 'gamma': 0.12134058669853781, 'lambda': 0.14496461732926783, 'alpha': 0.48763074911429183}. Best is trial 10 with value: 384.9483192892662.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:07:47,894]\u001b[0m Trial 14 finished with value: 393.5944023745636 and parameters: {'eta': 0.056142677805974914, 'max_depth': 8, 'n_estimators': 191, 'gamma': 0.294365560100873, 'lambda': 0.12356654156958373, 'alpha': 0.4972412620877727}. Best is trial 10 with value: 384.9483192892662.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:07:59,376]\u001b[0m Trial 15 finished with value: 563.1152497634025 and parameters: {'eta': 0.9825285660180979, 'max_depth': 5, 'n_estimators': 54, 'gamma': 0.0375378113697019, 'lambda': 0.016837374725615, 'alpha': 0.41368225786713375}. Best is trial 10 with value: 384.9483192892662.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:08:46,784]\u001b[0m Trial 16 finished with value: 398.52921916515663 and parameters: {'eta': 0.17295856254563452, 'max_depth': 9, 'n_estimators': 182, 'gamma': 0.33347839460116296, 'lambda': 0.4905662858868652, 'alpha': 0.34890152596207163}. Best is trial 10 with value: 384.9483192892662.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:08:55,659]\u001b[0m Trial 17 finished with value: 407.7717143300032 and parameters: {'eta': 0.33330733955710257, 'max_depth': 2, 'n_estimators': 181, 'gamma': 0.14899491656014807, 'lambda': 0.07109291643684937, 'alpha': 0.4348650718134136}. Best is trial 10 with value: 384.9483192892662.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:09:05,117]\u001b[0m Trial 18 finished with value: 714.0248351147931 and parameters: {'eta': 0.007522688684613322, 'max_depth': 7, 'n_estimators': 55, 'gamma': 0.014722029146575763, 'lambda': 0.19346768363770803, 'alpha': 0.11931623538399816}. Best is trial 10 with value: 384.9483192892662.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 18:09:27,082]\u001b[0m Trial 19 finished with value: 410.4810406787483 and parameters: {'eta': 0.22760078801112188, 'max_depth': 4, 'n_estimators': 183, 'gamma': 0.2100353705170388, 'lambda': 0.019659661001402803, 'alpha': 0.3580902722823053}. Best is trial 10 with value: 384.9483192892662.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# hyperparam tuning for XGBoost Regressor\n",
    "def xgradboosting_objective(trial):\n",
    "    \n",
    "    eta = trial.suggest_uniform('eta', 0+sys.float_info.min, 1.0)\n",
    "    max_depth = trial.suggest_int('max_depth', min_max_depth, max_max_depth)\n",
    "    n_estimators = trial.suggest_int('n_estimators', min_n_estimators, max_n_estimators)\n",
    "    \n",
    "    gamma = trial.suggest_float('gamma', 0.01, 1.0)\n",
    "    reg_lambda = trial.suggest_uniform('lambda', 0.01, 0.5)\n",
    "    reg_alpha = trial.suggest_uniform('alpha', 0.01, 0.5)\n",
    "\n",
    "    gb_xgb_opt = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "                                  booster='gbtree',\n",
    "                                  learning_rate=eta,\n",
    "                                  gamma=gamma,\n",
    "                                  reg_alpha=reg_alpha,\n",
    "                                  reg_lambda=reg_lambda,\n",
    "                                  max_depth=max_depth,\n",
    "                                  n_estimators=n_estimators,\n",
    "                                  random_state=random_state,\n",
    "                                  verbosity=verbose\n",
    "                                 )\n",
    "\n",
    "    gb_xgb_opt = gb_xgb_opt.fit(x_train, y_train)\n",
    "    y_val_pred = gb_xgb_opt.predict(x_val)\n",
    "    \n",
    "    return math.sqrt(metrics.mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "\n",
    "gb_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "gb_optuna.optimize(xgradboosting_objective, n_trials=budget)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['gradient_boosting'] = summary['gradient_boosting'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': gb_optuna.best_value,\n",
    "    'Learning rate': gb_optuna.best_params['eta'],\n",
    "    'Max. depth': gb_optuna.best_params['max_depth'],\n",
    "    'Gamma (min_split_loss)': gb_optuna.best_params['gamma'],\n",
    "    'Lambda': gb_optuna.best_params['lambda'],\n",
    "    'Alpha': gb_optuna.best_params['alpha'],\n",
    "    'N. estimators': gb_optuna.best_params['n_estimators']  \n",
    "    },\n",
    "    name='optuna_xgboost'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time (sec)</th>\n",
       "      <th>Score (RMSE)</th>\n",
       "      <th>N. neighbors</th>\n",
       "      <th>Weights</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>0.1176</td>\n",
       "      <td>455.123868</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optuna</th>\n",
       "      <td>33.7278</td>\n",
       "      <td>424.954880</td>\n",
       "      <td>11</td>\n",
       "      <td>distance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time (sec)  Score (RMSE) N. neighbors   Weights  P\n",
       "default     0.1176    455.123868            5   uniform  2\n",
       "optuna     33.7278    424.954880           11  distance  1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary['knn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time (sec)</th>\n",
       "      <th>Score (RMSE)</th>\n",
       "      <th>Min. samples split</th>\n",
       "      <th>Criterion</th>\n",
       "      <th>Max. depth</th>\n",
       "      <th>N. estimators</th>\n",
       "      <th>Max. features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>82.5335</td>\n",
       "      <td>375.560721</td>\n",
       "      <td>2</td>\n",
       "      <td>mse</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optuna</th>\n",
       "      <td>233.6654</td>\n",
       "      <td>374.129312</td>\n",
       "      <td>0.00872</td>\n",
       "      <td>mse</td>\n",
       "      <td>None</td>\n",
       "      <td>171</td>\n",
       "      <td>0.667976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optuna</th>\n",
       "      <td>1031.8257</td>\n",
       "      <td>373.977008</td>\n",
       "      <td>0.00742</td>\n",
       "      <td>mae</td>\n",
       "      <td>NaN</td>\n",
       "      <td>101</td>\n",
       "      <td>sqrt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time (sec)  Score (RMSE) Min. samples split Criterion Max. depth  \\\n",
       "default    82.5335    375.560721                  2       mse       None   \n",
       "optuna    233.6654    374.129312            0.00872       mse       None   \n",
       "optuna   1031.8257    373.977008            0.00742       mae        NaN   \n",
       "\n",
       "        N. estimators Max. features  \n",
       "default           100             1  \n",
       "optuna            171      0.667976  \n",
       "optuna            101          sqrt  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary['random_forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time (sec)</th>\n",
       "      <th>Score (RMSE)</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Gamma (min_split_loss)</th>\n",
       "      <th>Lambda</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Max. depth</th>\n",
       "      <th>N. estimators</th>\n",
       "      <th>Criterion</th>\n",
       "      <th>Max. leaf nodes</th>\n",
       "      <th>Min. samples leaf</th>\n",
       "      <th>Min. samples split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>51.8050</td>\n",
       "      <td>389.223359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default_xgboost</th>\n",
       "      <td>12.0105</td>\n",
       "      <td>409.802870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optuna_sklearn</th>\n",
       "      <td>1600.0196</td>\n",
       "      <td>373.503153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.130121</td>\n",
       "      <td>10.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optuna_xgboost</th>\n",
       "      <td>275.7636</td>\n",
       "      <td>384.920573</td>\n",
       "      <td>0.161185</td>\n",
       "      <td>0.745587</td>\n",
       "      <td>0.202009</td>\n",
       "      <td>0.068384</td>\n",
       "      <td>2.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time (sec)  Score (RMSE)     Alpha  Gamma (min_split_loss)  \\\n",
       "default            51.8050    389.223359       NaN                     NaN   \n",
       "default_xgboost    12.0105    409.802870  0.000000                0.000000   \n",
       "optuna_sklearn   1600.0196    373.503153       NaN                     NaN   \n",
       "optuna_xgboost    275.7636    384.920573  0.161185                0.745587   \n",
       "\n",
       "                   Lambda  Learning rate  Max. depth  N. estimators  \\\n",
       "default               NaN       0.100000         3.0          100.0   \n",
       "default_xgboost  1.000000       0.300000         6.0          100.0   \n",
       "optuna_sklearn        NaN       0.130121        10.0           60.0   \n",
       "optuna_xgboost   0.202009       0.068384         2.0          181.0   \n",
       "\n",
       "                    Criterion Max. leaf nodes  Min. samples leaf  \\\n",
       "default          friedman_mse            None                1.0   \n",
       "default_xgboost           NaN               0                NaN   \n",
       "optuna_sklearn   friedman_mse               9                1.0   \n",
       "optuna_xgboost            NaN             NaN                NaN   \n",
       "\n",
       "                 Min. samples split  \n",
       "default                         2.0  \n",
       "default_xgboost                 NaN  \n",
       "optuna_sklearn                  NaN  \n",
       "optuna_xgboost                  NaN  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary['gradient_boosting'].sort_index(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666.6691142412727"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dummy regressor(mean)\n",
    "math.sqrt(metrics.mean_squared_error(y_val, [y_val.mean() for i in range(len(y_val))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ATTRIBUTE SELECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Select from all attributes\n",
    "\n",
    "**Are all 550 input attributes actually necessary in order to get a good model? Is it possible to have an accurate model that uses fewer than 550 variables? How many?**\n",
    "\n",
    "For this question we will be using the best model we had in previous section and now include the parameter for select only certain attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_depth = 2\n",
    "max_max_depth = 15\n",
    "min_n_estimators = 50\n",
    "max_n_estimators = 200\n",
    "min_n_k = 10\n",
    "max_n_k = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-13 13:59:52,067]\u001b[0m A new study created in memory with name: no-name-f677b493-b3e6-48bb-87d6-43f34315514d\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:00:57,538]\u001b[0m Trial 0 finished with value: 444.03711882821585 and parameters: {'k': 59, 'min_samples_split': 0.31820927889533557, 'criterion': 'mae', 'max_depth': 15, 'n_estimators': 77, 'max_features': 'auto'}. Best is trial 0 with value: 444.03711882821585.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:00:58,050]\u001b[0m Trial 1 finished with value: 719.5022353639617 and parameters: {'k': 51, 'min_samples_split': 0.6987448939434953, 'criterion': 'mae', 'max_depth': 4, 'n_estimators': 176, 'max_features': 'auto'}. Best is trial 0 with value: 444.03711882821585.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:00:58,225]\u001b[0m Trial 2 finished with value: 668.4403422905759 and parameters: {'k': 188, 'min_samples_split': 0.8572131246824229, 'criterion': 'mse', 'max_depth': 2, 'n_estimators': 106, 'max_features': 'auto'}. Best is trial 0 with value: 444.03711882821585.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:03:25,676]\u001b[0m Trial 3 finished with value: 504.5863099089383 and parameters: {'k': 239, 'min_samples_split': 0.5580079987140251, 'criterion': 'mae', 'max_depth': 2, 'n_estimators': 86, 'max_features': 'auto'}. Best is trial 0 with value: 444.03711882821585.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:03:55,160]\u001b[0m Trial 4 finished with value: 429.23863688331056 and parameters: {'k': 252, 'min_samples_split': 0.414790192921739, 'criterion': 'mae', 'max_depth': 9, 'n_estimators': 156, 'max_features': 'sqrt'}. Best is trial 4 with value: 429.23863688331056.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:03:55,630]\u001b[0m Trial 5 finished with value: 528.2748767736183 and parameters: {'k': 180, 'min_samples_split': 0.6169346723309619, 'criterion': 'mse', 'max_depth': 7, 'n_estimators': 163, 'max_features': 'sqrt'}. Best is trial 4 with value: 429.23863688331056.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:03:55,724]\u001b[0m Trial 6 finished with value: 664.6526562333632 and parameters: {'k': 132, 'min_samples_split': 0.6470797517086144, 'criterion': 'mse', 'max_depth': 28, 'n_estimators': 54, 'max_features': 'sqrt'}. Best is trial 4 with value: 429.23863688331056.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:03:56,177]\u001b[0m Trial 7 finished with value: 508.41769478034865 and parameters: {'k': 178, 'min_samples_split': 0.5544594994309043, 'criterion': 'mse', 'max_depth': 21, 'n_estimators': 181, 'max_features': 'log2'}. Best is trial 4 with value: 429.23863688331056.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:04:19,414]\u001b[0m Trial 8 finished with value: 457.5337259369224 and parameters: {'k': 191, 'min_samples_split': 0.13384702543508287, 'criterion': 'mae', 'max_depth': 3, 'n_estimators': 143, 'max_features': 'sqrt'}. Best is trial 4 with value: 429.23863688331056.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:04:44,059]\u001b[0m Trial 9 finished with value: 428.7503186915439 and parameters: {'k': 236, 'min_samples_split': 0.0352297665222594, 'criterion': 'mae', 'max_depth': 3, 'n_estimators': 128, 'max_features': 'sqrt'}. Best is trial 9 with value: 428.7503186915439.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:04:55,520]\u001b[0m Trial 10 finished with value: 440.486065220071 and parameters: {'k': 111, 'min_samples_split': 0.08177742159457267, 'criterion': 'mae', 'max_depth': 4, 'n_estimators': 123, 'max_features': 'log2'}. Best is trial 9 with value: 428.7503186915439.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:05:33,407]\u001b[0m Trial 11 finished with value: 413.210766994515 and parameters: {'k': 273, 'min_samples_split': 0.3102503141152435, 'criterion': 'mae', 'max_depth': 9, 'n_estimators': 145, 'max_features': 'sqrt'}. Best is trial 11 with value: 413.210766994515.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:06:12,700]\u001b[0m Trial 12 finished with value: 414.8095303847707 and parameters: {'k': 266, 'min_samples_split': 0.23622935719523852, 'criterion': 'mae', 'max_depth': 11, 'n_estimators': 133, 'max_features': 'sqrt'}. Best is trial 11 with value: 413.210766994515.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:06:50,756]\u001b[0m Trial 13 finished with value: 413.7885828739367 and parameters: {'k': 271, 'min_samples_split': 0.26940567473030785, 'criterion': 'mae', 'max_depth': 12, 'n_estimators': 134, 'max_features': 'sqrt'}. Best is trial 11 with value: 413.210766994515.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:07:36,348]\u001b[0m Trial 14 finished with value: 420.7151876526134 and parameters: {'k': 271, 'min_samples_split': 0.36228216108641814, 'criterion': 'mae', 'max_depth': 14, 'n_estimators': 199, 'max_features': 'sqrt'}. Best is trial 11 with value: 413.210766994515.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:08:02,266]\u001b[0m Trial 15 finished with value: 430.9361850463441 and parameters: {'k': 217, 'min_samples_split': 0.23105468459545253, 'criterion': 'mae', 'max_depth': 6, 'n_estimators': 109, 'max_features': 'sqrt'}. Best is trial 11 with value: 413.210766994515.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:08:16,902]\u001b[0m Trial 16 finished with value: 441.8005297382076 and parameters: {'k': 272, 'min_samples_split': 0.4425683377434313, 'criterion': 'mae', 'max_depth': 22, 'n_estimators': 151, 'max_features': 'log2'}. Best is trial 11 with value: 413.210766994515.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:08:34,439]\u001b[0m Trial 17 finished with value: 438.8438489165108 and parameters: {'k': 99, 'min_samples_split': 0.19794144217269088, 'criterion': 'mae', 'max_depth': 7, 'n_estimators': 107, 'max_features': 'sqrt'}. Best is trial 11 with value: 413.210766994515.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:09:17,801]\u001b[0m Trial 18 finished with value: 435.2179382678843 and parameters: {'k': 216, 'min_samples_split': 0.30966457509084183, 'criterion': 'mae', 'max_depth': 14, 'n_estimators': 195, 'max_features': 'sqrt'}. Best is trial 11 with value: 413.210766994515.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 14:09:39,774]\u001b[0m Trial 19 finished with value: 471.58824124177477 and parameters: {'k': 155, 'min_samples_split': 0.48048219338820686, 'criterion': 'mae', 'max_depth': 10, 'n_estimators': 167, 'max_features': 'sqrt'}. Best is trial 11 with value: 413.210766994515.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587.7053737640381\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(random_state)\n",
    "def random_forest_objective_attr(trial):\n",
    "    k = trial.suggest_int('k', min_n_k, max_n_k)\n",
    "    min_samples_split = trial.suggest_uniform('min_samples_split', 0+sys.float_info.min, 1)\n",
    "    criterion = trial.suggest_categorical('criterion', ['mse','mae'])\n",
    "    max_depth = trial.suggest_int('max_depth', min_max_depth, max_max_depth, log=True)\n",
    "    n_estimators = trial.suggest_int('n_estimators', min_n_estimators, max_n_estimators)\n",
    "    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2'])\n",
    "\n",
    "    clf = Pipeline([\n",
    "      ('feature_selection', feature_selection.SelectKBest(feature_selection.f_regression, k=k)),\n",
    "      ('regression', ensemble.RandomForestRegressor(\n",
    "          random_state=random_state,\n",
    "          min_samples_split=min_samples_split,\n",
    "          criterion=criterion,\n",
    "          max_depth=max_depth,\n",
    "          n_estimators=n_estimators,\n",
    "          max_features=max_features\n",
    "      ))\n",
    "    ])\n",
    "\n",
    "    clf = clf.fit(x_train, y_train)\n",
    "    y_val_pred = clf.predict(x_val)\n",
    "    return math.sqrt(metrics.mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "rf_attr_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "rf_attr_optuna.optimize(random_forest_objective_attr, n_trials=budget, n_jobs=n_jobs)\n",
    "end_time = time.time()\n",
    "print(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 273, 'min_samples_split': 0.3102503141152435, 'criterion': 'mae', 'max_depth': 9, 'n_estimators': 145, 'max_features': 'sqrt'} 413.210766994515\n"
     ]
    }
   ],
   "source": [
    "#TODO: Conclusions\n",
    "print(rf_attr_optuna.best_params, rf_attr_optuna.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Use only Sotavento attributes\n",
    "**Is it enough to use only the attributes for the actual Sotavento location? (13th location in the grid)**\n",
    "\n",
    "We will select only Sotavento attributes and use the best model in previous section to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2528, 22) (1299, 22) (2110, 22)\n"
     ]
    }
   ],
   "source": [
    "sot_attr = []\n",
    "for attr in x_train.columns:\n",
    "    if int(attr.split('.')[-1]) == 13:\n",
    "        sot_attr.append(attr)\n",
    "\n",
    "x_train_sot = x_train[sot_attr]\n",
    "x_val_sot = x_val[sot_attr]\n",
    "x_test_sot = x_test[sot_attr]\n",
    "print(x_train_sot.shape,x_val_sot.shape,x_test_sot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-13 16:34:56,851]\u001b[0m A new study created in memory with name: no-name-f4f69465-2c2a-4495-bc8d-3e9ad3f30b8f\u001b[0m\n",
      "\u001b[33m[W 2021-01-13 16:34:56,861]\u001b[0m Trial 0 failed because of the following error: NameError(\"name 'x_train_sot' is not defined\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fddcampos/.local/lib/python3.8/site-packages/optuna/_optimize.py\", line 189, in _run_trial\n",
      "    value = func(trial)\n",
      "  File \"<ipython-input-14-c360c6436cc6>\", line 18, in random_forest_sot_objective\n",
      "    clf = clf.fit(x_train_sot, y_train)\n",
      "NameError: name 'x_train_sot' is not defined\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_train_sot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c360c6436cc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mrf_sot_optuna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minimize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mrf_sot_optuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_forest_sot_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbudget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    304\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \"\"\"\n\u001b[0;32m--> 306\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m# Register the last intermediate value if present as the value of the trial.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-c360c6436cc6>\u001b[0m in \u001b[0;36mrandom_forest_sot_objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     16\u001b[0m         )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_sot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0my_val_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val_sot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train_sot' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(random_state)\n",
    "def random_forest_sot_objective(trial):\n",
    "    min_samples_split = trial.suggest_uniform('min_samples_split', 0+sys.float_info.min, 1)\n",
    "    criterion = trial.suggest_categorical('criterion', ['mse','mae'])\n",
    "    max_depth = trial.suggest_int('max_depth', min_max_depth, max_max_depth)\n",
    "    n_estimators = trial.suggest_int('n_estimators', min_n_estimators, max_n_estimators)\n",
    "    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2'])\n",
    "\n",
    "    clf = ensemble.RandomForestRegressor(\n",
    "        random_state=random_state,\n",
    "        min_samples_split=min_samples_split,\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        n_estimators=n_estimators,\n",
    "        max_features=max_features\n",
    "        )\n",
    "\n",
    "    clf = clf.fit(x_train_sot, y_train)\n",
    "    y_val_pred = clf.predict(x_val_sot)\n",
    "    return math.sqrt(metrics.mean_squared_error(y_val, y_val_pred))\n",
    "\n",
    "rf_sot_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "rf_sot_optuna.optimize(random_forest_sot_objective, n_trials=budget, n_jobs=n_jobs)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Conclusions\n",
    "print(rf_sot_optuna.best_params, rf_sot_optuna.best_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
