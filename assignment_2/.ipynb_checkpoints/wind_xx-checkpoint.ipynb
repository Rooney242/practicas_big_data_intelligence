{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wind prediction - Second assignment\n",
    "\n",
    "## Authors\n",
    "\n",
    "David Moreno Maldonado 100441714     \n",
    "Inés Fernández Campos 100443936"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/fddcampos/Documents/uc3m/2_term/BDINTELLIGENCE/practicas_big_data_intelligence/assignment_2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import some libraries\n",
    "import os\n",
    "import numpy as np              \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn import preprocessing, impute, model_selection, neighbors, ensemble\n",
    "import optuna\n",
    "import optuna.visualization as ov\n",
    "import xgboost as xgb\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN PARAMETERS FOR THE ASSIGNMENT\n",
    "budget = 20\n",
    "random_state = 0\n",
    "verbose = 0\n",
    "\n",
    "#PARAMETERS FOR THE HYPER-PARAMETER TUNNING\n",
    "#KNN\n",
    "min_n_neigbors = 1\n",
    "max_n_neigbors = 16\n",
    "\n",
    "#RANDOM FOREST\n",
    "min_max_depth = 2\n",
    "max_max_depth = 20\n",
    "min_n_estimators = 50\n",
    "max_n_estimators = 200\n",
    "\n",
    "#GRADIENT BOOSTING\n",
    "min_max_leaf_nodes = 2\n",
    "max_max_leaf_nodes = 20\n",
    "min_min_samples_leaf = 1\n",
    "max_min_samples_leaf = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"wind_pickle\" file contains data in a binary format called \"Pickle\". Pickle data loads faster than text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle('wind_pickle.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the attributes in the dataset. Very important, the output attribute (i.e. the value to be predicted, **energy**, is the first attribute). **Steps** represents the hours in advance of the forecast. We will not use this variable here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5937, 556)\n"
     ]
    }
   ],
   "source": [
    "# The dataset contains 5937 instances and 556 attributes (including the outcome to be predicted)\n",
    "print(data.shape)\n",
    "#data.columns.values.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-1 for training, 0 for validation, 1 for testing\n",
    "year_to_part = {\n",
    "    2005: -1,\n",
    "    2006: -1,\n",
    "    2007: 0,\n",
    "    2008: 0, \n",
    "    2009: 1,\n",
    "    2010: 1\n",
    "}\n",
    "data['partition'] = data['year'].apply(lambda x: year_to_part[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now remove the columns that cannot be used for training the models from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps, month, day, hour, year should be removed, they cannot be used for training the models\n",
    "to_remove = ['steps', 'month', 'year', 'day', 'hour']\n",
    "for m in to_remove: data = data.drop(m, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets put 163861 missing values \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import randint\n",
    "\n",
    "# we add na values at random\n",
    "my_NIA = 100443936 + 100441714\n",
    "np.random.seed(my_NIA)\n",
    "\n",
    "how_many_nas = round(data.shape[0]*data.shape[1]*0.05)\n",
    "print('Lets put '+str(how_many_nas)+' missing values \\n')\n",
    "x_locations = randint(0, data.shape[0], size=how_many_nas)\n",
    "y_locations = randint(1, data.shape[1]-2, size=how_many_nas)\n",
    "\n",
    "for i in range(len(x_locations)):\n",
    "    data.iat[x_locations[i], y_locations[i]] = np.nan\n",
    "    \n",
    "data.to_pickle('wind_pickle_with_nan.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point on, the file wind_pickle_with_nan should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5937, 552)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('wind_pickle_with_nan.pickle')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().values.any())\n",
    "input_cols = data.columns.difference(['energy', 'partition'])\n",
    "x = data[input_cols]\n",
    "#Iterative imputer (takes too long)\n",
    "'''iter_imp = impute.IterativeImputer(random_state=random_state, \n",
    "                                   initial_strategy='median', \n",
    "                                   max_iter=3,\n",
    "                                   verbose=verbose)\n",
    "no_nan = iter_imp.fit_transform(x)'''\n",
    "\n",
    "#KNN imputer(takes too long)\n",
    "'''knn_imp = impute.KNNImputer(weights='distance')\n",
    "no_nan = knn_imp.fit_transform(x)'''\n",
    "\n",
    "#Simple imputer\n",
    "simp_imp = impute.SimpleImputer(strategy='median',\n",
    "                               verbose=2)\n",
    "no_nan = simp_imp.fit_transform(x)\n",
    "\n",
    "data[input_cols] = pd.DataFrame(data=no_nan)\n",
    "print(data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(data[input_cols]) \n",
    "data[input_cols] = scaler.transform(data[input_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split\n",
    "We are going to use train/test for model evaluation (outer) and train/validation for hyperparameter tuning (inner), as follows:     \n",
    "1. Train partition: the first two years of data. Given that there are 6 years worth of data, we will use the first 2/6 of the instances for training.     \n",
    "2. Validation partition: the second two years of data. \n",
    "3. Test partition: the remaining data    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-1 for training, 0 for validation, 1 for testing\n",
    "test = data[data['partition'] == 1]\n",
    "train = data[data['partition'] != 1]\n",
    "tr_val_partition = model_selection.PredefinedSplit(train['partition'].tolist())\n",
    "\n",
    "del test['partition']\n",
    "del train['partition']\n",
    "\n",
    "y_test = test['energy']\n",
    "x_test = test[test.columns.difference(['energy'])]\n",
    "\n",
    "y_train = train['energy']\n",
    "x_train = train[train.columns.difference(['energy'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert the training and test sets from Pandas DataFrames to Numpy matrices, so that they can be used by scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_x_train = np.matrix(x_train)\n",
    "mat_y_train = np.matrix(y_train).T\n",
    "mat_x_test = np.matrix(x_test)\n",
    "mat_y_test = np.matrix(y_test).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MODEL SELECTION AND HYPER-PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframes with all the information of each model\n",
    "summary = {\n",
    "    'knn': pd.DataFrame(columns=['Time (sec)', 'Score (RMSE)', 'N. neighbors', 'Weights', 'P']),\n",
    "    'random_forest': pd.DataFrame(columns=['Time (sec)', 'Score (RMSE)', 'Min. samples split', 'Criterion', 'Max. depth', 'N. estimators','Max. features']),\n",
    "    'gradient_boosting': pd.DataFrame(columns=['Time (sec)', 'Score (RMSE)'])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Default hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_state)\n",
    "knn_default = neighbors.KNeighborsRegressor()\n",
    "\n",
    "start_time = time.time()\n",
    "scores = -model_selection.cross_val_score(knn_default, x_train, y_train,\n",
    "                                          scoring='neg_root_mean_squared_error',\n",
    "                                          cv=tr_val_partition,\n",
    "                                          verbose=verbose) \n",
    "end_time = time.time()\n",
    "\n",
    "summary['knn'] = summary['knn'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': scores.mean(), \n",
    "    'N. neighbors': 5, \n",
    "    'Weights': 'uniform', \n",
    "    'P': 2\n",
    "    }, \n",
    "    name='default'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Hyper-parameter tunning (OPTUNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:39:31,240]\u001b[0m A new study created in memory with name: no-name-ec2f521e-b91a-437a-b743-0fb883f9735a\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:39:36,424]\u001b[0m Trial 0 finished with value: 434.58474235770177 and parameters: {'n_neighbors': 15, 'weights': 'uniform', 'p': 2}. Best is trial 0 with value: 434.58474235770177.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:39:42,500]\u001b[0m Trial 1 finished with value: 427.1897361344681 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'p': 1}. Best is trial 1 with value: 427.1897361344681.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:39:47,733]\u001b[0m Trial 2 finished with value: 436.66754039946005 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'p': 2}. Best is trial 1 with value: 427.1897361344681.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:39:53,542]\u001b[0m Trial 3 finished with value: 441.1599884529427 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'p': 1}. Best is trial 1 with value: 427.1897361344681.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:39:59,120]\u001b[0m Trial 4 finished with value: 432.0797327508031 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'p': 1}. Best is trial 1 with value: 427.1897361344681.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:04,894]\u001b[0m Trial 5 finished with value: 425.8532193925109 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'p': 1}. Best is trial 5 with value: 425.8532193925109.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:10,651]\u001b[0m Trial 6 finished with value: 429.05463080771233 and parameters: {'n_neighbors': 16, 'weights': 'uniform', 'p': 1}. Best is trial 5 with value: 425.8532193925109.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:15,152]\u001b[0m Trial 7 finished with value: 474.762900447833 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'p': 2}. Best is trial 5 with value: 425.8532193925109.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:19,526]\u001b[0m Trial 8 finished with value: 512.2417177624698 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'p': 2}. Best is trial 5 with value: 425.8532193925109.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:25,028]\u001b[0m Trial 9 finished with value: 426.6970286295103 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'p': 1}. Best is trial 5 with value: 425.8532193925109.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:31,012]\u001b[0m Trial 10 finished with value: 425.4813377209308 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'p': 1}. Best is trial 10 with value: 425.4813377209308.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:36,982]\u001b[0m Trial 11 finished with value: 425.4813377209308 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'p': 1}. Best is trial 10 with value: 425.4813377209308.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:42,362]\u001b[0m Trial 12 finished with value: 425.3455575639307 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'p': 1}. Best is trial 12 with value: 425.3455575639307.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:47,716]\u001b[0m Trial 13 finished with value: 425.3455575639307 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'p': 1}. Best is trial 12 with value: 425.3455575639307.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:53,068]\u001b[0m Trial 14 finished with value: 425.09591854856325 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'p': 1}. Best is trial 14 with value: 425.09591854856325.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:58,355]\u001b[0m Trial 15 finished with value: 437.64527002872245 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'p': 1}. Best is trial 14 with value: 425.09591854856325.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:41:04,131]\u001b[0m Trial 16 finished with value: 425.09591854856325 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'p': 1}. Best is trial 14 with value: 425.09591854856325.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:41:09,376]\u001b[0m Trial 17 finished with value: 451.51235760509013 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'p': 1}. Best is trial 14 with value: 425.09591854856325.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:41:14,867]\u001b[0m Trial 18 finished with value: 425.09591854856325 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'p': 1}. Best is trial 14 with value: 425.09591854856325.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:41:20,745]\u001b[0m Trial 19 finished with value: 429.3973607287476 and parameters: {'n_neighbors': 14, 'weights': 'uniform', 'p': 1}. Best is trial 14 with value: 425.09591854856325.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(random_state)\n",
    "def knn_objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', min_n_neigbors, max_n_neigbors)\n",
    "    weights = trial.suggest_categorical('weights', ['uniform','distance'])\n",
    "    p = trial.suggest_categorical('p', [1, 2])\n",
    "\n",
    "    clf = neighbors.KNeighborsRegressor(\n",
    "        n_neighbors=n_neighbors,\n",
    "        weights=weights,\n",
    "        p=p)\n",
    "\n",
    "    scores = -model_selection.cross_val_score(clf, x_train, y_train,\n",
    "        cv=tr_val_partition,\n",
    "        scoring='neg_root_mean_squared_error')\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "knn_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "knn_optuna.optimize(knn_objective, n_trials=budget)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['knn'] = summary['knn'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': knn_optuna.best_value, \n",
    "    'N. neighbors': knn_optuna.best_params['n_neighbors'], \n",
    "    'Weights': knn_optuna.best_params['weights'], \n",
    "    'P': knn_optuna.best_params['p']\n",
    "    }, \n",
    "    name='optuna'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Default hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_state)\n",
    "rf_default = ensemble.RandomForestRegressor(random_state=random_state, verbose=verbose)\n",
    "\n",
    "start_time = time.time()\n",
    "scores = -model_selection.cross_val_score(rf_default, x_train, y_train,\n",
    "                                          scoring='neg_root_mean_squared_error',\n",
    "                                          cv=tr_val_partition,\n",
    "                                          verbose=verbose)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['random_forest'] = summary['random_forest'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': scores.mean(),\n",
    "    'Min. samples split': 2, \n",
    "    'Criterion': 'mse', \n",
    "    'Max. depth': 'None',\n",
    "    'N. estimators': 100,\n",
    "    'Max. features': 1\n",
    "    },\n",
    "    name='default'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Hyper-parameter tunning (OPTUNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:19:15,385]\u001b[0m A new study created in memory with name: no-name-afbb499f-328b-4ec8-916e-41408b563fe5\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:19:15,507]\u001b[0m Trial 0 finished with value: 668.3157608288334 and parameters: {'min_samples_split': 0.8420626511506619, 'criterion': 'mse', 'max_depth': 11, 'n_estimators': 111, 'max_features': 0.22964889811063183}. Best is trial 0 with value: 668.3157608288334.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[668.31576083]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:19:15,953]\u001b[0m Trial 1 finished with value: 416.02693466304027 and parameters: {'min_samples_split': 0.22217725686158962, 'criterion': 'mse', 'max_depth': 10, 'n_estimators': 89, 'max_features': 0.014222760723832883}. Best is trial 1 with value: 416.02693466304027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[416.02693466]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:19:32,902]\u001b[0m Trial 2 finished with value: 397.0549870471909 and parameters: {'min_samples_split': 0.27608113381936805, 'criterion': 'friedman_mse', 'max_depth': 6, 'n_estimators': 195, 'max_features': 0.3254333086193524}. Best is trial 2 with value: 397.0549870471909.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:19:33,037]\u001b[0m Trial 3 finished with value: 668.3520154857824 and parameters: {'min_samples_split': 0.7155418283828904, 'criterion': 'mse', 'max_depth': 16, 'n_estimators': 133, 'max_features': 0.9539498563134007}. Best is trial 2 with value: 397.0549870471909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[397.05498705]\n",
      "[668.35201549]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:19:46,527]\u001b[0m Trial 4 finished with value: 439.6219384407865 and parameters: {'min_samples_split': 0.4973733826326475, 'criterion': 'friedman_mse', 'max_depth': 13, 'n_estimators': 132, 'max_features': 0.7543669851904506}. Best is trial 2 with value: 397.0549870471909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[439.62193844]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:19:50,193]\u001b[0m Trial 5 finished with value: 531.8125595160947 and parameters: {'min_samples_split': 0.5870028727181181, 'criterion': 'mse', 'max_depth': 7, 'n_estimators': 147, 'max_features': 0.3937671236597815}. Best is trial 2 with value: 397.0549870471909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[531.81255952]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:19:55,240]\u001b[0m Trial 6 finished with value: 398.4895565140924 and parameters: {'min_samples_split': 0.1961521278613999, 'criterion': 'mse', 'max_depth': 6, 'n_estimators': 134, 'max_features': 0.13840208553807065}. Best is trial 2 with value: 397.0549870471909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[398.48955651]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:19:56,503]\u001b[0m Trial 7 finished with value: 410.5623510360694 and parameters: {'min_samples_split': 0.2727794669539847, 'criterion': 'mse', 'max_depth': 18, 'n_estimators': 192, 'max_features': 0.021479311142142188}. Best is trial 2 with value: 397.0549870471909.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:19:56,596]\u001b[0m Trial 8 finished with value: 668.3138720807941 and parameters: {'min_samples_split': 0.9419565388143725, 'criterion': 'mse', 'max_depth': 16, 'n_estimators': 79, 'max_features': 0.14473233375850403}. Best is trial 2 with value: 397.0549870471909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[410.56235104]\n",
      "[668.31387208]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:20:13,588]\u001b[0m Trial 9 finished with value: 400.7885514258249 and parameters: {'min_samples_split': 0.3613713193049055, 'criterion': 'mse', 'max_depth': 5, 'n_estimators': 191, 'max_features': 0.4106695790225199}. Best is trial 2 with value: 397.0549870471909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400.78855143]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:20:32,533]\u001b[0m Trial 10 finished with value: 416.92737393683217 and parameters: {'min_samples_split': 0.012623405217639272, 'criterion': 'friedman_mse', 'max_depth': 3, 'n_estimators': 165, 'max_features': 0.6542220404285533}. Best is trial 2 with value: 397.0549870471909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[416.92737394]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:20:34,043]\u001b[0m Trial 11 finished with value: 458.77092445372074 and parameters: {'min_samples_split': 0.007491517955698135, 'criterion': 'friedman_mse', 'max_depth': 2, 'n_estimators': 51, 'max_features': 0.23840977483705364}. Best is trial 2 with value: 397.0549870471909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[458.77092445]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(random_state)\n",
    "def random_forest_objective(trial):\n",
    "    min_samples_split = trial.suggest_uniform('min_samples_split', 0+sys.float_info.min, 1)\n",
    "    criterion = trial.suggest_categorical('criterion', ['mse','friedman_mse'])\n",
    "    max_depth = trial.suggest_int('max_depth', min_max_depth, max_max_depth)\n",
    "    n_estimators = trial.suggest_int('n_estimators', min_n_estimators, max_n_estimators)\n",
    "    max_features = trial.suggest_uniform('max_features', 0+sys.float_info.min, 1)\n",
    "\n",
    "    clf = ensemble.RandomForestRegressor(\n",
    "        random_state=random_state,\n",
    "        min_samples_split=min_samples_split,\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        n_estimators=n_estimators,\n",
    "        max_features=max_features\n",
    "        )\n",
    "\n",
    "    scores = -model_selection.cross_val_score(clf, x_train, y_train,\n",
    "        cv=tr_val_partition,\n",
    "        scoring='neg_root_mean_squared_error')\n",
    "    print(scores)\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "rf_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "rf_optuna.optimize(random_forest_objective, n_trials=budget)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['random_forest'] = summary['random_forest'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': rf_optuna.best_value,\n",
    "    'Min. samples split': rf_optuna.best_params['min_samples_split'], \n",
    "    'Criterion': rf_optuna.best_params['criterion'], \n",
    "    'Max. depth': rf_optuna.best_params['max_depth'],\n",
    "    'N. estimators': rf_optuna.best_params['n_estimators'],\n",
    "    'Max. features': rf_optuna.best_params['max_features']\n",
    "    },\n",
    "    name='optuna'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Default hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation using sklearn\n",
    "np.random.seed(random_state)\n",
    "gb_sk_def = ensemble.GradientBoostingRegressor(random_state=random_state, verbose=verbose)\n",
    "\n",
    "start_time = time.time()\n",
    "scores = -model_selection.cross_val_score(gb_sk_def, x_train, y_train,\n",
    "                                          scoring='neg_root_mean_squared_error',\n",
    "                                          cv=tr_val_partition,\n",
    "                                          verbose=verbose)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['gradient_boosting'] = summary['gradient_boosting'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': scores.mean(),\n",
    "    'Learning rate': 0.1,\n",
    "    'N. estimators': 100,\n",
    "    'Criterion': 'friedman_mse', \n",
    "    'Min. samples split': 2, \n",
    "    'Min. samples leaf': 1,\n",
    "    'Max. depth': 3,\n",
    "    'Max. leaf nodes': 'None'\n",
    "    },\n",
    "    name='default_sklearn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation using xgboost\n",
    "dtrain = xgb.DMatrix(mat_x_train, label=mat_y_train)\n",
    "dtest = xgb.DMatrix(mat_x_test, label=mat_y_test)\n",
    "\n",
    "gb_xgb_def = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "start_time = time.time()\n",
    "scores = - model_selection.cross_val_score(gb_xgb_def, x_train, y_train,\n",
    "                                            cv=tr_val_partition,\n",
    "                                            scoring='neg_root_mean_squared_error')\n",
    "end_time = time.time()\n",
    "\n",
    "summary['gradient_boosting'] = summary['gradient_boosting'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': scores.mean(),\n",
    "    'Learning rate': 0.3,\n",
    "    'Max. depth': 6,\n",
    "    'Max. leaf nodes': 0,\n",
    "    'Gamma (min_split_loss)': 0,\n",
    "    'Lambda': 1,\n",
    "    'Alpha': 0,\n",
    "    'N. estimators': gb_xgb_def.get_params()['n_estimators']\n",
    "    },\n",
    "    name='default_xgboost'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Hyper-parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-13 10:31:34,015]\u001b[0m A new study created in memory with name: no-name-2860e01f-e44e-451f-89bb-701b42540c26\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:32:08,678]\u001b[0m Trial 0 finished with value: 415.6929906356532 and parameters: {'learning_rate': 0.5581843142559538, 'n_estimators': 61, 'min_samples_split': 0.6810553767188977, 'max_depth': 13, 'criterion': 'mse', 'min_samples_leaf': 9, 'max_leaf_nodes': 20}. Best is trial 0 with value: 415.6929906356532.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:33:02,370]\u001b[0m Trial 1 finished with value: 448.414630953337 and parameters: {'learning_rate': 0.7120867002666549, 'n_estimators': 99, 'min_samples_split': 0.5891413317574963, 'max_depth': 6, 'criterion': 'friedman_mse', 'min_samples_leaf': 3, 'max_leaf_nodes': 11}. Best is trial 0 with value: 415.6929906356532.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:34:15,713]\u001b[0m Trial 2 finished with value: 474.2649776097875 and parameters: {'learning_rate': 0.8300801503497136, 'n_estimators': 78, 'min_samples_split': 0.14873056751025882, 'max_depth': 8, 'criterion': 'mse', 'min_samples_leaf': 1, 'max_leaf_nodes': 15}. Best is trial 0 with value: 415.6929906356532.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:36:55,210]\u001b[0m Trial 3 finished with value: 387.70271183554735 and parameters: {'learning_rate': 0.28061892116910014, 'n_estimators': 181, 'min_samples_split': 0.35340331462678276, 'max_depth': 19, 'criterion': 'friedman_mse', 'min_samples_leaf': 6, 'max_leaf_nodes': 7}. Best is trial 3 with value: 387.70271183554735.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:37:58,430]\u001b[0m Trial 4 finished with value: 441.80175699866527 and parameters: {'learning_rate': 0.8970941102186111, 'n_estimators': 187, 'min_samples_split': 0.7911700533463608, 'max_depth': 15, 'criterion': 'friedman_mse', 'min_samples_leaf': 4, 'max_leaf_nodes': 3}. Best is trial 3 with value: 387.70271183554735.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:39:52,010]\u001b[0m Trial 5 finished with value: 383.37469976680836 and parameters: {'learning_rate': 0.13590934769150675, 'n_estimators': 194, 'min_samples_split': 0.7423806868961943, 'max_depth': 9, 'criterion': 'friedman_mse', 'min_samples_leaf': 4, 'max_leaf_nodes': 11}. Best is trial 5 with value: 383.37469976680836.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:42:38,078]\u001b[0m Trial 6 finished with value: 392.19902714772456 and parameters: {'learning_rate': 0.3448815305398293, 'n_estimators': 141, 'min_samples_split': 0.5694588632978107, 'max_depth': 19, 'criterion': 'friedman_mse', 'min_samples_leaf': 8, 'max_leaf_nodes': 19}. Best is trial 5 with value: 383.37469976680836.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:43:17,873]\u001b[0m Trial 7 finished with value: 392.40263088596515 and parameters: {'learning_rate': 0.19691170297688687, 'n_estimators': 120, 'min_samples_split': 0.20063729017221044, 'max_depth': 19, 'criterion': 'friedman_mse', 'min_samples_leaf': 2, 'max_leaf_nodes': 3}. Best is trial 5 with value: 383.37469976680836.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:47:07,568]\u001b[0m Trial 8 finished with value: 429.054516873644 and parameters: {'learning_rate': 0.6131077415470013, 'n_estimators': 166, 'min_samples_split': 0.1835494624909214, 'max_depth': 15, 'criterion': 'friedman_mse', 'min_samples_leaf': 6, 'max_leaf_nodes': 13}. Best is trial 5 with value: 383.37469976680836.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:49:10,476]\u001b[0m Trial 9 finished with value: 395.82694443274306 and parameters: {'learning_rate': 0.2801434213624211, 'n_estimators': 149, 'min_samples_split': 0.5509233643418185, 'max_depth': 11, 'criterion': 'friedman_mse', 'min_samples_leaf': 8, 'max_leaf_nodes': 15}. Best is trial 5 with value: 383.37469976680836.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:49:39,520]\u001b[0m Trial 10 finished with value: 389.59453743992714 and parameters: {'learning_rate': 0.08173649074377226, 'n_estimators': 196, 'min_samples_split': 0.9606174404804713, 'max_depth': 3, 'criterion': 'mse', 'min_samples_leaf': 4, 'max_leaf_nodes': 7}. Best is trial 5 with value: 383.37469976680836.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:51:52,793]\u001b[0m Trial 11 finished with value: 377.3941584276338 and parameters: {'learning_rate': 0.0572478186124713, 'n_estimators': 196, 'min_samples_split': 0.39791093305028824, 'max_depth': 8, 'criterion': 'friedman_mse', 'min_samples_leaf': 6, 'max_leaf_nodes': 8}. Best is trial 11 with value: 377.3941584276338.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:53:51,537]\u001b[0m Trial 12 finished with value: 375.2064329297455 and parameters: {'learning_rate': 0.02388997568532318, 'n_estimators': 198, 'min_samples_split': 0.377974863552156, 'max_depth': 7, 'criterion': 'friedman_mse', 'min_samples_leaf': 5, 'max_leaf_nodes': 8}. Best is trial 12 with value: 375.2064329297455.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:54:56,921]\u001b[0m Trial 13 finished with value: 379.16992983345006 and parameters: {'learning_rate': 0.03479079380214718, 'n_estimators': 168, 'min_samples_split': 0.37253862298953033, 'max_depth': 4, 'criterion': 'friedman_mse', 'min_samples_leaf': 7, 'max_leaf_nodes': 7}. Best is trial 12 with value: 375.2064329297455.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:56:22,603]\u001b[0m Trial 14 finished with value: 384.8171379517957 and parameters: {'learning_rate': 0.017989522826926653, 'n_estimators': 200, 'min_samples_split': 0.3711623166833741, 'max_depth': 6, 'criterion': 'friedman_mse', 'min_samples_leaf': 5, 'max_leaf_nodes': 5}. Best is trial 12 with value: 375.2064329297455.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:58:07,405]\u001b[0m Trial 15 finished with value: 420.4232846972663 and parameters: {'learning_rate': 0.4169096525586965, 'n_estimators': 165, 'min_samples_split': 0.04573549555943579, 'max_depth': 9, 'criterion': 'friedman_mse', 'min_samples_leaf': 10, 'max_leaf_nodes': 9}. Best is trial 12 with value: 375.2064329297455.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:58:34,903]\u001b[0m Trial 16 finished with value: 626.9558676392522 and parameters: {'learning_rate': 0.0012318675672648334, 'n_estimators': 123, 'min_samples_split': 0.4372021967098945, 'max_depth': 2, 'criterion': 'friedman_mse', 'min_samples_leaf': 5, 'max_leaf_nodes': 9}. Best is trial 12 with value: 375.2064329297455.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 10:59:06,365]\u001b[0m Trial 17 finished with value: 389.8654323862706 and parameters: {'learning_rate': 0.1853868199274208, 'n_estimators': 142, 'min_samples_split': 0.2759007484683616, 'max_depth': 6, 'criterion': 'mse', 'min_samples_leaf': 7, 'max_leaf_nodes': 2}. Best is trial 12 with value: 375.2064329297455.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:00:26,719]\u001b[0m Trial 18 finished with value: 414.70934113859033 and parameters: {'learning_rate': 0.46006655720850115, 'n_estimators': 176, 'min_samples_split': 0.4818827662505794, 'max_depth': 11, 'criterion': 'friedman_mse', 'min_samples_leaf': 7, 'max_leaf_nodes': 5}. Best is trial 12 with value: 375.2064329297455.\u001b[0m\n",
      "\u001b[32m[I 2021-01-13 11:02:08,510]\u001b[0m Trial 19 finished with value: 497.5888760774365 and parameters: {'learning_rate': 0.9966400406227076, 'n_estimators': 200, 'min_samples_split': 0.29164436965238877, 'max_depth': 5, 'criterion': 'friedman_mse', 'min_samples_leaf': 3, 'max_leaf_nodes': 9}. Best is trial 12 with value: 375.2064329297455.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# hyperparam tuning for sklearn ensemble.GradientBoostingRegressor\n",
    "np.random.seed(random_state)\n",
    "\n",
    "def gradboosting_objective(trial):  \n",
    "    gb_sk_opt = None\n",
    "    short = False\n",
    "    \n",
    "    learning_rate = trial.suggest_uniform('learning_rate', 0+sys.float_info.min, 1)\n",
    "    n_estimators = trial.suggest_int('n_estimators', min_n_estimators, max_n_estimators)\n",
    "    min_samples_split = trial.suggest_uniform('min_samples_split', 0+sys.float_info.min, 1)\n",
    "    max_depth = trial.suggest_int('max_depth', min_max_depth, max_max_depth)\n",
    "        \n",
    "    if short == False: # it will take a long time to run \n",
    "        criterion = trial.suggest_categorical('criterion', ['mse','friedman_mse'])\n",
    "        min_samples_leaf = trial.suggest_int('min_samples_leaf',min_min_samples_leaf, max_min_samples_leaf)\n",
    "        max_leaf_nodes = trial.suggest_int('max_leaf_nodes', min_max_leaf_nodes, max_max_leaf_nodes)\n",
    "        \n",
    "        gb_sk_opt = ensemble.GradientBoostingRegressor(learning_rate=learning_rate, \n",
    "                                                   n_estimators=n_estimators,\n",
    "                                                   criterion=criterion,\n",
    "                                                   min_samples_split=min_samples_split,\n",
    "                                                   min_samples_leaf=min_samples_leaf,\n",
    "                                                   max_depth=max_depth,\n",
    "                                                   max_leaf_nodes=max_leaf_nodes,\n",
    "                                                   random_state=random_state,\n",
    "                                                   verbose=verbose)\n",
    "    else:  # will take less time        \n",
    "        gb_sk_opt = ensemble.GradientBoostingRegressor(learning_rate=learning_rate, \n",
    "                                                   n_estimators=n_estimators,\n",
    "                                                   min_samples_split=min_samples_split,\n",
    "                                                   max_depth=max_depth,\n",
    "                                                   random_state=random_state,\n",
    "                                                   verbose=verbose)\n",
    "    \n",
    "    scores = -model_selection.cross_val_score(gb_sk_opt, x_train, y_train, scoring='neg_root_mean_squared_error', cv=tr_val_partition, verbose=verbose)\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "gb_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "gb_optuna.optimize(gradboosting_objective, n_trials=budget)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['gradient_boosting'] = summary['gradient_boosting'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': gb_optuna.best_value,\n",
    "    'Learning rate': gb_optuna.best_params['learning_rate'],\n",
    "    'N. estimators': gb_optuna.best_params['n_estimators'],\n",
    "    'Criterion': 'friedman_mse', \n",
    "    #Min. samples split': gb_optuna.best_params['min_samples_split'], \n",
    "    'Min. samples leaf': gb_optuna.best_params['min_samples_leaf'],\n",
    "    'Min. samples leaf': 1,\n",
    "    'Max. depth': gb_optuna.best_params['max_depth'],\n",
    "    #Max. leaf nodes': 'None'\n",
    "    'Max. leaf nodes': gb_optuna.best_params['max_leaf_nodes']\n",
    "    },\n",
    "    name='optuna_sklearn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgradboosting_objective(trial):  \n",
    "    \n",
    "    param = {\n",
    "        'booster': 'gbtree',\n",
    "        #'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),\n",
    "        #'alpha': trial.suggest_uniform('alpha', 0+sys.float_info.min, 1),\n",
    "        #'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0),\n",
    "        'lambda': trial.suggest_uniform('lambda', 0.01, 0.5),\n",
    "        'alpha': trial.suggest_uniform('alpha', 0.01, 0.5),\n",
    "        'gamma': trial.suggest_float('gamma', 0.01, 1.0),\n",
    "        'eta': trial.suggest_uniform('eta', 0+sys.float_info.min, 1.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', min_max_depth, max_max_depth),\n",
    "        'max_leaves': trial.suggest_int('max_leaves', min_max_leaf_nodes, max_max_leaf_nodes),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', min_n_estimators, max_n_estimators)\n",
    "    }\n",
    "\n",
    "    gb_xgb_opt = xgb.XGBRegressor(param=param, \n",
    "                                  objective='reg:squarederror',\n",
    "                                  verbosity=verbose,\n",
    "                                  random_state=random_state\n",
    "                                 )\n",
    "\n",
    "    scores = -model_selection.cross_val_score(gb_xgb_opt, x_train, y_train, scoring='neg_root_mean_squared_error', cv=tr_val_partition, verbose=verbose)\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "gb_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "gb_optuna.optimize(xgradboosting_objective, n_trials=budget)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['gradient_boosting'] = summary['gradient_boosting'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': gb_optuna.best_value,\n",
    "    'Learning rate': gb_optuna.best_params['eta'],\n",
    "    'Max. depth': gb_optuna.best_params['max_depth'],\n",
    "    'Max. leaf nodes': gb_optuna.best_params['max_leaves'],\n",
    "    'Gamma (min_split_loss)': gb_optuna.best_params['gamma'],\n",
    "    'Lambda': gb_optuna.best_params['lambda'],\n",
    "    'Alpha': gb_optuna.best_params['alpha'],\n",
    "    'N. estimators': gb_optuna.best_params['n_estimators']  \n",
    "    },\n",
    "    name='optuna_xgboost'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time (sec)</th>\n",
       "      <th>Score (RMSE)</th>\n",
       "      <th>N. neighbors</th>\n",
       "      <th>Weights</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>5.0999</td>\n",
       "      <td>455.123868</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optuna</th>\n",
       "      <td>109.5012</td>\n",
       "      <td>425.095919</td>\n",
       "      <td>9</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time (sec)  Score (RMSE) N. neighbors  Weights  P\n",
       "default     5.0999    455.123868            5  uniform  2\n",
       "optuna    109.5012    425.095919            9  uniform  1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary['knn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time (sec)</th>\n",
       "      <th>Score (RMSE)</th>\n",
       "      <th>Min. samples split</th>\n",
       "      <th>Criterion</th>\n",
       "      <th>Max. depth</th>\n",
       "      <th>N. estimators</th>\n",
       "      <th>Max. features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>0</td>\n",
       "      <td>375.560721</td>\n",
       "      <td>2</td>\n",
       "      <td>mse</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>73.5753</td>\n",
       "      <td>375.560721</td>\n",
       "      <td>2</td>\n",
       "      <td>mse</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optuna</th>\n",
       "      <td>183.5350</td>\n",
       "      <td>377.303660</td>\n",
       "      <td>0.037649</td>\n",
       "      <td>mse</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>0.227018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time (sec)  Score (RMSE) Min. samples split Criterion Max. depth  \\\n",
       "default          0    375.560721                  2       mse       None   \n",
       "default    73.5753    375.560721                  2       mse       None   \n",
       "optuna    183.5350    377.303660           0.037649       mse         10   \n",
       "\n",
       "        N. estimators Max. features  \n",
       "default           100             1  \n",
       "default           100             1  \n",
       "optuna             52      0.227018  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary['random_forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time (sec)</th>\n",
       "      <th>Score (RMSE)</th>\n",
       "      <th>Criterion</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Max. depth</th>\n",
       "      <th>Max. leaf nodes</th>\n",
       "      <th>Min. samples leaf</th>\n",
       "      <th>Min. samples split</th>\n",
       "      <th>N. estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>32.4810</td>\n",
       "      <td>389.357849</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optuna</th>\n",
       "      <td>2598.5261</td>\n",
       "      <td>381.286402</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>0.154706</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434674</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time (sec)  Score (RMSE)     Criterion  Learning rate  Max. depth  \\\n",
       "default    32.4810    389.357849  friedman_mse       0.100000         3.0   \n",
       "optuna   2598.5261    381.286402  friedman_mse       0.154706         7.0   \n",
       "\n",
       "        Max. leaf nodes  Min. samples leaf  Min. samples split  N. estimators  \n",
       "default            None                1.0            2.000000          100.0  \n",
       "optuna             None                1.0            0.434674           74.0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary['gradient_boosting']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ATTRIBUTE SELECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to answer the following questions: \n",
    "\n",
    "- Are all 550 input attributes actually necessary in order to get a good model? Is it possible to have an accurate model that uses fewer than 550 variables? How many? \n",
    "- Is it enough to use only the attributes for the actual Sotavento location? (13th location in the grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<USE AS MANY CELLS AS YOU NEED>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
