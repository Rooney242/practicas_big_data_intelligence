{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wind prediction - Second assignment\n",
    "\n",
    "## Authors\n",
    "\n",
    "David Moreno Maldonado 100441714     \n",
    "Inés Fernández Campos 100443936"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/fddcampos/Documents/uc3m/2_term/BDINTELLIGENCE/practicas_big_data_intelligence/assignment_2'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import some libraries\n",
    "import os\n",
    "import numpy as np              \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn import preprocessing, impute, model_selection, neighbors, ensemble\n",
    "import optuna\n",
    "import optuna.visualization as ov\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN PARAMETERS FOR THE ASSIGNMENT\n",
    "budget = 20\n",
    "random_state = 0\n",
    "verbose = 0\n",
    "\n",
    "#PARAMETERS FOR THE HYPER-PARAMETER TUNNING\n",
    "#KNN\n",
    "min_n_neigbors = 1\n",
    "max_n_neigbors = 16\n",
    "\n",
    "#RANDOM FOREST\n",
    "min_max_depth = 2\n",
    "max_max_depth = 20\n",
    "min_n_estimators = 50\n",
    "max_n_estimators = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"wind_pickle\" file contains data in a binary format called \"Pickle\". Pickle data loads faster than text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle('wind_pickle.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the attributes in the dataset. Very important, the output attribute (i.e. the value to be predicted, **energy**, is the first attribute). **Steps** represents the hours in advance of the forecast. We will not use this variable here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5937, 556)\n"
     ]
    }
   ],
   "source": [
    "# The dataset contains 5937 instances and 556 attributes (including the outcome to be predicted)\n",
    "print(data.shape)\n",
    "#data.columns.values.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-1 for training, 0 for validation, 1 for testing\n",
    "year_to_part = {\n",
    "    2005: -1,\n",
    "    2006: -1,\n",
    "    2007: 0,\n",
    "    2008: 0, \n",
    "    2009: 1,\n",
    "    2010: 1\n",
    "}\n",
    "data['partition'] = data['year'].apply(lambda x: year_to_part[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now remove the columns that cannot be used for training the models from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps, month, day, hour, year should be removed, they cannot be used for training the models\n",
    "to_remove = ['steps', 'month', 'year', 'day', 'hour']\n",
    "for m in to_remove: data = data.drop(m, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets put 163861 missing values \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import randint\n",
    "\n",
    "# we add na values at random\n",
    "my_NIA = 100443936 + 100441714\n",
    "np.random.seed(my_NIA)\n",
    "\n",
    "how_many_nas = round(data.shape[0]*data.shape[1]*0.05)\n",
    "print('Lets put '+str(how_many_nas)+' missing values \\n')\n",
    "x_locations = randint(0, data.shape[0], size=how_many_nas)\n",
    "y_locations = randint(1, data.shape[1]-2, size=how_many_nas)\n",
    "\n",
    "for i in range(len(x_locations)):\n",
    "    data.iat[x_locations[i], y_locations[i]] = np.nan\n",
    "    \n",
    "data.to_pickle('wind_pickle_with_nan.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point on, the file wind_pickle_with_nan should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5937, 552)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_pickle('wind_pickle_with_nan.pickle')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().values.any())\n",
    "input_cols = data.columns.difference(['energy', 'partition'])\n",
    "x = data[input_cols]\n",
    "#Iterative imputer (takes too long)\n",
    "'''iter_imp = impute.IterativeImputer(random_state=random_state, \n",
    "                                   initial_strategy='median', \n",
    "                                   max_iter=3,\n",
    "                                   verbose=verbose)\n",
    "no_nan = iter_imp.fit_transform(x)'''\n",
    "\n",
    "#KNN imputer(takes too long)\n",
    "'''knn_imp = impute.KNNImputer(weights='distance')\n",
    "no_nan = knn_imp.fit_transform(x)'''\n",
    "\n",
    "#Simple imputer\n",
    "simp_imp = impute.SimpleImputer(strategy='median',\n",
    "                               verbose=2)\n",
    "no_nan = simp_imp.fit_transform(x)\n",
    "\n",
    "data[input_cols] = pd.DataFrame(data=no_nan)\n",
    "print(data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(data[input_cols]) \n",
    "data[input_cols] = scaler.transform(data[input_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split\n",
    "We are going to use train/test for model evaluation (outer) and train/validation for hyperparameter tuning (inner), as follows:     \n",
    "1. Train partition: the first two years of data. Given that there are 6 years worth of data, we will use the first 2/6 of the instances for training.     \n",
    "2. Validation partition: the second two years of data. \n",
    "3. Test partition: the remaining data    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-1 for training, 0 for validation, 1 for testing\n",
    "test = data[data['partition'] == 1]\n",
    "train = data[data['partition'] != 1]\n",
    "tr_val_partition = model_selection.PredefinedSplit(train['partition'].tolist())\n",
    "\n",
    "del test['partition']\n",
    "del train['partition']\n",
    "\n",
    "y_test = test['energy']\n",
    "x_test = test[test.columns.difference(['energy'])]\n",
    "\n",
    "y_train = train['energy']\n",
    "x_train = train[train.columns.difference(['energy'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert the training and test sets from Pandas DataFrames to Numpy matrices, so that they can be used by scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_x_train = np.matrix(x_train)\n",
    "mat_y_train = np.matrix(y_train).T\n",
    "mat_x_test = np.matrix(x_test)\n",
    "mat_y_test = np.matrix(y_test).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. MODEL SELECTION AND HYPER-PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframes with all the information of each model\n",
    "summary = {\n",
    "    'knn': pd.DataFrame(columns=['Time (sec)', 'Score (RMSE)', 'N. neighbors', 'Weights', 'P']),\n",
    "    'random_forest': pd.DataFrame(columns=['Time (sec)', 'Score (RMSE)', 'Min. samples split', 'Criterion', 'Max. depth', 'N. estimators','Max. features']),\n",
    "    'gradient_boosting': pd.DataFrame(columns=['Time (sec)', 'Score (RMSE)'])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Default hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_state)\n",
    "knn_default = neighbors.KNeighborsRegressor()\n",
    "\n",
    "start_time = time.time()\n",
    "scores = -model_selection.cross_val_score(knn_default, x_train, y_train,\n",
    "                                          scoring='neg_root_mean_squared_error',\n",
    "                                          cv=tr_val_partition,\n",
    "                                          verbose=verbose) \n",
    "end_time = time.time()\n",
    "\n",
    "summary['knn'] = summary['knn'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': scores.mean(), \n",
    "    'N. neighbors': 5, \n",
    "    'Weights': 'uniform', \n",
    "    'P': 2\n",
    "    }, \n",
    "    name='default'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Hyper-parameter tunning (OPTUNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:39:31,240]\u001b[0m A new study created in memory with name: no-name-ec2f521e-b91a-437a-b743-0fb883f9735a\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:39:36,424]\u001b[0m Trial 0 finished with value: 434.58474235770177 and parameters: {'n_neighbors': 15, 'weights': 'uniform', 'p': 2}. Best is trial 0 with value: 434.58474235770177.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:39:42,500]\u001b[0m Trial 1 finished with value: 427.1897361344681 and parameters: {'n_neighbors': 8, 'weights': 'uniform', 'p': 1}. Best is trial 1 with value: 427.1897361344681.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:39:47,733]\u001b[0m Trial 2 finished with value: 436.66754039946005 and parameters: {'n_neighbors': 12, 'weights': 'distance', 'p': 2}. Best is trial 1 with value: 427.1897361344681.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:39:53,542]\u001b[0m Trial 3 finished with value: 441.1599884529427 and parameters: {'n_neighbors': 5, 'weights': 'distance', 'p': 1}. Best is trial 1 with value: 427.1897361344681.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:39:59,120]\u001b[0m Trial 4 finished with value: 432.0797327508031 and parameters: {'n_neighbors': 7, 'weights': 'uniform', 'p': 1}. Best is trial 1 with value: 427.1897361344681.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:04,894]\u001b[0m Trial 5 finished with value: 425.8532193925109 and parameters: {'n_neighbors': 12, 'weights': 'uniform', 'p': 1}. Best is trial 5 with value: 425.8532193925109.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:10,651]\u001b[0m Trial 6 finished with value: 429.05463080771233 and parameters: {'n_neighbors': 16, 'weights': 'uniform', 'p': 1}. Best is trial 5 with value: 425.8532193925109.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:15,152]\u001b[0m Trial 7 finished with value: 474.762900447833 and parameters: {'n_neighbors': 3, 'weights': 'distance', 'p': 2}. Best is trial 5 with value: 425.8532193925109.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:19,526]\u001b[0m Trial 8 finished with value: 512.2417177624698 and parameters: {'n_neighbors': 2, 'weights': 'distance', 'p': 2}. Best is trial 5 with value: 425.8532193925109.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:25,028]\u001b[0m Trial 9 finished with value: 426.6970286295103 and parameters: {'n_neighbors': 13, 'weights': 'distance', 'p': 1}. Best is trial 5 with value: 425.8532193925109.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:31,012]\u001b[0m Trial 10 finished with value: 425.4813377209308 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'p': 1}. Best is trial 10 with value: 425.4813377209308.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:36,982]\u001b[0m Trial 11 finished with value: 425.4813377209308 and parameters: {'n_neighbors': 11, 'weights': 'uniform', 'p': 1}. Best is trial 10 with value: 425.4813377209308.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:42,362]\u001b[0m Trial 12 finished with value: 425.3455575639307 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'p': 1}. Best is trial 12 with value: 425.3455575639307.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:47,716]\u001b[0m Trial 13 finished with value: 425.3455575639307 and parameters: {'n_neighbors': 10, 'weights': 'uniform', 'p': 1}. Best is trial 12 with value: 425.3455575639307.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:53,068]\u001b[0m Trial 14 finished with value: 425.09591854856325 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'p': 1}. Best is trial 14 with value: 425.09591854856325.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:40:58,355]\u001b[0m Trial 15 finished with value: 437.64527002872245 and parameters: {'n_neighbors': 6, 'weights': 'uniform', 'p': 1}. Best is trial 14 with value: 425.09591854856325.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:41:04,131]\u001b[0m Trial 16 finished with value: 425.09591854856325 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'p': 1}. Best is trial 14 with value: 425.09591854856325.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:41:09,376]\u001b[0m Trial 17 finished with value: 451.51235760509013 and parameters: {'n_neighbors': 4, 'weights': 'uniform', 'p': 1}. Best is trial 14 with value: 425.09591854856325.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:41:14,867]\u001b[0m Trial 18 finished with value: 425.09591854856325 and parameters: {'n_neighbors': 9, 'weights': 'uniform', 'p': 1}. Best is trial 14 with value: 425.09591854856325.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:41:20,745]\u001b[0m Trial 19 finished with value: 429.3973607287476 and parameters: {'n_neighbors': 14, 'weights': 'uniform', 'p': 1}. Best is trial 14 with value: 425.09591854856325.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(random_state)\n",
    "def knn_objective(trial):\n",
    "    n_neighbors = trial.suggest_int('n_neighbors', min_n_neigbors, max_n_neigbors)\n",
    "    weights = trial.suggest_categorical('weights', ['uniform','distance'])\n",
    "    p = trial.suggest_categorical('p', [1, 2])\n",
    "\n",
    "    clf = neighbors.KNeighborsRegressor(\n",
    "        n_neighbors=n_neighbors,\n",
    "        weights=weights,\n",
    "        p=p)\n",
    "\n",
    "    scores = -model_selection.cross_val_score(clf, x_train, y_train,\n",
    "        cv=tr_val_partition,\n",
    "        scoring='neg_root_mean_squared_error')\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "knn_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "knn_optuna.optimize(knn_objective, n_trials=budget)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['knn'] = summary['knn'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': knn_optuna.best_value, \n",
    "    'N. neighbors': knn_optuna.best_params['n_neighbors'], \n",
    "    'Weights': knn_optuna.best_params['weights'], \n",
    "    'P': knn_optuna.best_params['p']\n",
    "    }, \n",
    "    name='optuna'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Default hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_state)\n",
    "rf_default = ensemble.RandomForestRegressor(random_state=random_state, verbose=verbose)\n",
    "\n",
    "start_time = time.time()\n",
    "scores = -model_selection.cross_val_score(rf_default, x_train, y_train,\n",
    "                                          scoring='neg_root_mean_squared_error',\n",
    "                                          cv=tr_val_partition,\n",
    "                                          verbose=verbose)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['random_forest'] = summary['random_forest'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': scores.mean(),\n",
    "    'Min. samples split': 2, \n",
    "    'Criterion': 'mse', \n",
    "    'Max. depth': 'None',\n",
    "    'N. estimators': 100,\n",
    "    'Max. features': 1\n",
    "    },\n",
    "    name='default'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Hyper-parameter tunning (OPTUNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:19:15,385]\u001b[0m A new study created in memory with name: no-name-afbb499f-328b-4ec8-916e-41408b563fe5\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:19:15,507]\u001b[0m Trial 0 finished with value: 668.3157608288334 and parameters: {'min_samples_split': 0.8420626511506619, 'criterion': 'mse', 'max_depth': 11, 'n_estimators': 111, 'max_features': 0.22964889811063183}. Best is trial 0 with value: 668.3157608288334.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[668.31576083]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:19:15,953]\u001b[0m Trial 1 finished with value: 416.02693466304027 and parameters: {'min_samples_split': 0.22217725686158962, 'criterion': 'mse', 'max_depth': 10, 'n_estimators': 89, 'max_features': 0.014222760723832883}. Best is trial 1 with value: 416.02693466304027.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[416.02693466]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:19:32,902]\u001b[0m Trial 2 finished with value: 397.0549870471909 and parameters: {'min_samples_split': 0.27608113381936805, 'criterion': 'friedman_mse', 'max_depth': 6, 'n_estimators': 195, 'max_features': 0.3254333086193524}. Best is trial 2 with value: 397.0549870471909.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:19:33,037]\u001b[0m Trial 3 finished with value: 668.3520154857824 and parameters: {'min_samples_split': 0.7155418283828904, 'criterion': 'mse', 'max_depth': 16, 'n_estimators': 133, 'max_features': 0.9539498563134007}. Best is trial 2 with value: 397.0549870471909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[397.05498705]\n",
      "[668.35201549]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:19:46,527]\u001b[0m Trial 4 finished with value: 439.6219384407865 and parameters: {'min_samples_split': 0.4973733826326475, 'criterion': 'friedman_mse', 'max_depth': 13, 'n_estimators': 132, 'max_features': 0.7543669851904506}. Best is trial 2 with value: 397.0549870471909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[439.62193844]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:19:50,193]\u001b[0m Trial 5 finished with value: 531.8125595160947 and parameters: {'min_samples_split': 0.5870028727181181, 'criterion': 'mse', 'max_depth': 7, 'n_estimators': 147, 'max_features': 0.3937671236597815}. Best is trial 2 with value: 397.0549870471909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[531.81255952]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:19:55,240]\u001b[0m Trial 6 finished with value: 398.4895565140924 and parameters: {'min_samples_split': 0.1961521278613999, 'criterion': 'mse', 'max_depth': 6, 'n_estimators': 134, 'max_features': 0.13840208553807065}. Best is trial 2 with value: 397.0549870471909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[398.48955651]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:19:56,503]\u001b[0m Trial 7 finished with value: 410.5623510360694 and parameters: {'min_samples_split': 0.2727794669539847, 'criterion': 'mse', 'max_depth': 18, 'n_estimators': 192, 'max_features': 0.021479311142142188}. Best is trial 2 with value: 397.0549870471909.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 17:19:56,596]\u001b[0m Trial 8 finished with value: 668.3138720807941 and parameters: {'min_samples_split': 0.9419565388143725, 'criterion': 'mse', 'max_depth': 16, 'n_estimators': 79, 'max_features': 0.14473233375850403}. Best is trial 2 with value: 397.0549870471909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[410.56235104]\n",
      "[668.31387208]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:20:13,588]\u001b[0m Trial 9 finished with value: 400.7885514258249 and parameters: {'min_samples_split': 0.3613713193049055, 'criterion': 'mse', 'max_depth': 5, 'n_estimators': 191, 'max_features': 0.4106695790225199}. Best is trial 2 with value: 397.0549870471909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400.78855143]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:20:32,533]\u001b[0m Trial 10 finished with value: 416.92737393683217 and parameters: {'min_samples_split': 0.012623405217639272, 'criterion': 'friedman_mse', 'max_depth': 3, 'n_estimators': 165, 'max_features': 0.6542220404285533}. Best is trial 2 with value: 397.0549870471909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[416.92737394]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 17:20:34,043]\u001b[0m Trial 11 finished with value: 458.77092445372074 and parameters: {'min_samples_split': 0.007491517955698135, 'criterion': 'friedman_mse', 'max_depth': 2, 'n_estimators': 51, 'max_features': 0.23840977483705364}. Best is trial 2 with value: 397.0549870471909.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[458.77092445]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(random_state)\n",
    "def random_forest_objective(trial):\n",
    "    min_samples_split = trial.suggest_uniform('min_samples_split', 0+sys.float_info.min, 1)\n",
    "    criterion = trial.suggest_categorical('criterion', ['mse','friedman_mse'])\n",
    "    max_depth = trial.suggest_int('max_depth', min_max_depth, max_max_depth)\n",
    "    n_estimators = trial.suggest_int('n_estimators', min_n_estimators, max_n_estimators)\n",
    "    max_features = trial.suggest_uniform('max_features', 0+sys.float_info.min, 1)\n",
    "\n",
    "    clf = ensemble.RandomForestRegressor(\n",
    "        random_state=random_state,\n",
    "        min_samples_split=min_samples_split,\n",
    "        criterion=criterion,\n",
    "        max_depth=max_depth,\n",
    "        n_estimators=n_estimators,\n",
    "        max_features=max_features\n",
    "        )\n",
    "\n",
    "    scores = -model_selection.cross_val_score(clf, x_train, y_train,\n",
    "        cv=tr_val_partition,\n",
    "        scoring='neg_root_mean_squared_error')\n",
    "    print(scores)\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "rf_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "rf_optuna.optimize(random_forest_objective, n_trials=budget)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['random_forest'] = summary['random_forest'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': rf_optuna.best_value,\n",
    "    'Min. samples split': rf_optuna.best_params['min_samples_split'], \n",
    "    'Criterion': rf_optuna.best_params['criterion'], \n",
    "    'Max. depth': rf_optuna.best_params['max_depth'],\n",
    "    'N. estimators': rf_optuna.best_params['n_estimators'],\n",
    "    'Max. features': rf_optuna.best_params['max_features']\n",
    "    },\n",
    "    name='optuna'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Default hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation using sklearn\n",
    "np.random.seed(random_state)\n",
    "gb_sk_def = ensemble.GradientBoostingRegressor(random_state=random_state, verbose=verbose)\n",
    "\n",
    "start_time = time.time()\n",
    "scores = -model_selection.cross_val_score(gb_sk_def, x_train, y_train,\n",
    "                                          scoring='neg_root_mean_squared_error',\n",
    "                                          cv=tr_val_partition,\n",
    "                                          verbose=verbose)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['gradient_boosting'] = summary['gradient_boosting'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': scores.mean(),\n",
    "    'Learning rate': 0.1,\n",
    "    'N. estimators': 100,\n",
    "    'Criterion': 'friedman_mse', \n",
    "    'Min. samples split': 2, \n",
    "    'Min. samples leaf': 1,\n",
    "    'Max. depth': 3,\n",
    "    'Max. leaf nodes': 'None'\n",
    "    },\n",
    "    name='default'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation using xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(mat_x_train, label=mat_y_train)\n",
    "dtest = xgb.DMatrix(mat_x_test, label=mat_y_test)\n",
    "\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "start_time = time.time()\n",
    "scores = - model_selection.cross_val_score(model, x_train, y_train,\n",
    "                                            cv=tr_val_partition,\n",
    "                                            scoring='neg_root_mean_squared_error')\n",
    "end_time = time.time()\n",
    "\n",
    "summary['gradient_boosting'] = summary['gradient_boosting'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': scores.mean(),\n",
    "    'N. estimators': model.get_params()['n_estimators']\n",
    "    },\n",
    "    name='default'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Hyper-parameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dir(dtrain))\n",
    "#print('\\n', dir(model))\n",
    "min_max_leaf_nodes = 2\n",
    "max_max_leaf_nodes = 20\n",
    "min_min_samples_leaf = 1\n",
    "max_min_samples_leaf = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-12 22:32:14,604]\u001b[0m A new study created in memory with name: no-name-af1e068d-957b-41ab-9d66-55f63c91f777\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 22:32:35,641]\u001b[0m Trial 0 finished with value: 417.1559653806665 and parameters: {'learning_rate': 0.6038207442734052, 'n_estimators': 91, 'min_samples_split': 0.9701149707547224, 'max_depth': 12}. Best is trial 0 with value: 417.1559653806665.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 22:34:19,453]\u001b[0m Trial 1 finished with value: 386.0131527292542 and parameters: {'learning_rate': 0.14739036993273402, 'n_estimators': 68, 'min_samples_split': 0.30631877787078476, 'max_depth': 15}. Best is trial 1 with value: 386.0131527292542.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 22:38:03,094]\u001b[0m Trial 2 finished with value: 398.5639575103852 and parameters: {'learning_rate': 0.26108146965486645, 'n_estimators': 124, 'min_samples_split': 0.1919876374112307, 'max_depth': 11}. Best is trial 1 with value: 386.0131527292542.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 22:39:07,398]\u001b[0m Trial 3 finished with value: 485.89354300851465 and parameters: {'learning_rate': 0.8489591105192251, 'n_estimators': 111, 'min_samples_split': 0.3502197891638039, 'max_depth': 3}. Best is trial 1 with value: 386.0131527292542.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 22:47:37,456]\u001b[0m Trial 4 finished with value: 424.0047399149299 and parameters: {'learning_rate': 0.5037474616447736, 'n_estimators': 171, 'min_samples_split': 0.03279344004197149, 'max_depth': 17}. Best is trial 1 with value: 386.0131527292542.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 22:52:15,797]\u001b[0m Trial 5 finished with value: 411.4252837334762 and parameters: {'learning_rate': 0.3870859292071984, 'n_estimators': 142, 'min_samples_split': 0.12732233862911613, 'max_depth': 11}. Best is trial 1 with value: 386.0131527292542.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 22:53:11,111]\u001b[0m Trial 6 finished with value: 469.8079819794906 and parameters: {'learning_rate': 0.9963132757759628, 'n_estimators': 131, 'min_samples_split': 0.14858851605060186, 'max_depth': 2}. Best is trial 1 with value: 386.0131527292542.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 22:53:53,684]\u001b[0m Trial 7 finished with value: 392.02795680608244 and parameters: {'learning_rate': 0.06895668340119876, 'n_estimators': 122, 'min_samples_split': 0.8965940480380186, 'max_depth': 15}. Best is trial 1 with value: 386.0131527292542.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 22:58:23,579]\u001b[0m Trial 8 finished with value: 419.6078699192311 and parameters: {'learning_rate': 0.46388508618929647, 'n_estimators': 181, 'min_samples_split': 0.14882609798752222, 'max_depth': 8}. Best is trial 1 with value: 386.0131527292542.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 23:06:16,534]\u001b[0m Trial 9 finished with value: 438.4123214436052 and parameters: {'learning_rate': 0.5343861121396762, 'n_estimators': 162, 'min_samples_split': 0.14061135948447478, 'max_depth': 20}. Best is trial 1 with value: 386.0131527292542.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 23:06:50,362]\u001b[0m Trial 10 finished with value: 657.9418557948678 and parameters: {'learning_rate': 0.0005517337745158113, 'n_estimators': 52, 'min_samples_split': 0.6731975791785723, 'max_depth': 19}. Best is trial 1 with value: 386.0131527292542.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 23:07:24,053]\u001b[0m Trial 11 finished with value: 642.4995485739684 and parameters: {'learning_rate': 0.0013788167780819094, 'n_estimators': 51, 'min_samples_split': 0.6326682826462955, 'max_depth': 15}. Best is trial 1 with value: 386.0131527292542.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 23:07:39,241]\u001b[0m Trial 12 finished with value: 393.1570625108535 and parameters: {'learning_rate': 0.19496057678561796, 'n_estimators': 83, 'min_samples_split': 0.9921836340154124, 'max_depth': 15}. Best is trial 1 with value: 386.0131527292542.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 23:09:40,847]\u001b[0m Trial 13 finished with value: 381.6513214349438 and parameters: {'learning_rate': 0.13219481529327515, 'n_estimators': 78, 'min_samples_split': 0.3946347772922761, 'max_depth': 15}. Best is trial 13 with value: 381.6513214349438.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 23:10:54,639]\u001b[0m Trial 14 finished with value: 381.28640195357843 and parameters: {'learning_rate': 0.15470584883337957, 'n_estimators': 74, 'min_samples_split': 0.43467439799539437, 'max_depth': 7}. Best is trial 14 with value: 381.28640195357843.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 23:12:06,553]\u001b[0m Trial 15 finished with value: 391.3068796951583 and parameters: {'learning_rate': 0.2982985574127179, 'n_estimators': 95, 'min_samples_split': 0.4950791201817833, 'max_depth': 6}. Best is trial 14 with value: 381.28640195357843.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 23:13:06,060]\u001b[0m Trial 16 finished with value: 452.0236436305419 and parameters: {'learning_rate': 0.7085113324652672, 'n_estimators': 68, 'min_samples_split': 0.470994263746617, 'max_depth': 7}. Best is trial 14 with value: 381.28640195357843.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 23:13:49,000]\u001b[0m Trial 17 finished with value: 383.11238747183376 and parameters: {'learning_rate': 0.1269142212709772, 'n_estimators': 73, 'min_samples_split': 0.6512711758105689, 'max_depth': 5}. Best is trial 14 with value: 381.28640195357843.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 23:14:52,560]\u001b[0m Trial 18 finished with value: 394.15152935713377 and parameters: {'learning_rate': 0.28750577865190174, 'n_estimators': 57, 'min_samples_split': 0.34544966269622684, 'max_depth': 9}. Best is trial 14 with value: 381.28640195357843.\u001b[0m\n",
      "\u001b[32m[I 2021-01-12 23:15:33,134]\u001b[0m Trial 19 finished with value: 406.13628815750235 and parameters: {'learning_rate': 0.3708956565589232, 'n_estimators': 105, 'min_samples_split': 0.8029386719020871, 'max_depth': 4}. Best is trial 14 with value: 381.28640195357843.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# hyperparam tuning for sklearn ensemble.GradientBoostingRegressor\n",
    "np.random.seed(random_state)\n",
    "\n",
    "def gradboosting_objective(trial):  \n",
    "    gb_sk_opt = None\n",
    "    some = 0\n",
    "    \n",
    "    if some == 1:\n",
    "        learning_rate = trial.suggest_uniform('learning_rate', 0+sys.float_info.min, 1)\n",
    "        n_estimators = trial.suggest_int('n_estimators', min_n_estimators, max_n_estimators)\n",
    "        criterion = trial.suggest_categorical('criterion', ['mse','friedman_mse', 'mae'])\n",
    "        min_samples_split = trial.suggest_uniform('min_samples_split', 0+sys.float_info.min, 1)\n",
    "        min_samples_leaf = trial.suggest_int('min_samples_split',min_min_samples_leaf, max_min_samples_leaf)\n",
    "        max_depth = trial.suggest_int('max_depth', min_max_depth, max_max_depth)\n",
    "        max_leaf_nodes = trial.suggest_int('max_depth', min_max_leaf_nodes, max_max_leaf_nodes)\n",
    "        \n",
    "        \n",
    "        gb_sk_opt = ensemble.GradientBoostingRegressor(learning_rate=learning_rate, \n",
    "                                                   n_estimators=n_estimators,\n",
    "                                                   criterion=criterion,\n",
    "                                                   min_samples_split=min_samples_split,\n",
    "                                                   min_samples_leaf=min_samples_leaf,\n",
    "                                                   max_depth=max_depth,\n",
    "                                                   max_leaf_nodes=max_leaf_nodes,\n",
    "                                                   random_state=random_state,\n",
    "                                                   verbose=verbose)\n",
    "    \n",
    "    else:\n",
    "        learning_rate = trial.suggest_uniform('learning_rate', 0+sys.float_info.min, 1)\n",
    "        n_estimators = trial.suggest_int('n_estimators', min_n_estimators, max_n_estimators)\n",
    "        #criterion = trial.suggest_categorical('criterion', ['mse','friedman_mse', 'mae'])\n",
    "        min_samples_split = trial.suggest_uniform('min_samples_split', 0+sys.float_info.min, 1)\n",
    "        #min_samples_leaf = trial.suggest_int('min_samples_split',min_min_samples_leaf, max_min_samples_leaf)\n",
    "        max_depth = trial.suggest_int('max_depth', min_max_depth, max_max_depth)\n",
    "        #max_leaf_nodes = trial.suggest_int('max_depth', min_max_leaf_nodes, max_max_leaf_nodes)\n",
    "        \n",
    "        \n",
    "        gb_sk_opt = ensemble.GradientBoostingRegressor(learning_rate=learning_rate, \n",
    "                                                   n_estimators=n_estimators,\n",
    "                                                   #criterion=criterion,\n",
    "                                                   min_samples_split=min_samples_split,\n",
    "                                                  # min_samples_leaf=min_samples_leaf,\n",
    "                                                   max_depth=max_depth,\n",
    "                                                  # max_leaf_nodes=max_leaf_nodes,\n",
    "                                                   random_state=random_state,\n",
    "                                                   verbose=verbose)\n",
    "    \n",
    "        \n",
    "    \n",
    "    scores = -model_selection.cross_val_score(gb_sk_opt, x_train, y_train,\n",
    "                                          scoring='neg_root_mean_squared_error',\n",
    "                                          cv=tr_val_partition,\n",
    "                                          verbose=verbose)\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "gb_optuna = optuna.create_study(direction='minimize')\n",
    "start_time = time.time()\n",
    "gb_optuna.optimize(gradboosting_objective, n_trials=budget)\n",
    "end_time = time.time()\n",
    "\n",
    "summary['gradient_boosting'] = summary['gradient_boosting'].append(pd.Series({\n",
    "    'Time (sec)': '{:.4f}'.format(end_time - start_time), \n",
    "    'Score (RMSE)': gb_optuna.best_value,\n",
    "    'Learning rate': gb_optuna.best_params['learning_rate'],\n",
    "    'N. estimators': gb_optuna.best_params['n_estimators'],\n",
    "    'Criterion': 'friedman_mse', \n",
    "    'Min. samples split': gb_optuna.best_params['min_samples_split'], \n",
    "    #'Min. samples leaf': gb_optuna.best_params['min_samples_leaf'],\n",
    "    'Min. samples leaf': 1,\n",
    "    'Max. depth': gb_optuna.best_params['max_depth'],\n",
    "    'Max. leaf nodes': 'None'\n",
    "    #'Max. leaf nodes': gb_optuna.best_params['max_leaf_nodes']\n",
    "    },\n",
    "    name='optuna'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time (sec)</th>\n",
       "      <th>Score (RMSE)</th>\n",
       "      <th>N. neighbors</th>\n",
       "      <th>Weights</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>5.0999</td>\n",
       "      <td>455.123868</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optuna</th>\n",
       "      <td>109.5012</td>\n",
       "      <td>425.095919</td>\n",
       "      <td>9</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time (sec)  Score (RMSE) N. neighbors  Weights  P\n",
       "default     5.0999    455.123868            5  uniform  2\n",
       "optuna    109.5012    425.095919            9  uniform  1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary['knn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time (sec)</th>\n",
       "      <th>Score (RMSE)</th>\n",
       "      <th>Min. samples split</th>\n",
       "      <th>Criterion</th>\n",
       "      <th>Max. depth</th>\n",
       "      <th>N. estimators</th>\n",
       "      <th>Max. features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>0</td>\n",
       "      <td>375.560721</td>\n",
       "      <td>2</td>\n",
       "      <td>mse</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>73.5753</td>\n",
       "      <td>375.560721</td>\n",
       "      <td>2</td>\n",
       "      <td>mse</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optuna</th>\n",
       "      <td>183.5350</td>\n",
       "      <td>377.303660</td>\n",
       "      <td>0.037649</td>\n",
       "      <td>mse</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>0.227018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time (sec)  Score (RMSE) Min. samples split Criterion Max. depth  \\\n",
       "default          0    375.560721                  2       mse       None   \n",
       "default    73.5753    375.560721                  2       mse       None   \n",
       "optuna    183.5350    377.303660           0.037649       mse         10   \n",
       "\n",
       "        N. estimators Max. features  \n",
       "default           100             1  \n",
       "default           100             1  \n",
       "optuna             52      0.227018  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary['random_forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time (sec)</th>\n",
       "      <th>Score (RMSE)</th>\n",
       "      <th>Criterion</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Max. depth</th>\n",
       "      <th>Max. leaf nodes</th>\n",
       "      <th>Min. samples leaf</th>\n",
       "      <th>Min. samples split</th>\n",
       "      <th>N. estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>32.4810</td>\n",
       "      <td>389.357849</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optuna</th>\n",
       "      <td>2598.5261</td>\n",
       "      <td>381.286402</td>\n",
       "      <td>friedman_mse</td>\n",
       "      <td>0.154706</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434674</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time (sec)  Score (RMSE)     Criterion  Learning rate  Max. depth  \\\n",
       "default    32.4810    389.357849  friedman_mse       0.100000         3.0   \n",
       "optuna   2598.5261    381.286402  friedman_mse       0.154706         7.0   \n",
       "\n",
       "        Max. leaf nodes  Min. samples leaf  Min. samples split  N. estimators  \n",
       "default            None                1.0            2.000000          100.0  \n",
       "optuna             None                1.0            0.434674           74.0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary['gradient_boosting']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ATTRIBUTE SELECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to answer the following questions: \n",
    "\n",
    "- Are all 550 input attributes actually necessary in order to get a good model? Is it possible to have an accurate model that uses fewer than 550 variables? How many? \n",
    "- Is it enough to use only the attributes for the actual Sotavento location? (13th location in the grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<USE AS MANY CELLS AS YOU NEED>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
